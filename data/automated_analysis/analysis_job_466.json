{
    "job_id": 466,
    "job_details": {
        "job_id": 466,
        "Organisatienaam": "DeepL SE",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "Analytics Engineer",
        "Standplaats": null,
        "Vacaturelink (origineel)": "glassdoor.nl",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Marktanalist (m/v/x)",
        "Opleidingsniveau": "Onbekend",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "As an Analytics Engineer, your main responsibilities and deliverables will be to build and maintain ETL pipelines, create foundational data models in our data warehouse and integrate new data sources using DataOps best practices, including documentation and testing. You will also support other data specialists in their work to make their queries and tables efficient and their use of data effective., We are looking for a data-focused Analytics Engineer to join a team of versatile engineers that build and maintain data models, libraries and the tooling supporting data processing at DeepL. The data platform combines various data sources, both internal and external, and makes them available to our stakeholders across the company: Developers, Product Development, Data Science and Management. You will work in a cross-functional team with product managers, data scientists, data engineers and developers to solve complex technical challenges. You may work with revenue, customer or usage data and gain an analytical understanding of these datasets., * Collaborate with team members to collect business requirements, define successful outcomes, and design data models\n     * Leverage raw data in our data warehouse to build a curated data models\n     * Write production quality ELT code (Python, SQL) with an eye towards performance and maintainability\n     * Create and maintain architecture and systems documentation\n     * Maintain our data catalog as a scalable resource to support self-service and serve as single source of truth for data definition\n     * Provide data modeling expertise to all team members through code reviews, pair programming, and training to help deliver optimal, DRY, and scalable database designs and queries\n     * Become a domain expert in the data you are work with\n     * Improve, manage, and teach code maintainability and performance standards in code submitted and reviewed\n     * Help our team maintain and improve the infrastructure for data collection, processing, management and analysis\n     * Research, design, implement and drive new solutions and software for solving complex data processing problems across all of DeepL\n     * Work on our internal tools to make the data easily accessible to our internal stakeholders, * Diverse and internationally distributed team: joining our team means becoming part of a large, global community with people of more than 90 nationalities. We're more than just colleagues; we're a group of professionals with a shared mission to connect diverse cultures. Our global presence is growing-we've doubled in size nearly every year, with our employees based in the UK, Germany, the Netherlands, Poland, the US, and Japan, and we continue to expand our network.\n     * Open communication, regular feedback: as a language-focused company, we value the importance of clear, honest communication. We value smooth collaboration, direct and actionable feedback, and believe that leading with empathy makes us better together.\n     * Remote work, flexible hours: whether you're near or in our hubs in cities like Cologne, Berlin, Amsterdam, London, Austin, or Tokyo, or prefer the comfort of your own home, you decide where your office is. We offer remote opportunities, flexible working hours and trust in your productivity, all in sync with your team's general locations and time zones to foster effective and seamless collaboration. Our aim is to integrate your work with your lifestyle, ensuring a balance that respects both your needs and our operational requirements.\n     * Regular in-person team events: we bond over vibrant events that are as unique as our team, from local team and business unit gatherings, to new-joiner onboardings, to company-wide events that bring us all together-literally.\n     * Monthly full-day hacking sessions: every month, we have Hack Fridays, where you can spend your time diving into a project you're passionate about and get the opportunity to work with other teams-we value your initiatives, impact, and creativity.\n     * Comprehensive health insurance: your health comes first. With our comprehensive insurance, we'll make sure you're covered from head to toe.\n     * 30 days of annual leave: we value your peace of mind. With 30 days off (excluding public holidays) and access to mental health resources, we make sure you're as strong mentally as you are professionally.\n     * Annual learning budget: because we never stop learning, we've set up an annual budget for your professional development-pick a learning path which contributes to your career development and we'll back you up\n       If this role and our mission resonate with you, but you're hesitant because you don't check all the boxes, don't let that hold you back. At DeepL, it's all about the value you bring and the growth we can foster together. Go ahead, apply-let's discover your potential together. We can't wait to meet you!",
        "Datum gevonden": "2024-04-02",
        "Beroepsgroep": "Medewerkers marketing en reclame",
        "Beroepsklasse": "Communicatie, marketing en PR",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Overig / Onbekend",
        "Organisatiegrootte": "Onbekend",
        "Jaar (van datum gevonden)": 2024,
        "Maand (van datum gevonden)": 4,
        "full_text": "Analytics Engineer\n\nAs an Analytics Engineer, your main responsibilities and deliverables will be to build and maintain ETL pipelines, create foundational data models in our data warehouse and integrate new data sources using DataOps best practices, including documentation and testing. You will also support other data specialists in their work to make their queries and tables efficient and their use of data effective., We are looking for a data-focused Analytics Engineer to join a team of versatile engineers that build and maintain data models, libraries and the tooling supporting data processing at DeepL. The data platform combines various data sources, both internal and external, and makes them available to our stakeholders across the company: Developers, Product Development, Data Science and Management. You will work in a cross-functional team with product managers, data scientists, data engineers and developers to solve complex technical challenges. You may work with revenue, customer or usage data and gain an analytical understanding of these datasets., * Collaborate with team members to collect business requirements, define successful outcomes, and design data models\n     * Leverage raw data in our data warehouse to build a curated data models\n     * Write production quality ELT code (Python, SQL) with an eye towards performance and maintainability\n     * Create and maintain architecture and systems documentation\n     * Maintain our data catalog as a scalable resource to support self-service and serve as single source of truth for data definition\n     * Provide data modeling expertise to all team members through code reviews, pair programming, and training to help deliver optimal, DRY, and scalable database designs and queries\n     * Become a domain expert in the data you are work with\n     * Improve, manage, and teach code maintainability and performance standards in code submitted and reviewed\n     * Help our team maintain and improve the infrastructure for data collection, processing, management and analysis\n     * Research, design, implement and drive new solutions and software for solving complex data processing problems across all of DeepL\n     * Work on our internal tools to make the data easily accessible to our internal stakeholders, * Diverse and internationally distributed team: joining our team means becoming part of a large, global community with people of more than 90 nationalities. We're more than just colleagues; we're a group of professionals with a shared mission to connect diverse cultures. Our global presence is growing-we've doubled in size nearly every year, with our employees based in the UK, Germany, the Netherlands, Poland, the US, and Japan, and we continue to expand our network.\n     * Open communication, regular feedback: as a language-focused company, we value the importance of clear, honest communication. We value smooth collaboration, direct and actionable feedback, and believe that leading with empathy makes us better together.\n     * Remote work, flexible hours: whether you're near or in our hubs in cities like Cologne, Berlin, Amsterdam, London, Austin, or Tokyo, or prefer the comfort of your own home, you decide where your office is. We offer remote opportunities, flexible working hours and trust in your productivity, all in sync with your team's general locations and time zones to foster effective and seamless collaboration. Our aim is to integrate your work with your lifestyle, ensuring a balance that respects both your needs and our operational requirements.\n     * Regular in-person team events: we bond over vibrant events that are as unique as our team, from local team and business unit gatherings, to new-joiner onboardings, to company-wide events that bring us all together-literally.\n     * Monthly full-day hacking sessions: every month, we have Hack Fridays, where you can spend your time diving into a project you're passionate about and get the opportunity to work with other teams-we value your initiatives, impact, and creativity.\n     * Comprehensive health insurance: your health comes first. With our comprehensive insurance, we'll make sure you're covered from head to toe.\n     * 30 days of annual leave: we value your peace of mind. With 30 days off (excluding public holidays) and access to mental health resources, we make sure you're as strong mentally as you are professionally.\n     * Annual learning budget: because we never stop learning, we've set up an annual budget for your professional development-pick a learning path which contributes to your career development and we'll back you up\n       If this role and our mission resonate with you, but you're hesitant because you don't check all the boxes, don't let that hold you back. At DeepL, it's all about the value you bring and the growth we can foster together. Go ahead, apply-let's discover your potential together. We can't wait to meet you!"
    },
    "analysis": {
        "profile_classification": {
            "profile": "Ambiguous",
            "rationale": "The job description focuses heavily on data engineering, data modeling, and ETL processes, with a strong emphasis on building and maintaining data infrastructure and pipelines. While it mentions supporting data scientists and working with data, it does not describe the core responsibilities of developing, fine-tuning, or deploying generative AI models, nor does it focus on predictive modeling in the way an ML Engineer would. The role appears to be a traditional data engineering or analytics engineering role, which falls outside the scope of GenAI or ML Engineering as defined in the coding book. Therefore, it is classified as 'Ambiguous' as it is not a technical AI role as defined."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'build and maintain ETL pipelines' directly relates to the process of designing, building, and maintaining data pipelines.",
                    "phrase": "build and maintain ETL pipelines"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'create foundational data models in our data warehouse' describes the process of structuring and organizing data within a data warehouse, a key aspect of data engineering.",
                    "phrase": "create foundational data models in our data warehouse"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'integrate new data sources' involves bringing in data from various origins into the existing data infrastructure.",
                    "phrase": "integrate new data sources"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'DataOps best practices, including documentation and testing' refers to operational practices applied to data management and pipelines.",
                    "phrase": "DataOps best practices, including documentation and testing"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'support other data specialists in their work to make their queries and tables efficient and their use of data effective' implies optimizing data structures and access for other data professionals.",
                    "phrase": "support other data specialists in their work to make their queries and tables efficient and their use of data effective"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'build and maintain data models, libraries and the tooling supporting data processing' encompasses the creation and upkeep of data structures and the systems that process them.",
                    "phrase": "build and maintain data models, libraries and the tooling supporting data processing"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'The data platform combines various data sources, both internal and external, and makes them available to our stakeholders' describes the core function of a data platform, which is a data engineering responsibility.",
                    "phrase": "The data platform combines various data sources, both internal and external, and makes them available to our stakeholders"
                },
                {
                    "category": "TASK1: Business Understanding",
                    "justification": "The phrase 'collect business requirements, define successful outcomes' directly relates to understanding the business context and aligning technical work with business goals.",
                    "phrase": "collect business requirements, define successful outcomes"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "The phrase 'design data models' involves the conceptual and logical structuring of data, which is a form of modeling.",
                    "phrase": "design data models"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'Leverage raw data in our data warehouse to build a curated data models' describes the transformation and structuring of data for analytical purposes.",
                    "phrase": "Leverage raw data in our data warehouse to build a curated data models"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "The phrase 'Write production quality ELT code (Python, SQL) with an eye towards performance and maintainability' involves writing code for data transformation and integration, which falls under software development practices applied to data.",
                    "phrase": "Write production quality ELT code (Python, SQL) with an eye towards performance and maintainability"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'Create and maintain architecture and systems documentation' is crucial for data infrastructure management and understanding.",
                    "phrase": "Create and maintain architecture and systems documentation"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'Maintain our data catalog as a scalable resource to support self-service and serve as single source of truth for data definition' is about managing metadata and data governance, a data engineering task.",
                    "phrase": "Maintain our data catalog as a scalable resource to support self-service and serve as single source of truth for data definition"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "The phrase 'Provide data modeling expertise to all team members through code reviews, pair programming, and training to help deliver optimal, DRY, and scalable database designs and queries' highlights the skill in designing and optimizing database structures.",
                    "phrase": "Provide data modeling expertise to all team members through code reviews, pair programming, and training to help deliver optimal, DRY, and scalable database designs and queries"
                },
                {
                    "category": "TASK1: Business Understanding",
                    "justification": "The phrase 'Become a domain expert in the data you are work with' implies understanding the business context and meaning of the data.",
                    "phrase": "Become a domain expert in the data you are work with"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'Improve, manage, and teach code maintainability and performance standards in code submitted and reviewed' relates to ensuring the quality and efficiency of data processing code.",
                    "phrase": "Improve, manage, and teach code maintainability and performance standards in code submitted and reviewed"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'help our team maintain and improve the infrastructure for data collection, processing, management and analysis' directly addresses the upkeep and enhancement of data systems.",
                    "phrase": "help our team maintain and improve the infrastructure for data collection, processing, management and analysis"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'Research, design, implement and drive new solutions and software for solving complex data processing problems' involves developing new systems for handling data.",
                    "phrase": "Research, design, implement and drive new solutions and software for solving complex data processing problems"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "The phrase 'Work on our internal tools to make the data easily accessible to our internal stakeholders' involves developing software tools for data access.",
                    "phrase": "Work on our internal tools to make the data easily accessible to our internal stakeholders"
                }
            ],
            "soft_skills": [
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "Collaborate with team members"
                },
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "work in a cross-functional team with product managers, data scientists, data engineers and developers"
                },
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "Provide data modeling expertise to all team members through code reviews, pair programming, and training"
                },
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "phrase": "Annual learning budget"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "drive new solutions and software"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "Hack Fridays, where you can spend your time diving into a project you're passionate about"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "solve complex technical challenges"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "solving complex data processing problems"
                }
            ],
            "technologies": [
                {
                    "category": "TECH1: Programming Languages",
                    "phrase": "Python"
                },
                {
                    "category": "TECH1: Programming Languages",
                    "phrase": "SQL"
                }
            ]
        }
    }
}