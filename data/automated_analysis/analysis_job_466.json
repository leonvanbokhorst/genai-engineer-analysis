{
    "job_id": 466,
    "job_details": {
        "job_id": 466,
        "Organisatienaam": "DeepL SE",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "Analytics Engineer",
        "Standplaats": null,
        "Vacaturelink (origineel)": "glassdoor.nl",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Marktanalist (m/v/x)",
        "Opleidingsniveau": "Onbekend",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "As an Analytics Engineer, your main responsibilities and deliverables will be to build and maintain ETL pipelines, create foundational data models in our data warehouse and integrate new data sources using DataOps best practices, including documentation and testing. You will also support other data specialists in their work to make their queries and tables efficient and their use of data effective., We are looking for a data-focused Analytics Engineer to join a team of versatile engineers that build and maintain data models, libraries and the tooling supporting data processing at DeepL. The data platform combines various data sources, both internal and external, and makes them available to our stakeholders across the company: Developers, Product Development, Data Science and Management. You will work in a cross-functional team with product managers, data scientists, data engineers and developers to solve complex technical challenges. You may work with revenue, customer or usage data and gain an analytical understanding of these datasets., * Collaborate with team members to collect business requirements, define successful outcomes, and design data models\n     * Leverage raw data in our data warehouse to build a curated data models\n     * Write production quality ELT code (Python, SQL) with an eye towards performance and maintainability\n     * Create and maintain architecture and systems documentation\n     * Maintain our data catalog as a scalable resource to support self-service and serve as single source of truth for data definition\n     * Provide data modeling expertise to all team members through code reviews, pair programming, and training to help deliver optimal, DRY, and scalable database designs and queries\n     * Become a domain expert in the data you are work with\n     * Improve, manage, and teach code maintainability and performance standards in code submitted and reviewed\n     * Help our team maintain and improve the infrastructure for data collection, processing, management and analysis\n     * Research, design, implement and drive new solutions and software for solving complex data processing problems across all of DeepL\n     * Work on our internal tools to make the data easily accessible to our internal stakeholders, * Diverse and internationally distributed team: joining our team means becoming part of a large, global community with people of more than 90 nationalities. We're more than just colleagues; we're a group of professionals with a shared mission to connect diverse cultures. Our global presence is growing-we've doubled in size nearly every year, with our employees based in the UK, Germany, the Netherlands, Poland, the US, and Japan, and we continue to expand our network.\n     * Open communication, regular feedback: as a language-focused company, we value the importance of clear, honest communication. We value smooth collaboration, direct and actionable feedback, and believe that leading with empathy makes us better together.\n     * Remote work, flexible hours: whether you're near or in our hubs in cities like Cologne, Berlin, Amsterdam, London, Austin, or Tokyo, or prefer the comfort of your own home, you decide where your office is. We offer remote opportunities, flexible working hours and trust in your productivity, all in sync with your team's general locations and time zones to foster effective and seamless collaboration. Our aim is to integrate your work with your lifestyle, ensuring a balance that respects both your needs and our operational requirements.\n     * Regular in-person team events: we bond over vibrant events that are as unique as our team, from local team and business unit gatherings, to new-joiner onboardings, to company-wide events that bring us all together-literally.\n     * Monthly full-day hacking sessions: every month, we have Hack Fridays, where you can spend your time diving into a project you're passionate about and get the opportunity to work with other teams-we value your initiatives, impact, and creativity.\n     * Comprehensive health insurance: your health comes first. With our comprehensive insurance, we'll make sure you're covered from head to toe.\n     * 30 days of annual leave: we value your peace of mind. With 30 days off (excluding public holidays) and access to mental health resources, we make sure you're as strong mentally as you are professionally.\n     * Annual learning budget: because we never stop learning, we've set up an annual budget for your professional development-pick a learning path which contributes to your career development and we'll back you up\n       If this role and our mission resonate with you, but you're hesitant because you don't check all the boxes, don't let that hold you back. At DeepL, it's all about the value you bring and the growth we can foster together. Go ahead, apply-let's discover your potential together. We can't wait to meet you!",
        "Datum gevonden": "2024-04-02",
        "Beroepsgroep": "Medewerkers marketing en reclame",
        "Beroepsklasse": "Communicatie, marketing en PR",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Overig / Onbekend",
        "Organisatiegrootte": "Onbekend",
        "Jaar (van datum gevonden)": 2024,
        "Maand (van datum gevonden)": 4,
        "full_text": "Analytics Engineer\n\nAs an Analytics Engineer, your main responsibilities and deliverables will be to build and maintain ETL pipelines, create foundational data models in our data warehouse and integrate new data sources using DataOps best practices, including documentation and testing. You will also support other data specialists in their work to make their queries and tables efficient and their use of data effective., We are looking for a data-focused Analytics Engineer to join a team of versatile engineers that build and maintain data models, libraries and the tooling supporting data processing at DeepL. The data platform combines various data sources, both internal and external, and makes them available to our stakeholders across the company: Developers, Product Development, Data Science and Management. You will work in a cross-functional team with product managers, data scientists, data engineers and developers to solve complex technical challenges. You may work with revenue, customer or usage data and gain an analytical understanding of these datasets., * Collaborate with team members to collect business requirements, define successful outcomes, and design data models\n     * Leverage raw data in our data warehouse to build a curated data models\n     * Write production quality ELT code (Python, SQL) with an eye towards performance and maintainability\n     * Create and maintain architecture and systems documentation\n     * Maintain our data catalog as a scalable resource to support self-service and serve as single source of truth for data definition\n     * Provide data modeling expertise to all team members through code reviews, pair programming, and training to help deliver optimal, DRY, and scalable database designs and queries\n     * Become a domain expert in the data you are work with\n     * Improve, manage, and teach code maintainability and performance standards in code submitted and reviewed\n     * Help our team maintain and improve the infrastructure for data collection, processing, management and analysis\n     * Research, design, implement and drive new solutions and software for solving complex data processing problems across all of DeepL\n     * Work on our internal tools to make the data easily accessible to our internal stakeholders, * Diverse and internationally distributed team: joining our team means becoming part of a large, global community with people of more than 90 nationalities. We're more than just colleagues; we're a group of professionals with a shared mission to connect diverse cultures. Our global presence is growing-we've doubled in size nearly every year, with our employees based in the UK, Germany, the Netherlands, Poland, the US, and Japan, and we continue to expand our network.\n     * Open communication, regular feedback: as a language-focused company, we value the importance of clear, honest communication. We value smooth collaboration, direct and actionable feedback, and believe that leading with empathy makes us better together.\n     * Remote work, flexible hours: whether you're near or in our hubs in cities like Cologne, Berlin, Amsterdam, London, Austin, or Tokyo, or prefer the comfort of your own home, you decide where your office is. We offer remote opportunities, flexible working hours and trust in your productivity, all in sync with your team's general locations and time zones to foster effective and seamless collaboration. Our aim is to integrate your work with your lifestyle, ensuring a balance that respects both your needs and our operational requirements.\n     * Regular in-person team events: we bond over vibrant events that are as unique as our team, from local team and business unit gatherings, to new-joiner onboardings, to company-wide events that bring us all together-literally.\n     * Monthly full-day hacking sessions: every month, we have Hack Fridays, where you can spend your time diving into a project you're passionate about and get the opportunity to work with other teams-we value your initiatives, impact, and creativity.\n     * Comprehensive health insurance: your health comes first. With our comprehensive insurance, we'll make sure you're covered from head to toe.\n     * 30 days of annual leave: we value your peace of mind. With 30 days off (excluding public holidays) and access to mental health resources, we make sure you're as strong mentally as you are professionally.\n     * Annual learning budget: because we never stop learning, we've set up an annual budget for your professional development-pick a learning path which contributes to your career development and we'll back you up\n       If this role and our mission resonate with you, but you're hesitant because you don't check all the boxes, don't let that hold you back. At DeepL, it's all about the value you bring and the growth we can foster together. Go ahead, apply-let's discover your potential together. We can't wait to meet you!"
    },
    "analysis": {
        "profile_classification": {
            "profile": "Ambiguous / Not Relevant",
            "confidence_score": 2,
            "rationale": "The job description focuses heavily on data engineering, data modeling, and ETL/ELT processes within a data warehouse context. While it mentions supporting data science and product development, it lacks the core responsibilities and technologies associated with ML Engineering or GenAI Engineering, such as algorithm development, model training, or fine-tuning generative models."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "task": "Business Understanding",
                    "phrases": [
                        {
                            "text": "collect business requirements",
                            "justification": "This phrase directly indicates the need to understand and gather requirements from business stakeholders."
                        },
                        {
                            "text": "gain an analytical understanding of these datasets",
                            "justification": "This implies understanding the business context and implications of the data being worked with."
                        },
                        {
                            "text": "solve complex technical challenges",
                            "justification": "While broad, solving complex challenges often requires understanding the underlying business problem they are intended to solve."
                        }
                    ]
                },
                {
                    "task": "Data Engineering",
                    "phrases": [
                        {
                            "text": "build and maintain ETL pipelines",
                            "justification": "This is a core data engineering activity focused on extracting, transforming, and loading data."
                        },
                        {
                            "text": "integrate new data sources",
                            "justification": "This involves the technical process of connecting and incorporating new data into existing systems."
                        },
                        {
                            "text": "DataOps best practices",
                            "justification": "DataOps is a set of practices for data management and data science that aims to improve the speed and quality of data analytics."
                        },
                        {
                            "text": "data processing at DeepL",
                            "justification": "This broadly refers to the engineering tasks involved in handling and managing data."
                        },
                        {
                            "text": "Leverage raw data in our data warehouse",
                            "justification": "This implies working with and transforming raw data, a key aspect of data engineering."
                        },
                        {
                            "text": "Write production quality ELT code",
                            "justification": "ELT (Extract, Load, Transform) is a data engineering pattern, and writing production-quality code is a core engineering task."
                        },
                        {
                            "text": "Maintain our data catalog",
                            "justification": "Data cataloging is an important part of data governance and management, often handled by data engineers."
                        },
                        {
                            "text": "help our team maintain and improve the infrastructure for data collection, processing, management and analysis",
                            "justification": "This explicitly mentions infrastructure related to the data lifecycle, a data engineering responsibility."
                        },
                        {
                            "text": "Research, design, implement and drive new solutions and software for solving complex data processing problems",
                            "justification": "This describes the full lifecycle of developing and implementing data processing solutions."
                        }
                    ]
                },
                {
                    "task": "Modeling",
                    "phrases": [
                        {
                            "text": "create foundational data models",
                            "justification": "This refers to the design and creation of data structures, often within a data warehouse context."
                        },
                        {
                            "text": "design data models",
                            "justification": "This is a direct mention of the process of creating data models."
                        },
                        {
                            "text": "build a curated data models",
                            "justification": "This involves structuring and organizing data into usable models."
                        },
                        {
                            "text": "Provide data modeling expertise",
                            "justification": "This highlights the role's focus on the principles and practices of data modeling."
                        },
                        {
                            "text": "deliver optimal, DRY, and scalable database designs and queries",
                            "justification": "This emphasizes the quality and architectural aspects of data modeling and database design."
                        }
                    ]
                },
                {
                    "task": "Software Development",
                    "phrases": [
                        {
                            "text": "integrate new data sources",
                            "justification": "This involves software integration tasks to bring in new data."
                        },
                        {
                            "text": "Write production quality ELT code (Python, SQL)",
                            "justification": "Writing production-quality code in languages like Python and SQL is a fundamental software development skill applied to data pipelines."
                        },
                        {
                            "text": "internal tools to make the data easily accessible",
                            "justification": "This implies developing software tools for data accessibility."
                        },
                        {
                            "text": "Research, design, implement and drive new solutions and software",
                            "justification": "This covers the software development lifecycle from research to implementation."
                        }
                    ]
                },
                {
                    "task": "Operations Engineering (MLOps)",
                    "phrases": [
                        {
                            "text": "DataOps best practices",
                            "justification": "DataOps is closely related to MLOps, focusing on operational excellence in data pipelines."
                        },
                        {
                            "text": "testing",
                            "justification": "Testing is a crucial part of operations engineering to ensure reliability and quality."
                        },
                        {
                            "text": "maintain ETL pipelines",
                            "justification": "Maintenance of production pipelines falls under operations."
                        },
                        {
                            "text": "maintain foundational data models",
                            "justification": "Ongoing maintenance of data infrastructure components is an operational task."
                        },
                        {
                            "text": "maintain our data catalog",
                            "justification": "Keeping operational systems like data catalogs up-to-date and functional is an operations task."
                        },
                        {
                            "text": "improve, manage, and teach code maintainability and performance standards",
                            "justification": "This relates to ensuring the operational health and efficiency of code and systems."
                        },
                        {
                            "text": "maintain and improve the infrastructure for data collection, processing, management and analysis",
                            "justification": "This explicitly covers the operational aspects of data infrastructure."
                        }
                    ]
                }
            ],
            "technologies": [
                {
                    "tech": "TECH1: Programming Languages",
                    "items": [
                        "Python",
                        "SQL"
                    ]
                },
                {
                    "tech": "TECH10: Data Modeling",
                    "items": [
                        "data models"
                    ]
                },
                {
                    "tech": "TECH6: MLOps & Data Pipelines",
                    "items": [
                        "ETL pipelines",
                        "ELT code",
                        "DataOps"
                    ]
                },
                {
                    "tech": "TECH11: Data Analysis",
                    "items": [
                        "queries",
                        "tables"
                    ]
                },
                {
                    "tech": "TECH9: Data Storage",
                    "items": [
                        "data warehouse"
                    ]
                }
            ],
            "soft_skills": [
                {
                    "skill": "SKILL1: Communication & Collaboration",
                    "phrases": [
                        {
                            "text": "Collaborate with team members"
                        },
                        {
                            "text": "support other data specialists"
                        },
                        {
                            "text": "work in a cross-functional team with product managers, data scientists, data engineers and developers"
                        },
                        {
                            "text": "Provide data modeling expertise to all team members through code reviews, pair programming, and training"
                        },
                        {
                            "text": "Open communication, regular feedback"
                        },
                        {
                            "text": "smooth collaboration, direct and actionable feedback"
                        },
                        {
                            "text": "foster effective and seamless collaboration"
                        }
                    ]
                },
                {
                    "skill": "SKILL2: Learning & Adaptability",
                    "phrases": [
                        {
                            "text": "gain an analytical understanding of these datasets"
                        },
                        {
                            "text": "Become a domain expert in the data you are work with"
                        },
                        {
                            "text": "Annual learning budget"
                        },
                        {
                            "text": "don't check all the boxes, don't let that hold you back. At DeepL, it's all about the value you bring and the growth we can foster together."
                        }
                    ]
                },
                {
                    "skill": "SKILL3: Problem Solving & Pragmatism",
                    "phrases": [
                        {
                            "text": "solve complex technical challenges"
                        },
                        {
                            "text": "Research, design, implement and drive new solutions and software for solving complex data processing problems"
                        },
                        {
                            "text": "make their queries and tables efficient and their use of data effective"
                        },
                        {
                            "text": "eye towards performance and maintainability"
                        },
                        {
                            "text": "deliver optimal, DRY, and scalable database designs and queries"
                        },
                        {
                            "text": "Improve, manage, and teach code maintainability and performance standards"
                        }
                    ]
                },
                {
                    "skill": "SKILL5: Innovation & Ownership",
                    "phrases": [
                        {
                            "text": "drive new solutions and software"
                        },
                        {
                            "text": "Hack Fridays, where you can spend your time diving into a project you're passionate about"
                        },
                        {
                            "text": "we value your initiatives, impact, and creativity"
                        },
                        {
                            "text": "it's all about the value you bring and the growth we can foster together."
                        }
                    ]
                }
            ]
        }
    }
}