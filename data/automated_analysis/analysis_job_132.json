{
    "job_id": 132,
    "job_details": {
        "job_id": 132,
        "Organisatienaam": "Synthesia",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "DataOps Engineer",
        "Standplaats": "Amsterdam",
        "Vacaturelink (origineel)": "startup.jobs",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Data engineer (m/v/x)",
        "Opleidingsniveau": "Onbekend",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "We are looking for a DataOps Platform Engineer to help R&D manage large data-sets of audio-video data at Synthesia. We are creating a new ML Platform team, that will be supporting 7+ teams developing cutting edge solutions in generative video synthesis. You will join us to set up a world class data function, managing a lake with PB scale data and building complex audio/visual data pipelines to bring order and make data consumption simple. You are going to super-charge our research., In this position, you will be working alongside our Senior DataOps Engineer to help streamline our ML development process with access to large scale datasets for our ML teams in R&D at Synthesia. You will help set up our audio-video data pipeline for the Video team and our speech data pipeline for the Voice team. You will be responsible for:\n     * Data Ops for data management, versioning, usage tracking, logging.\n     * Setup of a data-lake and data transform pipelines for large scale audio-visual datasets.\n     * Integration of 3d party annotation services for continuous data annotation and active learning.\n     * Setup of metadata stores and APIs to access data-sets on demand for ML training.\n     * Support for data streaming to train large models.\n     * Data pipelines - deploy custom ML data transformations, working with our ML team.\n     * Data access - create transient data-sets on demand to support ML model training.\n     * Data tracking - usage tracking and monitoring across all data sources.\n     * Establish the workflow for continual data delivery and annotation.",
        "Datum gevonden": "2023-04-28",
        "Beroepsgroep": "Systeemontwikkelaars en -analisten",
        "Beroepsklasse": "Informatie- en communicatietechnologie",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Cultuur / Recreatie",
        "Organisatiegrootte": "1-9",
        "Jaar (van datum gevonden)": 2023,
        "Maand (van datum gevonden)": 4,
        "full_text": "DataOps Engineer\n\nWe are looking for a DataOps Platform Engineer to help R&D manage large data-sets of audio-video data at Synthesia. We are creating a new ML Platform team, that will be supporting 7+ teams developing cutting edge solutions in generative video synthesis. You will join us to set up a world class data function, managing a lake with PB scale data and building complex audio/visual data pipelines to bring order and make data consumption simple. You are going to super-charge our research., In this position, you will be working alongside our Senior DataOps Engineer to help streamline our ML development process with access to large scale datasets for our ML teams in R&D at Synthesia. You will help set up our audio-video data pipeline for the Video team and our speech data pipeline for the Voice team. You will be responsible for:\n     * Data Ops for data management, versioning, usage tracking, logging.\n     * Setup of a data-lake and data transform pipelines for large scale audio-visual datasets.\n     * Integration of 3d party annotation services for continuous data annotation and active learning.\n     * Setup of metadata stores and APIs to access data-sets on demand for ML training.\n     * Support for data streaming to train large models.\n     * Data pipelines - deploy custom ML data transformations, working with our ML team.\n     * Data access - create transient data-sets on demand to support ML model training.\n     * Data tracking - usage tracking and monitoring across all data sources.\n     * Establish the workflow for continual data delivery and annotation."
    },
    "analysis": {
        "profile_classification": {
            "profile": "ML Engineer",
            "rationale": "The job description emphasizes managing large datasets, building complex data pipelines, and supporting ML teams, aligning with the core responsibilities of an ML Engineer focused on data engineering, modeling support, and MLOps. While generative models are mentioned in the context of the teams being supported, the primary focus of this role is on the data infrastructure and pipelines that enable ML development, rather than the direct development or fine-tuning of generative models themselves."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The role involves managing large datasets, building complex audio/visual data pipelines, setting up a data lake, and creating data transform pipelines, all of which are core to data engineering.",
                    "phrase": "manage large data-sets of audio-video data"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The description explicitly mentions building complex audio/visual data pipelines to organize and simplify data consumption.",
                    "phrase": "building complex audio/visual data pipelines"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The role involves setting up a data lake and data transformation pipelines for large-scale datasets.",
                    "phrase": "Setup of a data-lake and data transform pipelines for large scale audio-visual datasets."
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The role requires setting up metadata stores and APIs for on-demand data access, which is crucial for data engineering in ML contexts.",
                    "phrase": "Setup of metadata stores and APIs to access data-sets on demand for ML training."
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The job involves supporting data streaming for training large models, which is a data engineering responsibility.",
                    "phrase": "Support for data streaming to train large models."
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The role includes deploying custom ML data transformations, a key aspect of data engineering for ML.",
                    "phrase": "Data pipelines - deploy custom ML data transformations"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Creating transient datasets on demand for ML model training is a data engineering task focused on providing specific data for modeling.",
                    "phrase": "Data access - create transient data-sets on demand to support ML model training."
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Usage tracking and monitoring across data sources falls under data management and engineering responsibilities.",
                    "phrase": "Data tracking - usage tracking and monitoring across all data sources."
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Establishing workflows for continual data delivery and annotation is a data engineering process.",
                    "phrase": "Establish the workflow for continual data delivery and annotation."
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "The role includes 'Data Ops for data management, versioning, usage tracking, logging,' which aligns with the operational aspects of managing data for ML systems.",
                    "phrase": "Data Ops for data management, versioning, usage tracking, logging."
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Integrating third-party annotation services for continuous data annotation and active learning is an operational task that supports the ML lifecycle.",
                    "phrase": "Integration of 3d party annotation services for continuous data annotation and active learning."
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "The role involves setting up APIs to access datasets, which is a software development task to enable data access.",
                    "phrase": "Setup of metadata stores and APIs to access data-sets on demand for ML training."
                },
                {
                    "category": "TASK1: Business Understanding",
                    "justification": "The role aims to 'super-charge our research' and 'streamline our ML development process,' indicating an understanding of how data operations support business and R&D goals.",
                    "phrase": "You will join us to set up a world class data function, managing a lake with PB scale data and building complex audio/visual data pipelines to bring order and make data consumption simple. You are going to super-charge our research."
                }
            ],
            "soft_skills": [
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "help streamline our ML development process"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "building complex audio/visual data pipelines to bring order and make data consumption simple"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "set up a world class data function"
                },
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "working alongside our Senior DataOps Engineer"
                }
            ],
            "technologies": [
                {
                    "category": "TECH2: Cloud Platforms & Services",
                    "phrase": "PB scale data"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "ML training"
                }
            ]
        }
    }
}