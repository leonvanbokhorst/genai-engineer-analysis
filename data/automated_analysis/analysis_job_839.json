{
    "job_id": 839,
    "job_details": {
        "job_id": 839,
        "Organisatienaam": "Barrington James",
        "Type adverteerder": "Intermediair",
        "Vacaturetitel": "Data Engineer",
        "Standplaats": "Amsterdam",
        "Vacaturelink (origineel)": "barringtonjames.com",
        "Contactpersoon": "Joe Templeman",
        "Telefoonnummer": "31441293776644.0",
        "E-mail": "jtempleman@barringtonjames.com",
        "Beroep": "Data engineer (m/v/x)",
        "Opleidingsniveau": "HBO",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "They are looking for an experienced Senior Data Engineer to design, develop, and maintain a robust data infrastructure for their oncology-focused AI platform. You will play a key role in architecting and scaling a high-performance data platform that supports multimodal data processing, data lake architecture, and machine learning pipelines, all within a secure, scalable, and cloud-based environment., Architect, build, and maintain scalable data pipelines and infrastructure that support multimodal data for oncology AI models.\n   Develop and optimize data workflows for ingesting, transforming, and processing diverse oncology-related data (e.g., medical imaging, genomics, clinical data) using Apache Spark and Python.\n   Design and manage data storage, processing, and orchestration on Azure, ensuring reliability, security, and scalability.\n   Utilize Terraform to automate infrastructure provisioning and deployment, ensuring repeatability and reducing manual configurations.\n   Implement and manage Kubernetes clusters for deploying and managing data workflows and model training pipelines.\n   Work closely with data scientists, ML engineers, and product teams to understand data requirements and provide end-to-end support on data ingestion, transformation, and accessibility.\n   Monitor and fine-tune the data pipelines to improve efficiency, reduce latency, and optimize resource usage.\n   Document data pipeline architecture, transformations, and ensure adherence to industry standards and compliance requirements in healthcare data handling (e.g., HIPAA, GDPR).",
        "Datum gevonden": "2025-01-29",
        "Beroepsgroep": "Systeemontwikkelaars en -analisten",
        "Beroepsklasse": "Informatie- en communicatietechnologie",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Arbeidsbemiddeling",
        "Organisatiegrootte": "Onbekend",
        "Jaar (van datum gevonden)": 2025,
        "Maand (van datum gevonden)": 1,
        "full_text": "Data Engineer\n\nThey are looking for an experienced Senior Data Engineer to design, develop, and maintain a robust data infrastructure for their oncology-focused AI platform. You will play a key role in architecting and scaling a high-performance data platform that supports multimodal data processing, data lake architecture, and machine learning pipelines, all within a secure, scalable, and cloud-based environment., Architect, build, and maintain scalable data pipelines and infrastructure that support multimodal data for oncology AI models.\n   Develop and optimize data workflows for ingesting, transforming, and processing diverse oncology-related data (e.g., medical imaging, genomics, clinical data) using Apache Spark and Python.\n   Design and manage data storage, processing, and orchestration on Azure, ensuring reliability, security, and scalability.\n   Utilize Terraform to automate infrastructure provisioning and deployment, ensuring repeatability and reducing manual configurations.\n   Implement and manage Kubernetes clusters for deploying and managing data workflows and model training pipelines.\n   Work closely with data scientists, ML engineers, and product teams to understand data requirements and provide end-to-end support on data ingestion, transformation, and accessibility.\n   Monitor and fine-tune the data pipelines to improve efficiency, reduce latency, and optimize resource usage.\n   Document data pipeline architecture, transformations, and ensure adherence to industry standards and compliance requirements in healthcare data handling (e.g., HIPAA, GDPR)."
    },
    "analysis": {
        "profile_classification": {
            "profile": "ML Engineer",
            "rationale": "The job description heavily emphasizes data engineering tasks such as designing, building, and maintaining data pipelines and infrastructure, data ingestion, transformation, and processing using tools like Apache Spark and Python. It also mentions supporting machine learning pipelines, data lake architecture, and working with data scientists and ML engineers. While it mentions cloud platforms and Kubernetes, the core focus remains on data infrastructure and supporting ML models, aligning more closely with the 'ML Engineer' profile's emphasis on data engineering and productionizing models, rather than the 'GenAI Engineer' profile's focus on generative models and user-facing applications."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The job description explicitly states 'design, develop, and maintain a robust data infrastructure', 'architecting and scaling a high-performance data platform that supports multimodal data processing, data lake architecture, and machine learning pipelines', 'Architect, build, and maintain scalable data pipelines and infrastructure', and 'Develop and optimize data workflows for ingesting, transforming, and processing diverse oncology-related data'.",
                    "phrase": "design, develop, and maintain a robust data infrastructure"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The description details the need to 'ingest, transform, and process diverse oncology-related data (e.g., medical imaging, genomics, clinical data) using Apache Spark and Python'.",
                    "phrase": "ingesting, transforming, and processing diverse oncology-related data"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The role involves 'Design and manage data storage, processing, and orchestration on Azure, ensuring reliability, security, and scalability.'",
                    "phrase": "Design and manage data storage, processing, and orchestration"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "The use of 'Terraform to automate infrastructure provisioning and deployment' and 'Kubernetes clusters for deploying and managing data workflows and model training pipelines' falls under operations and infrastructure management for ML/data pipelines.",
                    "phrase": "Utilize Terraform to automate infrastructure provisioning and deployment"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "The mention of 'Implement and manage Kubernetes clusters for deploying and managing data workflows and model training pipelines' is a clear indicator of MLOps practices.",
                    "phrase": "Implement and manage Kubernetes clusters for deploying and managing data workflows and model training pipelines"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "While the primary focus is data infrastructure, the role involves working with 'data scientists, ML engineers, and product teams to understand data requirements and provide end-to-end support on data ingestion, transformation, and accessibility', which implies building and integrating data solutions within a larger software ecosystem.",
                    "phrase": "Work closely with data scientists, ML engineers, and product teams to understand data requirements and provide end-to-end support on data ingestion, transformation, and accessibility"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "The task 'Monitor and fine-tune the data pipelines to improve efficiency, reduce latency, and optimize resource usage' is a core aspect of MLOps and pipeline optimization.",
                    "phrase": "Monitor and fine-tune the data pipelines to improve efficiency, reduce latency, and optimize resource usage"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The requirement to 'Document data pipeline architecture, transformations, and ensure adherence to industry standards and compliance requirements in healthcare data handling (e.g., HIPAA, GDPR)' relates to the design and maintenance of data systems.",
                    "phrase": "Document data pipeline architecture, transformations, and ensure adherence to industry standards and compliance requirements in healthcare data handling"
                }
            ],
            "soft_skills": [
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "Work closely with data scientists, ML engineers, and product teams"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "Monitor and fine-tune the data pipelines to improve efficiency, reduce latency, and optimize resource usage"
                },
                {
                    "category": "SKILL4: Ethical & Legal Responsibility",
                    "phrase": "ensure adherence to industry standards and compliance requirements in healthcare data handling (e.g., HIPAA, GDPR)"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "design, develop, and maintain a robust data infrastructure"
                }
            ],
            "technologies": [
                {
                    "category": "TECH1: Programming Languages",
                    "phrase": "Python"
                },
                {
                    "category": "TECH2: Cloud Platforms & Services",
                    "phrase": "Azure"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "Apache Spark"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "Terraform"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "Kubernetes"
                }
            ]
        }
    }
}