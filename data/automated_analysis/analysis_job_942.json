{
    "job_id": 942,
    "job_details": {
        "job_id": 942,
        "Organisatienaam": "NVIDIA",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "Senior Performance Research and Analysis Engineer",
        "Standplaats": "Zwolle",
        "Vacaturelink (origineel)": "engineering.jobs",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "R&D ingenieur (m/v/x)",
        "Opleidingsniveau": "WO",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "NVIDIA is looking for a talented Performance Research Engineer to join our Performance group.\n\n   The ideal candidate will profile and analyze AI workloads on large GPUs and CPUs scale clusters for distributed Deep Learning LLM training focusing at the collectives communication and networking.\n\n   You will work and interact with many types of HW and platforms such as HCAs, Switches, CPUs, GPUs, and Systems.\n\n   You will experience with and develop performance analysis tools and methodologies to dive deeply into the details, understand performance expectation, limitations, and bottlenecks.\n\n   What you'll be doing:\n     * Experience and research AI workloads and DL models specifically tailored for large-scale deep learning LLM training on NVIDIA supercomputers with a focus on High-performance networking.\n     * Benchmarking, Profiling, and Analyzing the performance to find bottlenecks and identify areas of improvement and optimizations, with a strong emphasis on networking aspects.\n     * Implement performance analysis tools.\n     * Collaborating with many teams from HW to SW to provide performance analysis insights.\n     * Define performance test planning , set performance expectations for new technologies and solutions, and work to reach the performance targets limits.\n\n   What we need to see:\n     * B.Sc in Computer Science or Software Engineering\n     * 5+ years of experience with high-performance Networking (RDMA, MPI)\n     * Demonstrated Performance Analysis skills and methodologies.\n     * Experience with NVIDIA GPUs, CUDA library, deep learning frameworks like TensorFlow or PyTorch,\n       combined with expertise in networking collective communication libraries (such as NCCL) and protocols (such as RoCE and RDMA).\n     * Fast and self-learning capabilities with strong analytical and problem-solving skills.\n     * Programming Languages: Python, Bash and C languages\n     * Experience with Linux OS distros.\n     * Team player with good communication and interpersonal skills\n\n   Ways to stand out from the crowd:\n     * In-depth knowledge and experience with AI workloads and benchmarking for distributed LLM training.\n     * Knowledge in CUDA, and NCCL libraries.\n     * Knowledge in Congestion Control algorithms.\n     * In-depth System knowledge and understanding (Intel / AMD / ARM CPUs, NVIDIA GPUs, HCA, Memory, PCI).\n     * Strong Performance Analysis skills and methodologies using modern tools.\n\n   NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) based on race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",
        "Datum gevonden": "2024-11-26",
        "Beroepsgroep": "Bedrijfskundig ingenieurs en deskundigen",
        "Beroepsklasse": "Engineering",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Overig / Onbekend",
        "Organisatiegrootte": "Onbekend",
        "Jaar (van datum gevonden)": 2024,
        "Maand (van datum gevonden)": 11,
        "full_text": "Senior Performance Research and Analysis Engineer\n\nNVIDIA is looking for a talented Performance Research Engineer to join our Performance group.\n\n   The ideal candidate will profile and analyze AI workloads on large GPUs and CPUs scale clusters for distributed Deep Learning LLM training focusing at the collectives communication and networking.\n\n   You will work and interact with many types of HW and platforms such as HCAs, Switches, CPUs, GPUs, and Systems.\n\n   You will experience with and develop performance analysis tools and methodologies to dive deeply into the details, understand performance expectation, limitations, and bottlenecks.\n\n   What you'll be doing:\n     * Experience and research AI workloads and DL models specifically tailored for large-scale deep learning LLM training on NVIDIA supercomputers with a focus on High-performance networking.\n     * Benchmarking, Profiling, and Analyzing the performance to find bottlenecks and identify areas of improvement and optimizations, with a strong emphasis on networking aspects.\n     * Implement performance analysis tools.\n     * Collaborating with many teams from HW to SW to provide performance analysis insights.\n     * Define performance test planning , set performance expectations for new technologies and solutions, and work to reach the performance targets limits.\n\n   What we need to see:\n     * B.Sc in Computer Science or Software Engineering\n     * 5+ years of experience with high-performance Networking (RDMA, MPI)\n     * Demonstrated Performance Analysis skills and methodologies.\n     * Experience with NVIDIA GPUs, CUDA library, deep learning frameworks like TensorFlow or PyTorch,\n       combined with expertise in networking collective communication libraries (such as NCCL) and protocols (such as RoCE and RDMA).\n     * Fast and self-learning capabilities with strong analytical and problem-solving skills.\n     * Programming Languages: Python, Bash and C languages\n     * Experience with Linux OS distros.\n     * Team player with good communication and interpersonal skills\n\n   Ways to stand out from the crowd:\n     * In-depth knowledge and experience with AI workloads and benchmarking for distributed LLM training.\n     * Knowledge in CUDA, and NCCL libraries.\n     * Knowledge in Congestion Control algorithms.\n     * In-depth System knowledge and understanding (Intel / AMD / ARM CPUs, NVIDIA GPUs, HCA, Memory, PCI).\n     * Strong Performance Analysis skills and methodologies using modern tools.\n\n   NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) based on race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law."
    },
    "analysis": {
        "profile_classification": {
            "profile": "ML Engineer",
            "rationale": "The job description heavily emphasizes profiling, analyzing, and optimizing AI workloads, specifically large-scale deep learning LLM training, with a focus on distributed systems, communication, and networking. While it mentions LLMs, the core tasks revolve around performance analysis, bottleneck identification, and optimization of existing models and infrastructure, aligning with the 'ML Engineer' profile's focus on building and maintaining production-grade systems and optimizing models, rather than developing novel generative AI applications or advanced prompt engineering, which are central to the 'GenAI Engineer' profile."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "category": "TASK3: Modeling",
                    "justification": "The job involves researching AI workloads and DL models specifically tailored for large-scale deep learning LLM training, which directly relates to the creation, adaptation, and optimization of models.",
                    "phrase": "research AI workloads and DL models specifically tailored for large-scale deep learning LLM training"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "Benchmarking, profiling, and analyzing performance to find bottlenecks and identify areas for improvement and optimization are core activities in model performance tuning.",
                    "phrase": "Benchmarking, Profiling, and Analyzing the performance to find bottlenecks and identify areas of improvement and optimizations"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "Implementing performance analysis tools requires software development skills to create and maintain the necessary utilities.",
                    "phrase": "Implement performance analysis tools"
                },
                {
                    "category": "TASK1: Business Understanding",
                    "justification": "Collaborating with various teams (HW to SW) to provide performance analysis insights requires understanding the impact of performance on different parts of the system and business.",
                    "phrase": "Collaborating with many teams from HW to SW to provide performance analysis insights"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Defining performance test planning, setting performance expectations, and working to reach performance targets are crucial aspects of ensuring models and systems perform as expected in a production-like environment.",
                    "phrase": "Define performance test planning , set performance expectations for new technologies and solutions, and work to reach the performance targets limits"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "The phrase 'distributed Deep Learning LLM training' directly points to the core activity of training and optimizing deep learning models.",
                    "phrase": "distributed Deep Learning LLM training"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "The role involves working with and developing performance analysis tools and methodologies, which falls under software development.",
                    "phrase": "develop performance analysis tools and methodologies"
                }
            ],
            "soft_skills": [
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "phrase": "Fast and self-learning capabilities"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "strong analytical and problem-solving skills"
                },
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "Team player with good communication and interpersonal skills"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "research AI workloads"
                }
            ],
            "technologies": [
                {
                    "category": "TECH3: LLM / Generative Models",
                    "phrase": "LLM"
                },
                {
                    "category": "TECH1: Programming Languages",
                    "phrase": "Python"
                },
                {
                    "category": "TECH1: Programming Languages",
                    "phrase": "Bash"
                },
                {
                    "category": "TECH1: Programming Languages",
                    "phrase": "C languages"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "deep learning frameworks"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "TensorFlow"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "PyTorch"
                },
                {
                    "category": "TECH2: Cloud Platforms & Services",
                    "phrase": "NVIDIA GPUs"
                },
                {
                    "category": "TECH2: Cloud Platforms & Services",
                    "phrase": "CUDA library"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "NCCL"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "RDMA"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "MPI"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "RoCE"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "networking collective communication libraries"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "Congestion Control algorithms"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "HCAs"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "Switches"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "CPUs"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "Systems"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "Linux OS distros"
                }
            ]
        }
    }
}