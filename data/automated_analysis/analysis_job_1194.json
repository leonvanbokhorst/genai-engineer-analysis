{
    "job_id": 1194,
    "job_details": {
        "job_id": 1194,
        "Organisatienaam": "Eindhoven University of Technology",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "AI/ML Application Support Engineer",
        "Standplaats": null,
        "Vacaturelink (origineel)": "tue.nl",
        "Contactpersoon": "Richard Zoontjens",
        "Telefoonnummer": null,
        "E-mail": "r.j.zoontjens@tue.nl",
        "Beroep": "Helpdeskmedewerker informatietechnologie (m/v/x)",
        "Opleidingsniveau": "Onbekend",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "For the TU/e HPC Lab, we are looking for a proactive, service-minded, and self-driven AI/ML Application Support Engineer who will help us build and professionalize this innovative service. Do you want to rise above yourself, in your profession, and as a person? Do you want to be challenged every day? At the TU/e, scientists and students continuously create the unthinkable. These creative minds expect you to offer them a solution for tomorrow that doesn't exist today.\n\n   You will closely work with researchers, students of all departments, and TU/e institutes as well as with industry partners. You have AI and HPC infrastructure engineering know-how, but your focus and interest are on the application and workflow side. You will work in a team of highly motivated experts and can help us shape the future of our university, scientists, and students.\n\n   The job entails:\n     * Assisting researchers and students to efficiently deploy scientific workloads on the various AI platforms (NVIDIA DGX B200, local clusters, SURF, Azure and Rescale)\n     * Working with researchers to understand and optimize their application (benchmarking, code optimization)\n     * Optimizing application workflows and pipelines (training/inferencing, pre-processing, simulation, post-processing, data storage, etc.) to make the best use of a given platform\n     * Benchmarking and administration/accounting of workloads\n     * Training and communication for end-users",
        "Datum gevonden": "2024-07-15",
        "Beroepsgroep": "Supportmedewerkers",
        "Beroepsklasse": "Informatie- en communicatietechnologie",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Onderwijs / Onderzoek",
        "Organisatiegrootte": "1000+",
        "Jaar (van datum gevonden)": 2024,
        "Maand (van datum gevonden)": 7,
        "full_text": "AI/ML Application Support Engineer\n\nFor the TU/e HPC Lab, we are looking for a proactive, service-minded, and self-driven AI/ML Application Support Engineer who will help us build and professionalize this innovative service. Do you want to rise above yourself, in your profession, and as a person? Do you want to be challenged every day? At the TU/e, scientists and students continuously create the unthinkable. These creative minds expect you to offer them a solution for tomorrow that doesn't exist today.\n\n   You will closely work with researchers, students of all departments, and TU/e institutes as well as with industry partners. You have AI and HPC infrastructure engineering know-how, but your focus and interest are on the application and workflow side. You will work in a team of highly motivated experts and can help us shape the future of our university, scientists, and students.\n\n   The job entails:\n     * Assisting researchers and students to efficiently deploy scientific workloads on the various AI platforms (NVIDIA DGX B200, local clusters, SURF, Azure and Rescale)\n     * Working with researchers to understand and optimize their application (benchmarking, code optimization)\n     * Optimizing application workflows and pipelines (training/inferencing, pre-processing, simulation, post-processing, data storage, etc.) to make the best use of a given platform\n     * Benchmarking and administration/accounting of workloads\n     * Training and communication for end-users"
    },
    "analysis": {
        "profile_classification": {
            "profile": "ML Engineer",
            "rationale": "The job description emphasizes assisting researchers with deploying scientific workloads, optimizing application workflows and pipelines, and benchmarking. While generative AI technologies are not explicitly mentioned, the focus on optimizing training/inferencing, pre-processing, and data storage, along with the mention of MLOps-related tasks like administration/accounting of workloads, aligns more closely with the core responsibilities of an ML Engineer focused on productionizing and optimizing models and applications within an HPC environment. The role is less about building new generative models or applications and more about supporting and optimizing existing scientific workloads."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "category": "TASK3: Modeling",
                    "justification": "The phrase 'optimize their application (benchmarking, code optimization)' and 'Optimizing application workflows and pipelines (training/inferencing, pre-processing, simulation, post-processing, data storage, etc.)' directly relates to the process of improving and fine-tuning machine learning models and their associated processes.",
                    "phrase": "optimize their application (benchmarking, code optimization)"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "The phrase 'Optimizing application workflows and pipelines (training/inferencing, pre-processing, simulation, post-processing, data storage, etc.)' describes the core activities involved in refining and enhancing the performance of machine learning models and their data handling processes.",
                    "phrase": "Optimizing application workflows and pipelines (training/inferencing, pre-processing, simulation, post-processing, data storage, etc.)"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "The phrase 'Assisting researchers and students to efficiently deploy scientific workloads on the various AI platforms' implies supporting the integration and operationalization of AI/ML applications within specific infrastructure, which is a software development related task in the context of deployment.",
                    "phrase": "Assisting researchers and students to efficiently deploy scientific workloads on the various AI platforms"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "The phrase 'Benchmarking and administration/accounting of workloads' directly relates to the operational aspects of managing and monitoring computational resources and tasks, which is a key component of MLOps.",
                    "phrase": "Benchmarking and administration/accounting of workloads"
                },
                {
                    "category": "TASK1: Business Understanding",
                    "justification": "The phrase 'Training and communication for end-users' indicates a need to understand the users' requirements and effectively convey technical information, aligning with business understanding and stakeholder management.",
                    "phrase": "Training and communication for end-users"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'Optimizing application workflows and pipelines (training/inferencing, pre-processing, simulation, post-processing, data storage, etc.)' includes 'pre-processing' and 'data storage', which are core components of data engineering.",
                    "phrase": "Optimizing application workflows and pipelines (training/inferencing, pre-processing, simulation, post-processing, data storage, etc.)"
                }
            ],
            "soft_skills": [
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "proactive, service-minded, and self-driven"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "proactive, service-minded, and self-driven"
                },
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "phrase": "rise above yourself, in your profession, and as a person? Do you want to be challenged every day?"
                },
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "closely work with researchers, students of all departments, and TU/e institutes as well as with industry partners."
                },
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "Training and communication for end-users"
                }
            ],
            "technologies": [
                {
                    "category": "TECH2: Cloud Platforms & Services",
                    "phrase": "Azure"
                },
                {
                    "category": "TECH2: Cloud Platforms & Services",
                    "phrase": "SURF"
                },
                {
                    "category": "TECH2: Cloud Platforms & Services",
                    "phrase": "Rescale"
                },
                {
                    "category": "TECH2: Cloud Platforms & Services",
                    "phrase": "NVIDIA DGX B200"
                }
            ]
        }
    }
}