{
    "job_id": 387,
    "job_details": {
        "job_id": 387,
        "Organisatienaam": "AKZO Nobel",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "Engineer AI Job",
        "Standplaats": "Amsterdam",
        "Vacaturelink (origineel)": "nationalevacaturebank.nl",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Engineer (overig) (m/v/x)",
        "Opleidingsniveau": "HBO",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "* Collaborate with business, architects and demand and project managers to understand company needs and devise possible AI / model based solutions.\n   * Build scalable AI solutions in a cloud environment (Databricks) using python and Apache spark.\n   * Develop projects through proof-of-concept, pilot and full deployment phases.\n   * Further develop the AI components in our data platform to improve our technical infrastructure, standards of working and tool stack.\n   * Integrate the final model with other aspects of the application; design and control how they communicate with one another (REST APIs, database queries, etc..).\n   * Communicate results and ideas to key stakeholders; explain complex use cases at an appropriate level for the audience using effective data visualization techniques.\n   * Experiment with new ideas, technologies and data to stay posted on the latest developments and identify new use cases to leverage them.",
        "Datum gevonden": "2024-05-18",
        "Beroepsgroep": "Engineering (overig)",
        "Beroepsklasse": "Engineering",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Pharma / Chemie",
        "Organisatiegrootte": "1000+",
        "Jaar (van datum gevonden)": 2024,
        "Maand (van datum gevonden)": 5,
        "full_text": "Engineer AI Job\n\n* Collaborate with business, architects and demand and project managers to understand company needs and devise possible AI / model based solutions.\n   * Build scalable AI solutions in a cloud environment (Databricks) using python and Apache spark.\n   * Develop projects through proof-of-concept, pilot and full deployment phases.\n   * Further develop the AI components in our data platform to improve our technical infrastructure, standards of working and tool stack.\n   * Integrate the final model with other aspects of the application; design and control how they communicate with one another (REST APIs, database queries, etc..).\n   * Communicate results and ideas to key stakeholders; explain complex use cases at an appropriate level for the audience using effective data visualization techniques.\n   * Experiment with new ideas, technologies and data to stay posted on the latest developments and identify new use cases to leverage them."
    },
    "analysis": {
        "profile_classification": {
            "profile": "ML Engineer",
            "confidence_score": 4,
            "rationale": "The job description emphasizes building scalable AI solutions, developing projects through full deployment phases, and integrating models with existing systems via APIs. While generative AI is not explicitly mentioned, the focus on data platform development, model integration, and cloud-based solutions aligns strongly with the core responsibilities of an ML Engineer."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "task": "TASK1: Business Understanding",
                    "phrases": [
                        "Collaborate with business, architects and demand and project managers to understand company needs and devise possible AI / model based solutions."
                    ],
                    "justification": "This phrase directly indicates collaboration with business stakeholders to understand needs and translate them into technical solutions."
                },
                {
                    "task": "TASK2: Data Engineering",
                    "phrases": [
                        "Build scalable AI solutions in a cloud environment (Databricks) using python and Apache spark.",
                        "Further develop the AI components in our data platform to improve our technical infrastructure, standards of working and tool stack."
                    ],
                    "justification": "Building solutions in a cloud environment with specific data processing tools (Spark) and developing components within a data platform points to data engineering activities."
                },
                {
                    "task": "TASK3: Modeling",
                    "phrases": [
                        "devise possible AI / model based solutions.",
                        "Develop projects through proof-of-concept, pilot and full deployment phases."
                    ],
                    "justification": "The mention of 'model based solutions' and developing projects through various deployment phases implies the creation and refinement of models."
                },
                {
                    "task": "TASK4: Software Development",
                    "phrases": [
                        "Integrate the final model with other aspects of the application; design and control how they communicate with one another (REST APIs, database queries, etc..)."
                    ],
                    "justification": "Integrating models with applications and designing communication mechanisms like REST APIs are core software development tasks."
                },
                {
                    "task": "TASK5: Operations Engineering (MLOps)",
                    "phrases": [
                        "Build scalable AI solutions in a cloud environment (Databricks) using python and Apache spark.",
                        "Develop projects through proof-of-concept, pilot and full deployment phases."
                    ],
                    "justification": "Building scalable solutions in a cloud environment and taking projects through full deployment phases are indicative of MLOps practices."
                }
            ],
            "technologies": [
                {
                    "technology": "Databricks",
                    "category": "TECH2: Cloud Platforms & Services"
                },
                {
                    "technology": "python",
                    "category": "TECH1: Programming Languages"
                },
                {
                    "technology": "Apache spark",
                    "category": "TECH11: Data Analysis"
                },
                {
                    "technology": "REST APIs",
                    "category": "TECH4: LLM Frameworks & Libraries"
                }
            ],
            "soft_skills": [
                {
                    "skill": "SKILL1: Communication & Collaboration",
                    "phrases": [
                        "Collaborate with business, architects and demand and project managers to understand company needs and devise possible AI / model based solutions.",
                        "Communicate results and ideas to key stakeholders; explain complex use cases at an appropriate level for the audience using effective data visualization techniques."
                    ]
                },
                {
                    "skill": "SKILL2: Learning & Adaptability",
                    "phrases": [
                        "Experiment with new ideas, technologies and data to stay posted on the latest developments and identify new use cases to leverage them."
                    ]
                },
                {
                    "skill": "SKILL3: Problem Solving & Pragmatism",
                    "phrases": [
                        "devise possible AI / model based solutions.",
                        "Develop projects through proof-of-concept, pilot and full deployment phases."
                    ]
                },
                {
                    "skill": "SKILL5: Innovation & Ownership",
                    "phrases": [
                        "Experiment with new ideas, technologies and data to stay posted on the latest developments and identify new use cases to leverage them."
                    ]
                }
            ]
        }
    }
}