{
    "job_id": 77,
    "job_details": {
        "job_id": 77,
        "Organisatienaam": "Nebius",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "ML Engineer, Large Language Models",
        "Standplaats": "Amsterdam",
        "Vacaturelink (origineel)": "glassdoor.nl",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Engineer (overig) (m/v/x)",
        "Opleidingsniveau": "Onbekend",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "The Large Language Models (LLM) team at Nebius is committed to developing a cutting-edge LLM technological stack that encompasses:\n     * Foundational model training\n     * Web-scale data collection\n     * Efficient inference\n     * Model alignment\n     * Model evaluation\n\n   Our goal is to create state-of-the-art language generation technology for internal use and customer applications, propelling the development of the next generation of AI-powered products.\n\n   The Role\n\n   We are seeking Machine Learning (ML) engineers with diverse skill sets and a passion for large language models. Your contribution will help us construct a cutting-edge LLM stack. We offer flexible working arrangements, with options for office-based work in Amsterdam, hybrid, or remote engagement.\n\n   Your responsibilities in this role will include some of the following:\n     * Designing and developing our distributed training and data processing infrastructure;\n     * Experimenting with innovative deep learning methods to enhance the quality of our models;\n     * Exploring techniques to augment the quality and volume of our training data;\n     * Optimizing our training and inference infrastructure to squeeze out every FLOP out of hardware.",
        "Datum gevonden": "2023-06-14",
        "Beroepsgroep": "Engineering (overig)",
        "Beroepsklasse": "Engineering",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Overig / Onbekend",
        "Organisatiegrootte": "Onbekend",
        "Jaar (van datum gevonden)": 2023,
        "Maand (van datum gevonden)": 6,
        "full_text": "ML Engineer, Large Language Models\n\nThe Large Language Models (LLM) team at Nebius is committed to developing a cutting-edge LLM technological stack that encompasses:\n     * Foundational model training\n     * Web-scale data collection\n     * Efficient inference\n     * Model alignment\n     * Model evaluation\n\n   Our goal is to create state-of-the-art language generation technology for internal use and customer applications, propelling the development of the next generation of AI-powered products.\n\n   The Role\n\n   We are seeking Machine Learning (ML) engineers with diverse skill sets and a passion for large language models. Your contribution will help us construct a cutting-edge LLM stack. We offer flexible working arrangements, with options for office-based work in Amsterdam, hybrid, or remote engagement.\n\n   Your responsibilities in this role will include some of the following:\n     * Designing and developing our distributed training and data processing infrastructure;\n     * Experimenting with innovative deep learning methods to enhance the quality of our models;\n     * Exploring techniques to augment the quality and volume of our training data;\n     * Optimizing our training and inference infrastructure to squeeze out every FLOP out of hardware."
    },
    "analysis": {
        "profile_classification": {
            "profile": "GenAI Engineer",
            "rationale": "The job description emphasizes the development of a cutting-edge LLM technological stack, including foundational model training, data collection, efficient inference, model alignment, and evaluation. The responsibilities focus on designing and developing distributed training and data processing infrastructure, experimenting with deep learning methods for model quality enhancement, augmenting training data, and optimizing training and inference infrastructure. These activities strongly align with the core responsibilities and typical projects of a GenAI Engineer, particularly in building and maintaining production-grade systems around generative models."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'Designing and developing our distributed training and data processing infrastructure' directly relates to building and maintaining the systems for handling and processing data, which is a core aspect of data engineering.",
                    "phrase": "Designing and developing our distributed training and data processing infrastructure"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'Exploring techniques to augment the quality and volume of our training data' involves improving and expanding the datasets used for model training, a key data engineering task.",
                    "phrase": "Exploring techniques to augment the quality and volume of our training data"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "The phrase 'Experimenting with innovative deep learning methods to enhance the quality of our models' directly refers to the process of creating, training, and improving machine learning models, specifically using deep learning techniques.",
                    "phrase": "Experimenting with innovative deep learning methods to enhance the quality of our models"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "The mention of 'Foundational model training', 'Model alignment', and 'Model evaluation' are all core activities within the modeling phase of machine learning and generative AI development.",
                    "phrase": "Foundational model training"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "The mention of 'Foundational model training', 'Model alignment', and 'Model evaluation' are all core activities within the modeling phase of machine learning and generative AI development.",
                    "phrase": "Model alignment"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "The mention of 'Foundational model training', 'Model alignment', and 'Model evaluation' are all core activities within the modeling phase of machine learning and generative AI development.",
                    "phrase": "Model evaluation"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "The phrase 'creating state-of-the-art language generation technology for internal use and customer applications, propelling the development of the next generation of AI-powered products' implies building software systems that utilize LLMs, which falls under software development.",
                    "phrase": "creating state-of-the-art language generation technology for internal use and customer applications"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "The phrase 'Efficient inference' relates to optimizing the deployment and performance of models in production, a key aspect of MLOps.",
                    "phrase": "Efficient inference"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "The phrase 'Optimizing our training and inference infrastructure to squeeze out every FLOP out of hardware' directly addresses the operational aspects of making training and inference efficient and performant, which is a core MLOps responsibility.",
                    "phrase": "Optimizing our training and inference infrastructure to squeeze out every FLOP out of hardware"
                }
            ],
            "soft_skills": [
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "phrase": "diverse skill sets and a passion for large language models"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "committed to developing a cutting-edge LLM technological stack"
                }
            ],
            "technologies": [
                {
                    "category": "TECH3: LLM / Generative Models",
                    "phrase": "Large Language Models (LLM)"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "deep learning methods"
                }
            ]
        }
    }
}