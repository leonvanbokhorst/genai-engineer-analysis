{
    "job_id": 77,
    "job_details": {
        "job_id": 77,
        "Organisatienaam": "Nebius",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "ML Engineer, Large Language Models",
        "Standplaats": "Amsterdam",
        "Vacaturelink (origineel)": "glassdoor.nl",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Engineer (overig) (m/v/x)",
        "Opleidingsniveau": "Onbekend",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "The Large Language Models (LLM) team at Nebius is committed to developing a cutting-edge LLM technological stack that encompasses:\n     * Foundational model training\n     * Web-scale data collection\n     * Efficient inference\n     * Model alignment\n     * Model evaluation\n\n   Our goal is to create state-of-the-art language generation technology for internal use and customer applications, propelling the development of the next generation of AI-powered products.\n\n   The Role\n\n   We are seeking Machine Learning (ML) engineers with diverse skill sets and a passion for large language models. Your contribution will help us construct a cutting-edge LLM stack. We offer flexible working arrangements, with options for office-based work in Amsterdam, hybrid, or remote engagement.\n\n   Your responsibilities in this role will include some of the following:\n     * Designing and developing our distributed training and data processing infrastructure;\n     * Experimenting with innovative deep learning methods to enhance the quality of our models;\n     * Exploring techniques to augment the quality and volume of our training data;\n     * Optimizing our training and inference infrastructure to squeeze out every FLOP out of hardware.",
        "Datum gevonden": "2023-06-14",
        "Beroepsgroep": "Engineering (overig)",
        "Beroepsklasse": "Engineering",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Overig / Onbekend",
        "Organisatiegrootte": "Onbekend",
        "Jaar (van datum gevonden)": 2023,
        "Maand (van datum gevonden)": 6,
        "full_text": "ML Engineer, Large Language Models\n\nThe Large Language Models (LLM) team at Nebius is committed to developing a cutting-edge LLM technological stack that encompasses:\n     * Foundational model training\n     * Web-scale data collection\n     * Efficient inference\n     * Model alignment\n     * Model evaluation\n\n   Our goal is to create state-of-the-art language generation technology for internal use and customer applications, propelling the development of the next generation of AI-powered products.\n\n   The Role\n\n   We are seeking Machine Learning (ML) engineers with diverse skill sets and a passion for large language models. Your contribution will help us construct a cutting-edge LLM stack. We offer flexible working arrangements, with options for office-based work in Amsterdam, hybrid, or remote engagement.\n\n   Your responsibilities in this role will include some of the following:\n     * Designing and developing our distributed training and data processing infrastructure;\n     * Experimenting with innovative deep learning methods to enhance the quality of our models;\n     * Exploring techniques to augment the quality and volume of our training data;\n     * Optimizing our training and inference infrastructure to squeeze out every FLOP out of hardware."
    },
    "analysis": {
        "profile_classification": {
            "profile": "ML Engineer",
            "rationale": "The job description emphasizes foundational model training, web-scale data collection, efficient inference, model alignment, and model evaluation. While it mentions LLMs, the core responsibilities lean towards building and optimizing the underlying infrastructure for training and data processing, experimenting with deep learning methods, and optimizing hardware utilization. This aligns more closely with the 'ML Engineer' profile's focus on algorithm development, data preprocessing, model training, and productionizing prototypes, rather than the 'GenAI Engineer's' focus on fine-tuning, RAG, and building user-facing applications directly on top of LLMs."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'Designing and developing our distributed training and data processing infrastructure' directly relates to building and maintaining data pipelines and infrastructure.",
                    "phrase": "Designing and developing our distributed training and data processing infrastructure"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'Exploring techniques to augment the quality and volume of our training data' relates to data preprocessing and feature engineering.",
                    "phrase": "Exploring techniques to augment the quality and volume of our training data"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "The phrase 'Experimenting with innovative deep learning methods to enhance the quality of our models' directly refers to creating and adapting machine learning models.",
                    "phrase": "Experimenting with innovative deep learning methods to enhance the quality of our models"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "The mention of 'Foundational model training' is a core aspect of creating machine learning models.",
                    "phrase": "Foundational model training"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "The phrase 'Model evaluation' is a key part of the model development lifecycle.",
                    "phrase": "Model evaluation"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "The phrase 'Efficient inference' implies the development of software components to run models efficiently, which is part of building applications.",
                    "phrase": "Efficient inference"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "The phrase 'Optimizing our training and inference infrastructure to squeeze out every FLOP out of hardware' relates to the operational aspects of managing and optimizing production systems.",
                    "phrase": "Optimizing our training and inference infrastructure to squeeze out every FLOP out of hardware"
                }
            ],
            "soft_skills": [
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "phrase": "diverse skill sets and a passion for large language models"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "Experimenting with innovative deep learning methods"
                }
            ],
            "technologies": [
                {
                    "category": "TECH3: LLM / Generative Models",
                    "phrase": "Large Language Models (LLM)"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "deep learning methods"
                }
            ]
        }
    }
}