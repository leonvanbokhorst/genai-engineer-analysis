{
    "job_id": 755,
    "job_details": {
        "job_id": 755,
        "Organisatienaam": "GitLab",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "Intermediate Machine Learning Engineer, AI Framework",
        "Standplaats": null,
        "Vacaturelink (origineel)": "dejobs.org",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Machine learning engineer (m/v/x)",
        "Opleidingsniveau": "Onbekend",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "Are you passionate about building robust frameworks to evaluate and ensure the reliability of AI models? As a Machine Learning Engineer on GitLab's AIF team, you'll play a critical role in shaping the future of AI-powered features at GitLab. This is an exciting opportunity to work on impactful projects that directly influence the quality of GitLab's AI capabilities.\n\n   You'll help merge cutting-edge evaluation tools, optimize dataset management, and scale our validation infrastructure. Working closely with other AI feature teams, you'll ensure that every AI feature we deliver is robust, reliable, and meets the highest quality standards.\n\n   Some challenges in this role include designing scalable solutions for LLM evaluation, consolidating disparate validation tools, and contributing to GitLab's innovative AI roadmap.\n\n   Some examples of our projects:\n\n   Consolidating Evaluation Tooling | The GitLab Handbook (https://handbook.gitlab.com/handbook/engineering/architecture/design-documents/ai_evaluation_consolidation/) GitLab.org / AI Powered / ELI5 (https://gitlab.com/gitlab-org/ai-powered/eli5)\n     * GitLab.org / ModelOps / AI Model Validation and Research / AI Evaluation / Prompt Library (https://gitlab.com/gitlab-org/modelops/ai-model-validation-and-research/ai-evaluation/prompt-library)\n\n   What You'll Do\n     * Design and implement technical evaluators for LLM assessment.\n     * Contribute to evaluation infrastructure consolidation efforts.\n     * Build scalable evaluation pipelines and frameworks.\n     * Develop and manage datasets and evaluation metrics.\n     * Collaborate with feature teams to integrate validation solutions.\n     * Optimize performance across ML evaluation systems.\n     * Support improvements to GitLab's AI-powered tools through validation.\n     * Ensure all solutions align with GitLab's infrastructure and security protocols., The AIF team ensures that AI models across GitLab are reliable and well-validated. We focus on building robust evaluation frameworks, consolidating tools, and streamlining processes to scale validation efforts across GitLab's AI infrastructure. Working on high-impact projects, the team partners with AI feature teams to deliver quality-focused solutions that enhance user trust and product performance.\n\n   How GitLab will support you\n     * Benefits to support your health, finances, and well-being (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/)\n     * All remote (https://about.gitlab.com/company/culture/all-remote/guide/) , asynchronous (https://about.gitlab.com/company/culture/all-remote/asynchronous/) work environment\n     * Flexible Paid Time Off (https://about.gitlab.com/handbook/paid-time-off/)\n     * Team Member Resource Groups\n     * Equity Compensation & Employee Stock Purchase Plan (https://about.gitlab.com/handbook/stock-options/)\n     * Growth and development budget (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/#growth-and-development-benefit)\n     * Parental leave (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/#parental-leave)\n     * Home office (https://about.gitlab.com/handbook/finance/procurement/office-equipment-supplies/) support\n\n   Please note that we welcome interest from candidates with varying levels of experience; many successful candidates do not meet every single requirement. Additionally, studies have shown that people from underrepresented groups (https://about.gitlab.com/company/culture/inclusion/#examples-of-select-underrepresented-groups) are less likely to apply to a job unless they meet every single qualification. If you're excited about this role, please apply and allow our recruiters to assess your application.\n\n   Remote-Global\n\n   Country Hiring Guidelines: GitLab hires new team members in countries around the world. All of our roles are remote, however some roles may carry specific location-based eligibility requirements. Our Talent Acquisition team can help answer any questions about location after starting the recruiting process.\n\n   Privacy Policy: Please review our Recruitment Privacy Policy. (https://handbook.gitlab.com/handbook/hiring/candidate-faq/recruitment-privacy-policy/) Your privacy is important to us.\n\n   GitLab is proud to be an equal opportunity workplace and is an affirmative action employer. GitLab's policies and practices relating to recruitment, employment, career development and advancement, promotion, and retirement are based solely on merit, regardless of race, color, religion, ancestry, sex (including pregnancy, lactation, sexual orientation, gender identity, or gender expression), national origin, age, citizenship, marital status, mental or physical disability, genetic information (including family medical history), discharge status from the military, protected veteran status (which includes disabled veterans, recently separated veterans, active duty wartime or campaign badge veterans, and Armed Forces service medal veterans), or any other basis protected by law. GitLab will not tolerate discrimination or harassment based on any of these characteristics. See also GitLab's EEO Policy\n   (https://about.gitlab.com/handbook/people-policies/inc-usa/#equal-employment-opportunity-policy) and EEO is the Law (https://about.gitlab.com/handbook/labor-and-employment-notices/#eeoc-us-equal-employment-opportunity-commission-notices) . If you have a disability or special need that requires accommodation (https://about.gitlab.com/handbook/people-policies/inc-usa/#reasonable-accommodation) , please let us know during the recruiting process (https://about.gitlab.com/handbook/hiring/interviewing/#adjustments-to-our-interview-process) .",
        "Datum gevonden": "2024-11-21",
        "Beroepsgroep": "IT R&D Professionals",
        "Beroepsklasse": "Informatie- en communicatietechnologie",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Overig / Onbekend",
        "Organisatiegrootte": "Onbekend",
        "Jaar (van datum gevonden)": 2024,
        "Maand (van datum gevonden)": 11,
        "full_text": "Intermediate Machine Learning Engineer, AI Framework\n\nAre you passionate about building robust frameworks to evaluate and ensure the reliability of AI models? As a Machine Learning Engineer on GitLab's AIF team, you'll play a critical role in shaping the future of AI-powered features at GitLab. This is an exciting opportunity to work on impactful projects that directly influence the quality of GitLab's AI capabilities.\n\n   You'll help merge cutting-edge evaluation tools, optimize dataset management, and scale our validation infrastructure. Working closely with other AI feature teams, you'll ensure that every AI feature we deliver is robust, reliable, and meets the highest quality standards.\n\n   Some challenges in this role include designing scalable solutions for LLM evaluation, consolidating disparate validation tools, and contributing to GitLab's innovative AI roadmap.\n\n   Some examples of our projects:\n\n   Consolidating Evaluation Tooling | The GitLab Handbook (https://handbook.gitlab.com/handbook/engineering/architecture/design-documents/ai_evaluation_consolidation/) GitLab.org / AI Powered / ELI5 (https://gitlab.com/gitlab-org/ai-powered/eli5)\n     * GitLab.org / ModelOps / AI Model Validation and Research / AI Evaluation / Prompt Library (https://gitlab.com/gitlab-org/modelops/ai-model-validation-and-research/ai-evaluation/prompt-library)\n\n   What You'll Do\n     * Design and implement technical evaluators for LLM assessment.\n     * Contribute to evaluation infrastructure consolidation efforts.\n     * Build scalable evaluation pipelines and frameworks.\n     * Develop and manage datasets and evaluation metrics.\n     * Collaborate with feature teams to integrate validation solutions.\n     * Optimize performance across ML evaluation systems.\n     * Support improvements to GitLab's AI-powered tools through validation.\n     * Ensure all solutions align with GitLab's infrastructure and security protocols., The AIF team ensures that AI models across GitLab are reliable and well-validated. We focus on building robust evaluation frameworks, consolidating tools, and streamlining processes to scale validation efforts across GitLab's AI infrastructure. Working on high-impact projects, the team partners with AI feature teams to deliver quality-focused solutions that enhance user trust and product performance.\n\n   How GitLab will support you\n     * Benefits to support your health, finances, and well-being (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/)\n     * All remote (https://about.gitlab.com/company/culture/all-remote/guide/) , asynchronous (https://about.gitlab.com/company/culture/all-remote/asynchronous/) work environment\n     * Flexible Paid Time Off (https://about.gitlab.com/handbook/paid-time-off/)\n     * Team Member Resource Groups\n     * Equity Compensation & Employee Stock Purchase Plan (https://about.gitlab.com/handbook/stock-options/)\n     * Growth and development budget (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/#growth-and-development-benefit)\n     * Parental leave (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/#parental-leave)\n     * Home office (https://about.gitlab.com/handbook/finance/procurement/office-equipment-supplies/) support\n\n   Please note that we welcome interest from candidates with varying levels of experience; many successful candidates do not meet every single requirement. Additionally, studies have shown that people from underrepresented groups (https://about.gitlab.com/company/culture/inclusion/#examples-of-select-underrepresented-groups) are less likely to apply to a job unless they meet every single qualification. If you're excited about this role, please apply and allow our recruiters to assess your application.\n\n   Remote-Global\n\n   Country Hiring Guidelines: GitLab hires new team members in countries around the world. All of our roles are remote, however some roles may carry specific location-based eligibility requirements. Our Talent Acquisition team can help answer any questions about location after starting the recruiting process.\n\n   Privacy Policy: Please review our Recruitment Privacy Policy. (https://handbook.gitlab.com/handbook/hiring/candidate-faq/recruitment-privacy-policy/) Your privacy is important to us.\n\n   GitLab is proud to be an equal opportunity workplace and is an affirmative action employer. GitLab's policies and practices relating to recruitment, employment, career development and advancement, promotion, and retirement are based solely on merit, regardless of race, color, religion, ancestry, sex (including pregnancy, lactation, sexual orientation, gender identity, or gender expression), national origin, age, citizenship, marital status, mental or physical disability, genetic information (including family medical history), discharge status from the military, protected veteran status (which includes disabled veterans, recently separated veterans, active duty wartime or campaign badge veterans, and Armed Forces service medal veterans), or any other basis protected by law. GitLab will not tolerate discrimination or harassment based on any of these characteristics. See also GitLab's EEO Policy\n   (https://about.gitlab.com/handbook/people-policies/inc-usa/#equal-employment-opportunity-policy) and EEO is the Law (https://about.gitlab.com/handbook/labor-and-employment-notices/#eeoc-us-equal-employment-opportunity-commission-notices) . If you have a disability or special need that requires accommodation (https://about.gitlab.com/handbook/people-policies/inc-usa/#reasonable-accommodation) , please let us know during the recruiting process (https://about.gitlab.com/handbook/hiring/interviewing/#adjustments-to-our-interview-process) ."
    },
    "analysis": {
        "profile_classification": {
            "profile": "ML Engineer",
            "rationale": "The job description emphasizes building frameworks for evaluating and ensuring the reliability of AI models, focusing on tasks like designing technical evaluators for LLM assessment, building scalable evaluation pipelines, developing and managing datasets and evaluation metrics, and optimizing performance across ML evaluation systems. While LLMs are mentioned, the core focus is on the evaluation and validation infrastructure rather than developing or fine-tuning generative models themselves. This aligns more closely with the 'ML Engineer' profile's emphasis on data-driven algorithms, model evaluation, and productionizing systems, particularly in the context of ensuring model reliability and quality."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "category": "TASK3: Modeling",
                    "justification": "The role involves designing technical evaluators for LLM assessment, which is a form of model evaluation and adaptation for specific tasks.",
                    "phrase": "Design and implement technical evaluators for LLM assessment"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "Developing and managing datasets and evaluation metrics are crucial steps in the modeling process.",
                    "phrase": "Develop and manage datasets and evaluation metrics"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "Optimizing performance across ML evaluation systems directly relates to improving model efficiency and effectiveness.",
                    "phrase": "Optimize performance across ML evaluation systems"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "Building scalable evaluation pipelines and frameworks involves software engineering principles to create robust systems.",
                    "phrase": "Build scalable evaluation pipelines and frameworks"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "Collaborating with feature teams to integrate validation solutions requires software integration and development skills.",
                    "phrase": "Collaborate with feature teams to integrate validation solutions"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "Supporting improvements to AI-powered tools through validation implies developing or integrating systems that enhance existing software.",
                    "phrase": "Support improvements to GitLab's AI-powered tools through validation"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Contributing to evaluation infrastructure consolidation efforts and building robust evaluation frameworks are core MLOps activities focused on production systems.",
                    "phrase": "Contribute to evaluation infrastructure consolidation efforts"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Ensuring solutions align with GitLab's infrastructure and security protocols is a key aspect of operations and deployment.",
                    "phrase": "Ensure all solutions align with GitLab's infrastructure and security protocols"
                },
                {
                    "category": "TASK1: Business Understanding",
                    "justification": "The role's focus on shaping the future of AI-powered features and influencing the quality of AI capabilities demonstrates an understanding of business impact.",
                    "phrase": "shaping the future of AI-powered features at GitLab"
                },
                {
                    "category": "TASK1: Business Understanding",
                    "justification": "Ensuring that every AI feature delivered is robust, reliable, and meets the highest quality standards directly aligns with business objectives for product quality.",
                    "phrase": "ensure that every AI feature we deliver is robust, reliable, and meets the highest quality standards"
                }
            ],
            "soft_skills": [
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "Working closely with other AI feature teams"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "designing scalable solutions for LLM evaluation"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "consolidating disparate validation tools"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "contributing to GitLab's innovative AI roadmap"
                },
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "phrase": "candidates with varying levels of experience"
                }
            ],
            "technologies": [
                {
                    "category": "TECH3: LLM / Generative Models",
                    "phrase": "LLM"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "ML evaluation systems"
                }
            ]
        }
    }
}