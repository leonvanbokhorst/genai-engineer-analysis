{
    "job_id": 755,
    "job_details": {
        "job_id": 755,
        "Organisatienaam": "GitLab",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "Intermediate Machine Learning Engineer, AI Framework",
        "Standplaats": null,
        "Vacaturelink (origineel)": "dejobs.org",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Machine learning engineer (m/v/x)",
        "Opleidingsniveau": "Onbekend",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "Are you passionate about building robust frameworks to evaluate and ensure the reliability of AI models? As a Machine Learning Engineer on GitLab's AIF team, you'll play a critical role in shaping the future of AI-powered features at GitLab. This is an exciting opportunity to work on impactful projects that directly influence the quality of GitLab's AI capabilities.\n\n   You'll help merge cutting-edge evaluation tools, optimize dataset management, and scale our validation infrastructure. Working closely with other AI feature teams, you'll ensure that every AI feature we deliver is robust, reliable, and meets the highest quality standards.\n\n   Some challenges in this role include designing scalable solutions for LLM evaluation, consolidating disparate validation tools, and contributing to GitLab's innovative AI roadmap.\n\n   Some examples of our projects:\n\n   Consolidating Evaluation Tooling | The GitLab Handbook (https://handbook.gitlab.com/handbook/engineering/architecture/design-documents/ai_evaluation_consolidation/) GitLab.org / AI Powered / ELI5 (https://gitlab.com/gitlab-org/ai-powered/eli5)\n     * GitLab.org / ModelOps / AI Model Validation and Research / AI Evaluation / Prompt Library (https://gitlab.com/gitlab-org/modelops/ai-model-validation-and-research/ai-evaluation/prompt-library)\n\n   What You'll Do\n     * Design and implement technical evaluators for LLM assessment.\n     * Contribute to evaluation infrastructure consolidation efforts.\n     * Build scalable evaluation pipelines and frameworks.\n     * Develop and manage datasets and evaluation metrics.\n     * Collaborate with feature teams to integrate validation solutions.\n     * Optimize performance across ML evaluation systems.\n     * Support improvements to GitLab's AI-powered tools through validation.\n     * Ensure all solutions align with GitLab's infrastructure and security protocols., The AIF team ensures that AI models across GitLab are reliable and well-validated. We focus on building robust evaluation frameworks, consolidating tools, and streamlining processes to scale validation efforts across GitLab's AI infrastructure. Working on high-impact projects, the team partners with AI feature teams to deliver quality-focused solutions that enhance user trust and product performance.\n\n   How GitLab will support you\n     * Benefits to support your health, finances, and well-being (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/)\n     * All remote (https://about.gitlab.com/company/culture/all-remote/guide/) , asynchronous (https://about.gitlab.com/company/culture/all-remote/asynchronous/) work environment\n     * Flexible Paid Time Off (https://about.gitlab.com/handbook/paid-time-off/)\n     * Team Member Resource Groups\n     * Equity Compensation & Employee Stock Purchase Plan (https://about.gitlab.com/handbook/stock-options/)\n     * Growth and development budget (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/#growth-and-development-benefit)\n     * Parental leave (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/#parental-leave)\n     * Home office (https://about.gitlab.com/handbook/finance/procurement/office-equipment-supplies/) support\n\n   Please note that we welcome interest from candidates with varying levels of experience; many successful candidates do not meet every single requirement. Additionally, studies have shown that people from underrepresented groups (https://about.gitlab.com/company/culture/inclusion/#examples-of-select-underrepresented-groups) are less likely to apply to a job unless they meet every single qualification. If you're excited about this role, please apply and allow our recruiters to assess your application.\n\n   Remote-Global\n\n   Country Hiring Guidelines: GitLab hires new team members in countries around the world. All of our roles are remote, however some roles may carry specific location-based eligibility requirements. Our Talent Acquisition team can help answer any questions about location after starting the recruiting process.\n\n   Privacy Policy: Please review our Recruitment Privacy Policy. (https://handbook.gitlab.com/handbook/hiring/candidate-faq/recruitment-privacy-policy/) Your privacy is important to us.\n\n   GitLab is proud to be an equal opportunity workplace and is an affirmative action employer. GitLab's policies and practices relating to recruitment, employment, career development and advancement, promotion, and retirement are based solely on merit, regardless of race, color, religion, ancestry, sex (including pregnancy, lactation, sexual orientation, gender identity, or gender expression), national origin, age, citizenship, marital status, mental or physical disability, genetic information (including family medical history), discharge status from the military, protected veteran status (which includes disabled veterans, recently separated veterans, active duty wartime or campaign badge veterans, and Armed Forces service medal veterans), or any other basis protected by law. GitLab will not tolerate discrimination or harassment based on any of these characteristics. See also GitLab's EEO Policy\n   (https://about.gitlab.com/handbook/people-policies/inc-usa/#equal-employment-opportunity-policy) and EEO is the Law (https://about.gitlab.com/handbook/labor-and-employment-notices/#eeoc-us-equal-employment-opportunity-commission-notices) . If you have a disability or special need that requires accommodation (https://about.gitlab.com/handbook/people-policies/inc-usa/#reasonable-accommodation) , please let us know during the recruiting process (https://about.gitlab.com/handbook/hiring/interviewing/#adjustments-to-our-interview-process) .",
        "Datum gevonden": "2024-11-21",
        "Beroepsgroep": "IT R&D Professionals",
        "Beroepsklasse": "Informatie- en communicatietechnologie",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Overig / Onbekend",
        "Organisatiegrootte": "Onbekend",
        "Jaar (van datum gevonden)": 2024,
        "Maand (van datum gevonden)": 11,
        "full_text": "Intermediate Machine Learning Engineer, AI Framework\n\nAre you passionate about building robust frameworks to evaluate and ensure the reliability of AI models? As a Machine Learning Engineer on GitLab's AIF team, you'll play a critical role in shaping the future of AI-powered features at GitLab. This is an exciting opportunity to work on impactful projects that directly influence the quality of GitLab's AI capabilities.\n\n   You'll help merge cutting-edge evaluation tools, optimize dataset management, and scale our validation infrastructure. Working closely with other AI feature teams, you'll ensure that every AI feature we deliver is robust, reliable, and meets the highest quality standards.\n\n   Some challenges in this role include designing scalable solutions for LLM evaluation, consolidating disparate validation tools, and contributing to GitLab's innovative AI roadmap.\n\n   Some examples of our projects:\n\n   Consolidating Evaluation Tooling | The GitLab Handbook (https://handbook.gitlab.com/handbook/engineering/architecture/design-documents/ai_evaluation_consolidation/) GitLab.org / AI Powered / ELI5 (https://gitlab.com/gitlab-org/ai-powered/eli5)\n     * GitLab.org / ModelOps / AI Model Validation and Research / AI Evaluation / Prompt Library (https://gitlab.com/gitlab-org/modelops/ai-model-validation-and-research/ai-evaluation/prompt-library)\n\n   What You'll Do\n     * Design and implement technical evaluators for LLM assessment.\n     * Contribute to evaluation infrastructure consolidation efforts.\n     * Build scalable evaluation pipelines and frameworks.\n     * Develop and manage datasets and evaluation metrics.\n     * Collaborate with feature teams to integrate validation solutions.\n     * Optimize performance across ML evaluation systems.\n     * Support improvements to GitLab's AI-powered tools through validation.\n     * Ensure all solutions align with GitLab's infrastructure and security protocols., The AIF team ensures that AI models across GitLab are reliable and well-validated. We focus on building robust evaluation frameworks, consolidating tools, and streamlining processes to scale validation efforts across GitLab's AI infrastructure. Working on high-impact projects, the team partners with AI feature teams to deliver quality-focused solutions that enhance user trust and product performance.\n\n   How GitLab will support you\n     * Benefits to support your health, finances, and well-being (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/)\n     * All remote (https://about.gitlab.com/company/culture/all-remote/guide/) , asynchronous (https://about.gitlab.com/company/culture/all-remote/asynchronous/) work environment\n     * Flexible Paid Time Off (https://about.gitlab.com/handbook/paid-time-off/)\n     * Team Member Resource Groups\n     * Equity Compensation & Employee Stock Purchase Plan (https://about.gitlab.com/handbook/stock-options/)\n     * Growth and development budget (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/#growth-and-development-benefit)\n     * Parental leave (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/#parental-leave)\n     * Home office (https://about.gitlab.com/handbook/finance/procurement/office-equipment-supplies/) support\n\n   Please note that we welcome interest from candidates with varying levels of experience; many successful candidates do not meet every single requirement. Additionally, studies have shown that people from underrepresented groups (https://about.gitlab.com/company/culture/inclusion/#examples-of-select-underrepresented-groups) are less likely to apply to a job unless they meet every single qualification. If you're excited about this role, please apply and allow our recruiters to assess your application.\n\n   Remote-Global\n\n   Country Hiring Guidelines: GitLab hires new team members in countries around the world. All of our roles are remote, however some roles may carry specific location-based eligibility requirements. Our Talent Acquisition team can help answer any questions about location after starting the recruiting process.\n\n   Privacy Policy: Please review our Recruitment Privacy Policy. (https://handbook.gitlab.com/handbook/hiring/candidate-faq/recruitment-privacy-policy/) Your privacy is important to us.\n\n   GitLab is proud to be an equal opportunity workplace and is an affirmative action employer. GitLab's policies and practices relating to recruitment, employment, career development and advancement, promotion, and retirement are based solely on merit, regardless of race, color, religion, ancestry, sex (including pregnancy, lactation, sexual orientation, gender identity, or gender expression), national origin, age, citizenship, marital status, mental or physical disability, genetic information (including family medical history), discharge status from the military, protected veteran status (which includes disabled veterans, recently separated veterans, active duty wartime or campaign badge veterans, and Armed Forces service medal veterans), or any other basis protected by law. GitLab will not tolerate discrimination or harassment based on any of these characteristics. See also GitLab's EEO Policy\n   (https://about.gitlab.com/handbook/people-policies/inc-usa/#equal-employment-opportunity-policy) and EEO is the Law (https://about.gitlab.com/handbook/labor-and-employment-notices/#eeoc-us-equal-employment-opportunity-commission-notices) . If you have a disability or special need that requires accommodation (https://about.gitlab.com/handbook/people-policies/inc-usa/#reasonable-accommodation) , please let us know during the recruiting process (https://about.gitlab.com/handbook/hiring/interviewing/#adjustments-to-our-interview-process) ."
    },
    "analysis": {
        "job_profile_classification": {
            "profile": "ML Engineer",
            "confidence_score": 4,
            "rationale": "The role heavily emphasizes building and maintaining frameworks for evaluating and validating AI models, including designing scalable pipelines and optimizing performance. While it involves AI, the core focus is on the engineering and operational aspects of model reliability and assessment rather than developing novel generative models or user-facing GenAI applications."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "phrase": "building robust frameworks to evaluate and ensure the reliability of AI models",
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "This phrase directly relates to building and maintaining systems (frameworks) for ensuring the operational reliability and quality of AI models."
                },
                {
                    "phrase": "shaping the future of AI-powered features at GitLab",
                    "category": "TASK1: Business Understanding",
                    "justification": "This indicates an understanding of how AI features contribute to the company's overall product strategy and future direction."
                },
                {
                    "phrase": "work on impactful projects that directly influence the quality of GitLab's AI capabilities",
                    "category": "TASK1: Business Understanding",
                    "justification": "This highlights the alignment of technical work with business objectives related to product quality and AI capabilities."
                },
                {
                    "phrase": "merge cutting-edge evaluation tools",
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "This involves integrating and managing tools for AI model evaluation, which falls under operationalizing AI systems."
                },
                {
                    "phrase": "optimize dataset management",
                    "category": "TASK2: Data Engineering",
                    "justification": "Managing datasets, especially for evaluation purposes, is a key aspect of data engineering."
                },
                {
                    "phrase": "scale our validation infrastructure",
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Scaling infrastructure for validation is a core MLOps responsibility."
                },
                {
                    "phrase": "Working closely with other AI feature teams",
                    "category": "SKILL1: Communication & Collaboration",
                    "justification": "This indicates the need to collaborate with other teams."
                },
                {
                    "phrase": "ensure that every AI feature we deliver is robust, reliable, and meets the highest quality standards",
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Focusing on robustness, reliability, and quality standards for delivered AI features is a key MLOps concern."
                },
                {
                    "phrase": "designing scalable solutions for LLM evaluation",
                    "category": "TASK3: Modeling",
                    "justification": "Designing solutions for LLM evaluation involves understanding and applying modeling concepts, even if focused on assessment."
                },
                {
                    "phrase": "consolidating disparate validation tools",
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Consolidating tools for validation is about streamlining and managing the operational aspects of AI model assessment."
                },
                {
                    "phrase": "contributing to GitLab's innovative AI roadmap",
                    "category": "TASK1: Business Understanding",
                    "justification": "Contributing to the AI roadmap implies understanding business strategy and future product direction."
                },
                {
                    "phrase": "Design and implement technical evaluators for LLM assessment",
                    "category": "TASK3: Modeling",
                    "justification": "Designing and implementing evaluators for LLMs involves understanding model behavior and assessment techniques."
                },
                {
                    "phrase": "Contribute to evaluation infrastructure consolidation efforts",
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "This task directly relates to building and managing the infrastructure for AI model evaluation."
                },
                {
                    "phrase": "Build scalable evaluation pipelines and frameworks",
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Building pipelines and frameworks for evaluation is a core MLOps activity."
                },
                {
                    "phrase": "Develop and manage datasets and evaluation metrics",
                    "category": "TASK2: Data Engineering",
                    "justification": "Developing and managing datasets and metrics is a data engineering task, especially in the context of model evaluation."
                },
                {
                    "phrase": "Collaborate with feature teams to integrate validation solutions",
                    "category": "TASK4: Software Development",
                    "justification": "Integrating validation solutions into feature teams implies software development and integration work."
                },
                {
                    "phrase": "Optimize performance across ML evaluation systems",
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Optimizing performance of evaluation systems falls under the operational maintenance and improvement of AI infrastructure."
                },
                {
                    "phrase": "Support improvements to GitLab's AI-powered tools through validation",
                    "category": "TASK1: Business Understanding",
                    "justification": "Supporting improvements to tools through validation aligns technical work with business goals of enhancing product capabilities."
                },
                {
                    "phrase": "Ensure all solutions align with GitLab's infrastructure and security protocols",
                    "category": "TASK4: Software Development",
                    "justification": "Ensuring alignment with infrastructure and security protocols is a standard software development and engineering practice."
                },
                {
                    "phrase": "building robust evaluation frameworks",
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "This directly describes the creation and maintenance of systems for AI model evaluation."
                },
                {
                    "phrase": "consolidating tools",
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Consolidating tools for AI model validation is an operational task."
                },
                {
                    "phrase": "streamlining processes to scale validation efforts",
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Streamlining and scaling validation processes are core MLOps responsibilities."
                },
                {
                    "phrase": "partners with AI feature teams to deliver quality-focused solutions",
                    "category": "SKILL1: Communication & Collaboration",
                    "justification": "This highlights collaboration with other teams to deliver solutions."
                }
            ],
            "technologies": [
                {
                    "phrase": "AI models",
                    "category": "TECH3: LLM / Generative Models",
                    "justification": "While broad, in the context of LLM evaluation, 'AI models' likely refers to generative models."
                },
                {
                    "phrase": "LLM",
                    "category": "TECH3: LLM / Generative Models",
                    "justification": "Explicit mention of Large Language Models."
                },
                {
                    "phrase": "GitLab",
                    "category": "TECH2: Cloud Platforms & Services",
                    "justification": "GitLab is a platform for software development and collaboration, often hosted on cloud infrastructure."
                }
            ],
            "soft_skills": [
                {
                    "phrase": "passionate about building robust frameworks",
                    "category": "SKILL5: Innovation & Ownership",
                    "justification": "Expresses a strong drive and commitment to building quality systems."
                },
                {
                    "phrase": "play a critical role in shaping the future of AI-powered features",
                    "category": "SKILL5: Innovation & Ownership",
                    "justification": "Indicates taking ownership and having a significant impact on future developments."
                },
                {
                    "phrase": "work on impactful projects",
                    "category": "SKILL5: Innovation & Ownership",
                    "justification": "Suggests a proactive approach to contributing to important initiatives."
                },
                {
                    "phrase": "Working closely with other AI feature teams",
                    "category": "SKILL1: Communication & Collaboration",
                    "justification": "Directly states collaboration with other teams."
                },
                {
                    "phrase": "Collaborate with feature teams to integrate validation solutions",
                    "category": "SKILL1: Communication & Collaboration",
                    "justification": "Explicitly mentions collaboration for integration purposes."
                },
                {
                    "phrase": "partners with AI feature teams",
                    "category": "SKILL1: Communication & Collaboration",
                    "justification": "Highlights the collaborative nature of the role with other teams."
                },
                {
                    "phrase": "candidates with varying levels of experience",
                    "category": "SKILL2: Learning & Adaptability",
                    "justification": "Implies a willingness to consider candidates who may need to learn and adapt to the role."
                },
                {
                    "phrase": "If you're excited about this role, please apply",
                    "category": "SKILL5: Innovation & Ownership",
                    "justification": "Encourages proactive engagement and interest in the role."
                }
            ]
        }
    }
}