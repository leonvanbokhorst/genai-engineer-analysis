{
    "job_id": 230,
    "job_details": {
        "job_id": 230,
        "Organisatienaam": "Databricks",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "Sr. Product Manager, Developer Ecosystem",
        "Standplaats": "Amsterdam",
        "Vacaturelink (origineel)": "nationalevacaturebank.nl",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Productingenieur (m/v/x)",
        "Opleidingsniveau": "HBO",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "Databricks\n       The Databricks Platform is the world's first data intelligence platform powered by generative AI. Infuse AI into every facet of your business.\n       Posted 5 hours ago\n       You will be the Product Manager in the Developer Ecosystem team at Databricks in Amsterdam. You will be responsible for enhancing the customer developer experience across the inner and outer development loops, ensuring seamless integration with tools, CI/CD workflows, and automation frameworks. Our customers require enterprise grade software best practices for their teams and this team delivers on that mission.\n       You have a deep understanding of developer workflows, cloud infrastructure, CI/CD best practices, and the evolving landscape of data and AI development to drive meaningful impact across Databricks' developer community. Specifically as a Product Manager in the Developer Ecosystem team you will work on:\n          + Strategy & Roadmap - Define and execute the vision for the developer ecosystem, prioritizing features and integrations that improve developer velocity, collaboration, and productivity.\n          + Developer Tooling & Experience - Drive improvements in Databricks Asset Bundles (DABs), IDE integrations, CLI and SDK enhancements, CI/CD workflows, automation frameworks, and testing tools to enhance the inner loop development experience.\n          + Integrations & Extensibility - Ensure Databricks integrates seamlessly with third-party developer tools (GitHub, GitLab, Jenkins, Terraform, etc.), enabling efficient DevOps and MLOps workflows.\n          + Metrics & Observability - Define and track key success metrics around developer adoption, engagement, and efficiency to continuously refine the developer experience.\n          + Collaboration & Stakeholder Management - Work closely with engineering, developer relations, solution architects, and external partners to drive adoption of Databricks as a best-in-class development platform.\n          + Customer-Centric Development - Gather insights from developers, iterate on feedback, and advocate for features that reduce friction in building, testing, and deploying data applications on Databricks.\n       The impact you will have:\n       What we look for:\n          + 5+ yrs of experience\n          + Bachelors degree in Computer Science or similar field\n          + Experience in Product Management (inbound, outbound, cross-functional processes)\n          + Technical skills using developer tools, frameworks and languages\n          + Solid understanding of cloud infrastructure (AWS, Azure, GCP)\n          + Strong data analysis and operationalization skills (SQL, Python, building operational dashboards)\n       About Databricks\n       Databricks is the data and AI company. More than 10,000 organizations worldwide - including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 - rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark , Delta Lake and MLflow. To learn more, follow Databricks on Twitter , LinkedIn and Facebook .\n       Benefits\n       At Databricks, we strive to provide comprehensive benefits and perks that meet the needs of all of our employees. For specific details on the benefits offered in your region, please visit https://www.mybenefitsnow.com/databricks .\n       Our Commitment to Diversity and Inclusion\n       At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.\n       Compliance\n       If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.",
        "Datum gevonden": "2025-02-20",
        "Beroepsgroep": "Bedrijfskundig ingenieurs en deskundigen",
        "Beroepsklasse": "Engineering",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Overig / Onbekend",
        "Organisatiegrootte": "1-9",
        "Jaar (van datum gevonden)": 2025,
        "Maand (van datum gevonden)": 2,
        "full_text": "Sr. Product Manager, Developer Ecosystem\n\nDatabricks\n       The Databricks Platform is the world's first data intelligence platform powered by generative AI. Infuse AI into every facet of your business.\n       Posted 5 hours ago\n       You will be the Product Manager in the Developer Ecosystem team at Databricks in Amsterdam. You will be responsible for enhancing the customer developer experience across the inner and outer development loops, ensuring seamless integration with tools, CI/CD workflows, and automation frameworks. Our customers require enterprise grade software best practices for their teams and this team delivers on that mission.\n       You have a deep understanding of developer workflows, cloud infrastructure, CI/CD best practices, and the evolving landscape of data and AI development to drive meaningful impact across Databricks' developer community. Specifically as a Product Manager in the Developer Ecosystem team you will work on:\n          + Strategy & Roadmap - Define and execute the vision for the developer ecosystem, prioritizing features and integrations that improve developer velocity, collaboration, and productivity.\n          + Developer Tooling & Experience - Drive improvements in Databricks Asset Bundles (DABs), IDE integrations, CLI and SDK enhancements, CI/CD workflows, automation frameworks, and testing tools to enhance the inner loop development experience.\n          + Integrations & Extensibility - Ensure Databricks integrates seamlessly with third-party developer tools (GitHub, GitLab, Jenkins, Terraform, etc.), enabling efficient DevOps and MLOps workflows.\n          + Metrics & Observability - Define and track key success metrics around developer adoption, engagement, and efficiency to continuously refine the developer experience.\n          + Collaboration & Stakeholder Management - Work closely with engineering, developer relations, solution architects, and external partners to drive adoption of Databricks as a best-in-class development platform.\n          + Customer-Centric Development - Gather insights from developers, iterate on feedback, and advocate for features that reduce friction in building, testing, and deploying data applications on Databricks.\n       The impact you will have:\n       What we look for:\n          + 5+ yrs of experience\n          + Bachelors degree in Computer Science or similar field\n          + Experience in Product Management (inbound, outbound, cross-functional processes)\n          + Technical skills using developer tools, frameworks and languages\n          + Solid understanding of cloud infrastructure (AWS, Azure, GCP)\n          + Strong data analysis and operationalization skills (SQL, Python, building operational dashboards)\n       About Databricks\n       Databricks is the data and AI company. More than 10,000 organizations worldwide - including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 - rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark , Delta Lake and MLflow. To learn more, follow Databricks on Twitter , LinkedIn and Facebook .\n       Benefits\n       At Databricks, we strive to provide comprehensive benefits and perks that meet the needs of all of our employees. For specific details on the benefits offered in your region, please visit https://www.mybenefitsnow.com/databricks .\n       Our Commitment to Diversity and Inclusion\n       At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.\n       Compliance\n       If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone."
    },
    "analysis": {
        "profile_classification": {
            "profile": "Ambiguous",
            "rationale": "The job description is for a Sr. Product Manager focused on the developer ecosystem, which involves understanding and improving developer workflows, CI/CD, and integrations. While it mentions AI and the Databricks platform is powered by generative AI, the core responsibilities and required skills are centered around product management, developer experience, and traditional software engineering practices (CI/CD, cloud infrastructure, tooling) rather than hands-on development, modeling, or deep MLOps of AI systems. The role is more about enabling developers to use AI tools and platforms effectively, rather than building or engineering the AI models themselves. Therefore, it does not fit the core definitions of ML Engineer or GenAI Engineer."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "category": "TASK1: Business Understanding",
                    "justification": "The role requires defining and executing the vision for the developer ecosystem, prioritizing features, and understanding customer needs to drive impact.",
                    "phrase": "Define and execute the vision for the developer ecosystem, prioritizing features and integrations that improve developer velocity, collaboration, and productivity."
                },
                {
                    "category": "TASK1: Business Understanding",
                    "justification": "The role involves gathering insights from developers and advocating for features that reduce friction, indicating a focus on understanding and meeting business/customer needs.",
                    "phrase": "Gather insights from developers, iterate on feedback, and advocate for features that reduce friction in building, testing, and deploying data applications on Databricks."
                },
                {
                    "category": "TASK1: Business Understanding",
                    "justification": "The role requires working closely with various teams and external partners to drive adoption, which involves understanding business objectives and stakeholder needs.",
                    "phrase": "Work closely with engineering, developer relations, solution architects, and external partners to drive adoption of Databricks as a best-in-class development platform."
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "The role focuses on improving developer experience through tools like Databricks Asset Bundles (DABs), IDE integrations, CLI and SDK enhancements, and testing tools, which are aspects of software development tooling.",
                    "phrase": "Drive improvements in Databricks Asset Bundles (DABs), IDE integrations, CLI and SDK enhancements, CI/CD workflows, automation frameworks, and testing tools to enhance the inner loop development experience."
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "Ensuring seamless integration with third-party developer tools and enabling efficient DevOps workflows falls under the umbrella of software development and integration.",
                    "phrase": "Ensure Databricks integrates seamlessly with third-party developer tools (GitHub, GitLab, Jenkins, Terraform, etc.), enabling efficient DevOps and MLOps workflows."
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "The job description explicitly mentions enabling efficient MLOps workflows through integrations with tools like Terraform, which is a component of Operations Engineering.",
                    "phrase": "Ensure Databricks integrates seamlessly with third-party developer tools (GitHub, GitLab, Jenkins, Terraform, etc.), enabling efficient DevOps and MLOps workflows."
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "The role involves working with CI/CD workflows and automation frameworks, which are key components of MLOps and DevOps.",
                    "phrase": "ensuring seamless integration with tools, CI/CD workflows, and automation frameworks."
                }
            ],
            "soft_skills": [
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "Work closely with engineering, developer relations, solution architects, and external partners"
                },
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "Collaboration & Stakeholder Management"
                },
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "phrase": "evolving landscape of data and AI development"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "drive meaningful impact across Databricks' developer community"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "reduce friction in building, testing, and deploying data applications"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "Define and execute the vision for the developer ecosystem"
                }
            ],
            "technologies": [
                {
                    "category": "TECH2: Cloud Platforms & Services",
                    "phrase": "AWS"
                },
                {
                    "category": "TECH2: Cloud Platforms & Services",
                    "phrase": "Azure"
                },
                {
                    "category": "TECH2: Cloud Platforms & Services",
                    "phrase": "GCP"
                },
                {
                    "category": "TECH4: LLM Frameworks & Libraries",
                    "phrase": "Databricks Asset Bundles (DABs)"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "CI/CD workflows"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "automation frameworks"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "Jenkins"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "Terraform"
                },
                {
                    "category": "TECH1: Programming Languages",
                    "phrase": "Python"
                },
                {
                    "category": "TECH11: Data Analysis",
                    "phrase": "SQL"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "MLflow"
                }
            ]
        }
    }
}