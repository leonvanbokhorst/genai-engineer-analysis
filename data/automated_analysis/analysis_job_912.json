{
    "job_id": 912,
    "job_details": {
        "job_id": 912,
        "Organisatienaam": "GitLab",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "Intermediate Machine Learning Engineer, AI Powered: AI Framework",
        "Standplaats": null,
        "Vacaturelink (origineel)": "dejobs.org",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Machine learning engineer (m/v/x)",
        "Opleidingsniveau": "Onbekend",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "Are you passionate about building robust frameworks to evaluate and ensure the reliability of AI models? As a Machine Learning Engineer on GitLab's AI framework team, you'll play a critical role in shaping the future of AI-powered features at GitLab. This is an exciting opportunity to work on impactful projects that directly influence the quality of GitLab's AI capabilities.\n\n   You'll help merge cutting-edge evaluation tools, optimize dataset management, and scale our validation infrastructure. Working closely with other AI feature teams, you'll ensure that every AI feature we deliver is robust, reliable, and meets the highest quality standards.\n\n   Some challenges in this role include designing scalable solutions for LLM evaluation, consolidating disparate validation tools, and contributing to GitLab's innovative AI roadmap.\n\n   Some examples of our projects:\n\n   Consolidating Evaluation Tooling | The GitLab Handbook (https://handbook.gitlab.com/handbook/engineering/architecture/design-documents/ai_evaluation_consolidation/) GitLab.org / AI Powered / ELI5 (https://gitlab.com/gitlab-org/ai-powered/eli5)\n     * GitLab.org / ModelOps / AI Model Validation and Research / AI Evaluation / Prompt Library (https://gitlab.com/gitlab-org/modelops/ai-model-validation-and-research/ai-evaluation/prompt-library)\n\n   What You'll Do\n     * Design and implement technical evaluators for LLM assessment.\n     * Contribute to evaluation infrastructure consolidation efforts.\n     * Build scalable evaluation pipelines and frameworks.\n     * Develop and manage datasets and evaluation metrics.\n     * Collaborate with feature teams to integrate validation solutions.\n     * Optimize performance across ML evaluation systems.\n     * Support improvements to GitLab's AI-powered tools through validation.\n     * Ensure all solutions align with GitLab's infrastructure and security protocols., The AIF team ensures that AI models across GitLab are reliable and well-validated. We focus on building robust evaluation frameworks, consolidating tools, and streamlining processes to scale validation efforts across GitLab's AI infrastructure. Working on high-impact projects, the team partners with AI feature teams to deliver quality-focused solutions that enhance user trust and product performance.\n\n   How GitLab will support you\n     * Benefits to support your health, finances, and well-being (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/)\n     * All remote (https://about.gitlab.com/company/culture/all-remote/guide/) , asynchronous (https://about.gitlab.com/company/culture/all-remote/asynchronous/) work environment\n     * Flexible Paid Time Off (https://about.gitlab.com/handbook/paid-time-off/)\n     * Team Member Resource Groups\n     * Equity Compensation & Employee Stock Purchase Plan (https://about.gitlab.com/handbook/stock-options/)\n     * Growth and development budget (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/#growth-and-development-benefit)\n     * Parental leave (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/#parental-leave)\n     * Home office (https://about.gitlab.com/handbook/finance/procurement/office-equipment-supplies/) support\n\n   Please note that we welcome interest from candidates with varying levels of experience; many successful candidates do not meet every single requirement. Additionally, studies have shown that people from underrepresented groups (https://about.gitlab.com/company/culture/inclusion/#examples-of-select-underrepresented-groups) are less likely to apply to a job unless they meet every single qualification. If you're excited about this role, please apply and allow our recruiters to assess your application.\n\n   Remote-Global\n\n   Country Hiring Guidelines: GitLab hires new team members in countries around the world. All of our roles are remote, however some roles may carry specific location-based eligibility requirements. Our Talent Acquisition team can help answer any questions about location after starting the recruiting process.\n\n   Privacy Policy: Please review our Recruitment Privacy Policy. (https://handbook.gitlab.com/handbook/hiring/candidate-faq/recruitment-privacy-policy/) Your privacy is important to us.\n\n   GitLab is proud to be an equal opportunity workplace and is an affirmative action employer. GitLab's policies and practices relating to recruitment, employment, career development and advancement, promotion, and retirement are based solely on merit, regardless of race, color, religion, ancestry, sex (including pregnancy, lactation, sexual orientation, gender identity, or gender expression), national origin, age, citizenship, marital status, mental or physical disability, genetic information (including family medical history), discharge status from the military, protected veteran status (which includes disabled veterans, recently separated veterans, active duty wartime or campaign badge veterans, and Armed Forces service medal veterans), or any other basis protected by law. GitLab will not tolerate discrimination or harassment based on any of these characteristics. See also GitLab's EEO Policy\n   (https://about.gitlab.com/handbook/people-policies/inc-usa/#equal-employment-opportunity-policy) and EEO is the Law (https://about.gitlab.com/handbook/labor-and-employment-notices/#eeoc-us-equal-employment-opportunity-commission-notices) . If you have a disability or special need that requires accommodation (https://about.gitlab.com/handbook/people-policies/inc-usa/#reasonable-accommodation) , please let us know during the recruiting process (https://about.gitlab.com/handbook/hiring/interviewing/#adjustments-to-our-interview-process) .",
        "Datum gevonden": "2025-01-29",
        "Beroepsgroep": "IT R&D Professionals",
        "Beroepsklasse": "Informatie- en communicatietechnologie",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Overig / Onbekend",
        "Organisatiegrootte": "Onbekend",
        "Jaar (van datum gevonden)": 2025,
        "Maand (van datum gevonden)": 1,
        "full_text": "Intermediate Machine Learning Engineer, AI Powered: AI Framework\n\nAre you passionate about building robust frameworks to evaluate and ensure the reliability of AI models? As a Machine Learning Engineer on GitLab's AI framework team, you'll play a critical role in shaping the future of AI-powered features at GitLab. This is an exciting opportunity to work on impactful projects that directly influence the quality of GitLab's AI capabilities.\n\n   You'll help merge cutting-edge evaluation tools, optimize dataset management, and scale our validation infrastructure. Working closely with other AI feature teams, you'll ensure that every AI feature we deliver is robust, reliable, and meets the highest quality standards.\n\n   Some challenges in this role include designing scalable solutions for LLM evaluation, consolidating disparate validation tools, and contributing to GitLab's innovative AI roadmap.\n\n   Some examples of our projects:\n\n   Consolidating Evaluation Tooling | The GitLab Handbook (https://handbook.gitlab.com/handbook/engineering/architecture/design-documents/ai_evaluation_consolidation/) GitLab.org / AI Powered / ELI5 (https://gitlab.com/gitlab-org/ai-powered/eli5)\n     * GitLab.org / ModelOps / AI Model Validation and Research / AI Evaluation / Prompt Library (https://gitlab.com/gitlab-org/modelops/ai-model-validation-and-research/ai-evaluation/prompt-library)\n\n   What You'll Do\n     * Design and implement technical evaluators for LLM assessment.\n     * Contribute to evaluation infrastructure consolidation efforts.\n     * Build scalable evaluation pipelines and frameworks.\n     * Develop and manage datasets and evaluation metrics.\n     * Collaborate with feature teams to integrate validation solutions.\n     * Optimize performance across ML evaluation systems.\n     * Support improvements to GitLab's AI-powered tools through validation.\n     * Ensure all solutions align with GitLab's infrastructure and security protocols., The AIF team ensures that AI models across GitLab are reliable and well-validated. We focus on building robust evaluation frameworks, consolidating tools, and streamlining processes to scale validation efforts across GitLab's AI infrastructure. Working on high-impact projects, the team partners with AI feature teams to deliver quality-focused solutions that enhance user trust and product performance.\n\n   How GitLab will support you\n     * Benefits to support your health, finances, and well-being (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/)\n     * All remote (https://about.gitlab.com/company/culture/all-remote/guide/) , asynchronous (https://about.gitlab.com/company/culture/all-remote/asynchronous/) work environment\n     * Flexible Paid Time Off (https://about.gitlab.com/handbook/paid-time-off/)\n     * Team Member Resource Groups\n     * Equity Compensation & Employee Stock Purchase Plan (https://about.gitlab.com/handbook/stock-options/)\n     * Growth and development budget (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/#growth-and-development-benefit)\n     * Parental leave (https://about.gitlab.com/handbook/total-rewards/benefits/general-and-entity-benefits/#parental-leave)\n     * Home office (https://about.gitlab.com/handbook/finance/procurement/office-equipment-supplies/) support\n\n   Please note that we welcome interest from candidates with varying levels of experience; many successful candidates do not meet every single requirement. Additionally, studies have shown that people from underrepresented groups (https://about.gitlab.com/company/culture/inclusion/#examples-of-select-underrepresented-groups) are less likely to apply to a job unless they meet every single qualification. If you're excited about this role, please apply and allow our recruiters to assess your application.\n\n   Remote-Global\n\n   Country Hiring Guidelines: GitLab hires new team members in countries around the world. All of our roles are remote, however some roles may carry specific location-based eligibility requirements. Our Talent Acquisition team can help answer any questions about location after starting the recruiting process.\n\n   Privacy Policy: Please review our Recruitment Privacy Policy. (https://handbook.gitlab.com/handbook/hiring/candidate-faq/recruitment-privacy-policy/) Your privacy is important to us.\n\n   GitLab is proud to be an equal opportunity workplace and is an affirmative action employer. GitLab's policies and practices relating to recruitment, employment, career development and advancement, promotion, and retirement are based solely on merit, regardless of race, color, religion, ancestry, sex (including pregnancy, lactation, sexual orientation, gender identity, or gender expression), national origin, age, citizenship, marital status, mental or physical disability, genetic information (including family medical history), discharge status from the military, protected veteran status (which includes disabled veterans, recently separated veterans, active duty wartime or campaign badge veterans, and Armed Forces service medal veterans), or any other basis protected by law. GitLab will not tolerate discrimination or harassment based on any of these characteristics. See also GitLab's EEO Policy\n   (https://about.gitlab.com/handbook/people-policies/inc-usa/#equal-employment-opportunity-policy) and EEO is the Law (https://about.gitlab.com/handbook/labor-and-employment-notices/#eeoc-us-equal-employment-opportunity-commission-notices) . If you have a disability or special need that requires accommodation (https://about.gitlab.com/handbook/people-policies/inc-usa/#reasonable-accommodation) , please let us know during the recruiting process (https://about.gitlab.com/handbook/hiring/interviewing/#adjustments-to-our-interview-process) ."
    },
    "analysis": {
        "profile_classification": {
            "profile": "ML Engineer",
            "rationale": "The job description emphasizes building frameworks for evaluating and ensuring the reliability of AI models, optimizing dataset management, and scaling validation infrastructure. While it mentions LLMs, the core focus is on the evaluation and validation of models, aligning with the 'ML Engineer' profile's emphasis on algorithm development, data preprocessing, model training, evaluation, and productionizing prototypes, particularly in the context of ensuring model quality and reliability."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "category": "TASK3: Modeling",
                    "justification": "The role involves designing technical evaluators for LLM assessment, building scalable evaluation pipelines and frameworks, and developing evaluation metrics, all of which are core to the modeling process, specifically in the context of evaluating and validating models.",
                    "phrase": "Design and implement technical evaluators for LLM assessment"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "Building scalable evaluation pipelines and frameworks directly relates to the process of creating and maintaining systems for model assessment and validation.",
                    "phrase": "Build scalable evaluation pipelines and frameworks"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "Developing and managing datasets and evaluation metrics are crucial steps in the modeling lifecycle, particularly for ensuring the quality and performance of AI models.",
                    "phrase": "Develop and manage datasets and evaluation metrics"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "Optimizing performance across ML evaluation systems is a direct task related to refining and improving the effectiveness of models and their assessment processes.",
                    "phrase": "Optimize performance across ML evaluation systems"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "Supporting improvements to AI-powered tools through validation is about ensuring the quality and reliability of models that power these tools.",
                    "phrase": "Support improvements to GitLab's AI-powered tools through validation"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "The role requires integrating validation solutions with feature teams, which involves software development to embed these validation capabilities into existing or new applications.",
                    "phrase": "Collaborate with feature teams to integrate validation solutions"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "Ensuring solutions align with infrastructure and security protocols involves the software development practices needed to deploy and maintain systems within an established environment.",
                    "phrase": "Ensure all solutions align with GitLab's infrastructure and security protocols"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Contributing to evaluation infrastructure consolidation efforts and building scalable evaluation pipelines and frameworks are key aspects of operationalizing and maintaining AI evaluation systems.",
                    "phrase": "Contribute to evaluation infrastructure consolidation efforts"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "The role focuses on scaling validation infrastructure, which is a core component of MLOps, ensuring that evaluation processes can handle increased load and complexity.",
                    "phrase": "scale our validation infrastructure"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Optimizing dataset management is a direct task related to the preparation and handling of data for AI models.",
                    "phrase": "optimize dataset management"
                }
            ],
            "soft_skills": [
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "Working closely with other AI feature teams"
                },
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "Collaborate with feature teams to integrate validation solutions"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "designing scalable solutions for LLM evaluation"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "consolidating disparate validation tools"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "shaping the future of AI-powered features at GitLab"
                },
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "phrase": "contributing to GitLab's innovative AI roadmap"
                }
            ],
            "technologies": [
                {
                    "category": "TECH3: LLM / Generative Models",
                    "phrase": "LLM"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "ML evaluation systems"
                }
            ]
        }
    }
}