{
    "job_id": 1182,
    "job_details": {
        "job_id": 1182,
        "Organisatienaam": "Deepl",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "Data Platform Engineer",
        "Standplaats": "Amsterdam",
        "Vacaturelink (origineel)": "jobsonline.nl",
        "Contactpersoon": "Allround Tandartsassistent",
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Data engineer (m/v/x)",
        "Opleidingsniveau": "Onbekend",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "We are looking for an Infrastructure Engineer to join a team of versatile engineers that craft the infrastructure, libraries and tooling to support data ingestion, processing, monitoring and lineage at DeepL. The main goal of the Data Platform is to combine different data sources, both internal and external, and make them available to our stakeholders company-wide: Developers, Product Development, Data Science and Management. We provide support at all stages of the data lifecycle to ensure that users can access the data they need to make data-driven decisions and to provide a framework for high data quality and transparent data security., * Administer Kafka clusters that play a central role for data exchange in the company\n     * Set up and maintain third party tools in Kubernetes that are used for data visualization, discovery and lineage\n     * Monitoring in Prometheus and Grafana - you build and set up solutions that make sure our systems are operating smoothly\n     * Help improve our CI/CD framework for reliable builds and deployments\n     * Write tools and services in Go and Python, Diverse and internationally distributed team: joining our team means becoming part of a large, global community with people of more than 90 nationalities. We're more than just colleagues; we're a group of professionals with a shared mission to connect diverse cultures. Our global presence is growing-we've doubled in size nearly every year, with our employees based in the UK, Germany, the Netherlands, Poland, the US, and Japan, and we continue to expand our network.\n\n   - Open communication, regular feedback: as a language-focused company, we value the importance of clear, honest communication. We value smooth collaboration, direct and actionable feedback, and believe that leading with empathy makes us better together.\n\n   - Remote work, flexible hours: whether you're near or in our hubs in cities like Cologne, Berlin, Amsterdam, London, Austin, or Tokyo, or prefer the comfort of your own home, you decide where your office is. We offer remote opportunities, flexible working hours and trust in your productivity, all in sync with your team's general locations and time zones to foster effective and seamless collaboration. Our aim is to integrate your work with your lifestyle, ensuring a balance that respects both your needs and our operational requirements.\n\n   - Regular in-person team events: we bond over vibrant events that are as unique as our team, from local team and business unit gatherings, to new-joiner onboardings, to company-wide events that bring us all together-literally.\n\n   - Monthly full-day hacking sessions: every month, we have Hack Fridays, where you can spend your time diving into a project you're passionate about and get the opportunity to work with other teams-we value your initiatives, impact, and creativity.\n\n   - Comprehensive health insurance: your health comes first. With our comprehensive insurance, we'll make sure you're covered from head to toe.\n\n   - 30 days of annual leave: we value your peace of mind. With 30 days off (excluding public holidays) and access to mental health resources, we make sure you're as strong mentally as you are professionally.\n   - Annual learning budget: because we never stop learning, we've set up an annual budget for your professional development-pick a learning path which contributes to your career development and we'll back you up.",
        "Datum gevonden": "2024-07-22",
        "Beroepsgroep": "Systeemontwikkelaars en -analisten",
        "Beroepsklasse": "Informatie- en communicatietechnologie",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Overig / Onbekend",
        "Organisatiegrootte": "Onbekend",
        "Jaar (van datum gevonden)": 2024,
        "Maand (van datum gevonden)": 7,
        "full_text": "Data Platform Engineer\n\nWe are looking for an Infrastructure Engineer to join a team of versatile engineers that craft the infrastructure, libraries and tooling to support data ingestion, processing, monitoring and lineage at DeepL. The main goal of the Data Platform is to combine different data sources, both internal and external, and make them available to our stakeholders company-wide: Developers, Product Development, Data Science and Management. We provide support at all stages of the data lifecycle to ensure that users can access the data they need to make data-driven decisions and to provide a framework for high data quality and transparent data security., * Administer Kafka clusters that play a central role for data exchange in the company\n     * Set up and maintain third party tools in Kubernetes that are used for data visualization, discovery and lineage\n     * Monitoring in Prometheus and Grafana - you build and set up solutions that make sure our systems are operating smoothly\n     * Help improve our CI/CD framework for reliable builds and deployments\n     * Write tools and services in Go and Python, Diverse and internationally distributed team: joining our team means becoming part of a large, global community with people of more than 90 nationalities. We're more than just colleagues; we're a group of professionals with a shared mission to connect diverse cultures. Our global presence is growing-we've doubled in size nearly every year, with our employees based in the UK, Germany, the Netherlands, Poland, the US, and Japan, and we continue to expand our network.\n\n   - Open communication, regular feedback: as a language-focused company, we value the importance of clear, honest communication. We value smooth collaboration, direct and actionable feedback, and believe that leading with empathy makes us better together.\n\n   - Remote work, flexible hours: whether you're near or in our hubs in cities like Cologne, Berlin, Amsterdam, London, Austin, or Tokyo, or prefer the comfort of your own home, you decide where your office is. We offer remote opportunities, flexible working hours and trust in your productivity, all in sync with your team's general locations and time zones to foster effective and seamless collaboration. Our aim is to integrate your work with your lifestyle, ensuring a balance that respects both your needs and our operational requirements.\n\n   - Regular in-person team events: we bond over vibrant events that are as unique as our team, from local team and business unit gatherings, to new-joiner onboardings, to company-wide events that bring us all together-literally.\n\n   - Monthly full-day hacking sessions: every month, we have Hack Fridays, where you can spend your time diving into a project you're passionate about and get the opportunity to work with other teams-we value your initiatives, impact, and creativity.\n\n   - Comprehensive health insurance: your health comes first. With our comprehensive insurance, we'll make sure you're covered from head to toe.\n\n   - 30 days of annual leave: we value your peace of mind. With 30 days off (excluding public holidays) and access to mental health resources, we make sure you're as strong mentally as you are professionally.\n   - Annual learning budget: because we never stop learning, we've set up an annual budget for your professional development-pick a learning path which contributes to your career development and we'll back you up."
    },
    "analysis": {
        "profile_classification": {
            "profile": "Ambiguous",
            "rationale": "The job description focuses heavily on data infrastructure, data pipelines, and operational aspects of data management (Kafka, Kubernetes, Prometheus, Grafana, CI/CD). While it mentions making data available to Data Science and Management, it does not describe the core activities of building, training, or fine-tuning ML/GenAI models, nor does it involve advanced prompt engineering, RAG, or agent development. The technologies and tasks described align more with traditional data engineering and infrastructure roles rather than specialized ML or GenAI engineering. Therefore, it falls under the 'Ambiguous' category as it's not a technical AI role as defined in the Coding Book."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The description explicitly mentions 'data ingestion, processing, monitoring and lineage' and the goal to 'combine different data sources... and make them available'. Administering Kafka clusters for data exchange and setting up tools for data visualization, discovery, and lineage directly relate to data pipeline and infrastructure management.",
                    "phrase": "craft the infrastructure, libraries and tooling to support data ingestion, processing, monitoring and lineage"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Administering Kafka clusters is a core task in managing data pipelines and ensuring data exchange within an organization.",
                    "phrase": "Administer Kafka clusters that play a central role for data exchange in the company"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Setting up and maintaining third-party tools in Kubernetes, especially for data-related functions like visualization, discovery, and lineage, falls under managing infrastructure and deployment, which is part of operations engineering.",
                    "phrase": "Set up and maintain third party tools in Kubernetes that are used for data visualization, discovery and lineage"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Monitoring systems using Prometheus and Grafana and ensuring systems operate smoothly is a direct responsibility within operations engineering.",
                    "phrase": "Monitoring in Prometheus and Grafana - you build and set up solutions that make sure our systems are operating smoothly"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Improving CI/CD frameworks for reliable builds and deployments is a key aspect of operations engineering, ensuring efficient and stable software delivery.",
                    "phrase": "Help improve our CI/CD framework for reliable builds and deployments"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "Writing tools and services in Go and Python indicates traditional software development activities, even if they are in support of the data platform.",
                    "phrase": "Write tools and services in Go and Python"
                },
                {
                    "category": "TASK1: Business Understanding",
                    "justification": "The main goal of the Data Platform is to make data available to stakeholders company-wide for 'data-driven decisions' and to ensure 'high data quality and transparent data security', which aligns with understanding business needs and providing data solutions.",
                    "phrase": "The main goal of the Data Platform is to combine different data sources, both internal and external, and make them available to our stakeholders company-wide: Developers, Product Development, Data Science and Management. We provide support at all stages of the data lifecycle to ensure that users can access the data they need to make data-driven decisions and to provide a framework for high data quality and transparent data security."
                }
            ],
            "soft_skills": [
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "Diverse and internationally distributed team: joining our team means becoming part of a large, global community with people of more than 90 nationalities."
                },
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "Open communication, regular feedback: as a language-focused company, we value the importance of clear, honest communication. We value smooth collaboration, direct and actionable feedback, and believe that leading with empathy makes us better together."
                },
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "phrase": "Annual learning budget: because we never stop learning, we've set up an annual budget for your professional development-pick a learning path which contributes to your career development and we'll back you up."
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "Monthly full-day hacking sessions: every month, we have Hack Fridays, where you can spend your time diving into a project you're passionate about and get the opportunity to work with other teams-we value your initiatives, impact, and creativity."
                }
            ],
            "technologies": [
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "Kafka"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "Kubernetes"
                },
                {
                    "category": "TECH5: Vector Stores & Search",
                    "phrase": "Prometheus"
                },
                {
                    "category": "TECH5: Vector Stores & Search",
                    "phrase": "Grafana"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "CI/CD"
                },
                {
                    "category": "TECH1: Programming Languages",
                    "phrase": "Go"
                },
                {
                    "category": "TECH1: Programming Languages",
                    "phrase": "Python"
                }
            ]
        }
    }
}