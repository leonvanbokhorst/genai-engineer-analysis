{
    "job_id": 754,
    "job_details": {
        "job_id": 754,
        "Organisatienaam": "Garanti BBVA International",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "Finance Data Engineer / Data Analyst Role",
        "Standplaats": "Amsterdam",
        "Vacaturelink (origineel)": "nationalevacaturebank.nl",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Data analyst (m/v/x)",
        "Opleidingsniveau": "Onbekend",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "Are you a skilled Finance Data Engineer or Data Analyst looking to modernize financial data management processes in the banking domain? We're hiring a dynamic professional to join our team and lead the transformation of legacy systems like MS Access databases and Excel reports into a robust, scalable, and version-controlled environment using modern tools and best practices like like SQL Server, Git, Python.\n       The ideal candidate will have deep understanding of banking domain, especially financial products and calculations, core banking system data, and experience in working with tools like SQL Server, Git, Python, as well as being able to understand and reverse-engineer complex legacy setups that use MS Access databases, text files and Excel reports.\n       Your role:\n       In this role, you'll collaborate with key departments- Financial Control , Management Reporting , and Risk Management -to design efficient data models, implement centralized solutions, and build automation pipelines . Your efforts will break down data silos, improve data integrity, and enhance accessibility, ensuring seamless integration across systems., Legacy System Transition\n       * Migrate MS Access databases and spreadsheets to a centralized and maintainable SQL Server setup.\n       * Replace ad hoc workflows with structured, automated, and version-controlled pipelines.\n       * Work with core banking system data, including structured and non-structured text files\n       * Ability to work with limited documentation and follow complex legacy pipelines\n       Data Integration and Collaboration\n       * Collaborate with various departments to understand data needs and eliminate silos.\n       * Design and implement efficient data-sharing solutions that comply with industry standards and security policies.\n       Data Modelling and Management\n       * Develop and maintain robust, scalable data models tailored to business needs.\n       * Optimize database structures to improve performance and accessibility.\n       * Work with the BI & reporting teams to make sure the data models are suitable for existing reports and future reporting needs\n       Tooling and Automation\n       * Implement and manage ETL pipelines using Python, SQL, Airflow, or similar tools.\n       * Introduce automated solutions to streamline data collection, transformation, and analysis.\n       * Make sure all solutions are future proof and extensible as we keep working on transition to cloud-based systems\n       Version Control and Best Practices\n       * Establish Git-based workflows for version control and collaborative development.\n       * Enforce best practices in code development, testing, and deployment.\n       * Ensure all solutions have tests in place, covering various scenarios and regressions\n       Knowledge Sharing and Training\n       * Train staff on new systems, tools, and workflows to ensure smooth transitions.\n       * Serve as a resource for resolving technical challenges related to data systems.\n       Compliance and Security\n       * Ensure all data solutions align with regulatory requirements and internal policies, including GDPR and DORA\n       * Implement measures to safeguard sensitive data from unauthorized access.\n       Who are we looking for?\n       A colleague open-minded, very curious by nature and passionate about your job. You are not afraid to handle various tasks at the same time and meet tight deadlines. You are thinking proactively and always a step ahead, finding solutions with both internal and external stakeholders. You are a cooperating person who listens and invests in the work & persons to achieve common goals. You must naturally think out of the box and navigate in a fast changing and complex environment by questioning the how & the why., If you are ready to join our team and contribute to the success of company, we encourage you to apply by submitting your resume and a cover letter via Online Application: Click on the link below to access our online application portal and submit your application.\n       We appreciate your interest in our organization and look forward to reviewing your application. Should you have any questions or require further information, please don't hesitate to reach out.\n       Please note that we do not appreciate any acquisition efforts for this vacancy by recruitment agencies.\n       Fidelity Investments logo\n       Generative AI Keras LangChain LLMs Machine Learning ML models Python +4\n       Flex hours Flex vacation Health care Salary bonus Team events\n       EUR 58K EUR 58K",
        "Datum gevonden": "2024-11-06",
        "Beroepsgroep": "Systeemontwikkelaars en -analisten",
        "Beroepsklasse": "Informatie- en communicatietechnologie",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Overig / Onbekend",
        "Organisatiegrootte": "Onbekend",
        "Jaar (van datum gevonden)": 2024,
        "Maand (van datum gevonden)": 11,
        "full_text": "Finance Data Engineer / Data Analyst Role\n\nAre you a skilled Finance Data Engineer or Data Analyst looking to modernize financial data management processes in the banking domain? We're hiring a dynamic professional to join our team and lead the transformation of legacy systems like MS Access databases and Excel reports into a robust, scalable, and version-controlled environment using modern tools and best practices like like SQL Server, Git, Python.\n       The ideal candidate will have deep understanding of banking domain, especially financial products and calculations, core banking system data, and experience in working with tools like SQL Server, Git, Python, as well as being able to understand and reverse-engineer complex legacy setups that use MS Access databases, text files and Excel reports.\n       Your role:\n       In this role, you'll collaborate with key departments- Financial Control , Management Reporting , and Risk Management -to design efficient data models, implement centralized solutions, and build automation pipelines . Your efforts will break down data silos, improve data integrity, and enhance accessibility, ensuring seamless integration across systems., Legacy System Transition\n       * Migrate MS Access databases and spreadsheets to a centralized and maintainable SQL Server setup.\n       * Replace ad hoc workflows with structured, automated, and version-controlled pipelines.\n       * Work with core banking system data, including structured and non-structured text files\n       * Ability to work with limited documentation and follow complex legacy pipelines\n       Data Integration and Collaboration\n       * Collaborate with various departments to understand data needs and eliminate silos.\n       * Design and implement efficient data-sharing solutions that comply with industry standards and security policies.\n       Data Modelling and Management\n       * Develop and maintain robust, scalable data models tailored to business needs.\n       * Optimize database structures to improve performance and accessibility.\n       * Work with the BI & reporting teams to make sure the data models are suitable for existing reports and future reporting needs\n       Tooling and Automation\n       * Implement and manage ETL pipelines using Python, SQL, Airflow, or similar tools.\n       * Introduce automated solutions to streamline data collection, transformation, and analysis.\n       * Make sure all solutions are future proof and extensible as we keep working on transition to cloud-based systems\n       Version Control and Best Practices\n       * Establish Git-based workflows for version control and collaborative development.\n       * Enforce best practices in code development, testing, and deployment.\n       * Ensure all solutions have tests in place, covering various scenarios and regressions\n       Knowledge Sharing and Training\n       * Train staff on new systems, tools, and workflows to ensure smooth transitions.\n       * Serve as a resource for resolving technical challenges related to data systems.\n       Compliance and Security\n       * Ensure all data solutions align with regulatory requirements and internal policies, including GDPR and DORA\n       * Implement measures to safeguard sensitive data from unauthorized access.\n       Who are we looking for?\n       A colleague open-minded, very curious by nature and passionate about your job. You are not afraid to handle various tasks at the same time and meet tight deadlines. You are thinking proactively and always a step ahead, finding solutions with both internal and external stakeholders. You are a cooperating person who listens and invests in the work & persons to achieve common goals. You must naturally think out of the box and navigate in a fast changing and complex environment by questioning the how & the why., If you are ready to join our team and contribute to the success of company, we encourage you to apply by submitting your resume and a cover letter via Online Application: Click on the link below to access our online application portal and submit your application.\n       We appreciate your interest in our organization and look forward to reviewing your application. Should you have any questions or require further information, please don't hesitate to reach out.\n       Please note that we do not appreciate any acquisition efforts for this vacancy by recruitment agencies.\n       Fidelity Investments logo\n       Generative AI Keras LangChain LLMs Machine Learning ML models Python +4\n       Flex hours Flex vacation Health care Salary bonus Team events\n       EUR 58K EUR 58K"
    },
    "analysis": {
        "profile_classification": {
            "profile": "Ambiguous",
            "rationale": "The job description focuses heavily on traditional data engineering, data analysis, and migrating legacy systems to a SQL Server environment. While it mentions 'Generative AI', 'Keras', 'LangChain', 'LLMs', and 'Machine Learning' in a list of technologies, these are not integrated into the core responsibilities or tasks described. The primary focus is on modernizing financial data management and building pipelines, which aligns more with a Data Engineer or Data Analyst role rather than a specialized GenAI Engineer or ML Engineer. The mention of AI technologies appears to be a broad list of potentially relevant tech rather than a core requirement of the role."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The role involves modernizing financial data management, migrating legacy systems (MS Access, Excel) to SQL Server, building automation pipelines, working with core banking system data, and implementing ETL pipelines.",
                    "phrase": "modernize financial data management processes"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The core of the role is migrating data from older formats to a structured database.",
                    "phrase": "Migrate MS Access databases and spreadsheets to a centralized and maintainable SQL Server setup."
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Replacing manual processes with automated data flows is a key data engineering task.",
                    "phrase": "Replace ad hoc workflows with structured, automated, and version-controlled pipelines."
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Working with raw data from core systems is a fundamental data engineering activity.",
                    "phrase": "Work with core banking system data, including structured and non-structured text files"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Understanding and re-engineering existing data processes is part of data engineering.",
                    "phrase": "Ability to work with limited documentation and follow complex legacy pipelines"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Integrating data from different sources and ensuring its quality is a data engineering responsibility.",
                    "phrase": "Collaborate with various departments to understand data needs and eliminate silos."
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Designing and implementing data flows for sharing and integration is a data engineering task.",
                    "phrase": "Design and implement efficient data-sharing solutions that comply with industry standards and security policies."
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Creating and managing the structure of data for efficient use is a core data engineering function.",
                    "phrase": "Develop and maintain robust, scalable data models tailored to business needs."
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Improving how data is stored and accessed is a data engineering task.",
                    "phrase": "Optimize database structures to improve performance and accessibility."
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Ensuring data structures meet reporting needs is part of data engineering for analytics.",
                    "phrase": "Work with the BI & reporting teams to make sure the data models are suitable for existing reports and future reporting needs"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Building data pipelines for extraction, transformation, and loading is a primary data engineering task.",
                    "phrase": "Implement and manage ETL pipelines using Python, SQL, Airflow, or similar tools."
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Automating data processes is a key goal of data engineering.",
                    "phrase": "Introduce automated solutions to streamline data collection, transformation, and analysis."
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Planning for future scalability and cloud migration is part of modern data engineering.",
                    "phrase": "Make sure all solutions are future proof and extensible as we keep working on transition to cloud-based systems"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "Establishing version control workflows is a standard software development practice applied to data pipelines and scripts.",
                    "phrase": "Establish Git-based workflows for version control and collaborative development."
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "Enforcing quality standards in code and deployment is a software development practice.",
                    "phrase": "Enforce best practices in code development, testing, and deployment."
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "Implementing tests for data solutions ensures code quality and reliability, a software development practice.",
                    "phrase": "Ensure all solutions have tests in place, covering various scenarios and regressions"
                },
                {
                    "category": "TASK1: Business Understanding",
                    "justification": "The role requires understanding the financial domain, banking products, and calculations to effectively manage data.",
                    "phrase": "deep understanding of banking domain, especially financial products and calculations, core banking system data"
                },
                {
                    "category": "TASK1: Business Understanding",
                    "justification": "Collaboration with specific finance departments indicates a need to understand their business needs.",
                    "phrase": "collaborate with key departments- Financial Control , Management Reporting , and Risk Management"
                },
                {
                    "category": "TASK1: Business Understanding",
                    "justification": "Ensuring data solutions meet regulatory and policy requirements is a business-aligned technical task.",
                    "phrase": "Ensure all data solutions align with regulatory requirements and internal policies, including GDPR and DORA"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "While not explicitly MLOps, the focus on 'automated, and version-controlled pipelines' and 'future proof and extensible' solutions touches on operational aspects of data management.",
                    "phrase": "build automation pipelines"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Implementing and managing ETL pipelines with tools like Airflow is part of operationalizing data flows.",
                    "phrase": "Implement and manage ETL pipelines using Python, SQL, Airflow, or similar tools."
                },
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "justification": "The role requires working with various departments and training staff.",
                    "phrase": "collaborate with key departments"
                },
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "justification": "The description emphasizes cooperation and listening to achieve common goals.",
                    "phrase": "You are a cooperating person who listens and invests in the work & persons to achieve common goals."
                },
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "justification": "The role involves modernizing systems and transitioning to new tools and cloud-based systems, requiring adaptability.",
                    "phrase": "lead the transformation of legacy systems"
                },
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "justification": "The need to understand and reverse-engineer legacy systems implies learning and adapting to existing complex setups.",
                    "phrase": "understand and reverse-engineer complex legacy setups"
                },
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "justification": "The fast-changing and complex environment requires adaptability.",
                    "phrase": "navigate in a fast changing and complex environment"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "justification": "The role involves solving complex problems related to legacy systems and data silos.",
                    "phrase": "reverse-engineer complex legacy setups"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "justification": "The description highlights finding solutions and thinking proactively.",
                    "phrase": "thinking proactively and always a step ahead, finding solutions"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "justification": "Questioning the 'how & the why' indicates a problem-solving and analytical approach.",
                    "phrase": "questioning the how & the why"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "justification": "The role is about leading transformation and modernizing systems, implying initiative.",
                    "phrase": "lead the transformation of legacy systems"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "justification": "The description mentions being proactive and thinking ahead.",
                    "phrase": "thinking proactively and always a step ahead"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "justification": "The phrase 'think out of the box' suggests an innovative approach.",
                    "phrase": "naturally think out of the box"
                }
            ],
            "soft_skills": [
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "collaborate with key departments"
                },
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "cooperating person who listens and invests in the work & persons to achieve common goals"
                },
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "phrase": "lead the transformation of legacy systems"
                },
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "phrase": "understand and reverse-engineer complex legacy setups"
                },
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "phrase": "navigate in a fast changing and complex environment"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "reverse-engineer complex legacy setups"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "thinking proactively and always a step ahead, finding solutions"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "questioning the how & the why"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "lead the transformation of legacy systems"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "thinking proactively and always a step ahead"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "naturally think out of the box"
                }
            ],
            "technologies": [
                {
                    "category": "TECH1: Programming Languages",
                    "phrase": "Python"
                },
                {
                    "category": "TECH1: Programming Languages",
                    "phrase": "SQL"
                },
                {
                    "category": "TECH2: Cloud Platforms & Services",
                    "phrase": "cloud-based systems"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "Airflow"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "Git"
                },
                {
                    "category": "TECH9: Data Storage",
                    "phrase": "MS Access databases"
                },
                {
                    "category": "TECH9: Data Storage",
                    "phrase": "SQL Server"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "data models"
                },
                {
                    "category": "TECH11: Data Analysis",
                    "phrase": "Excel reports"
                },
                {
                    "category": "TECH3: LLM / Generative Models",
                    "phrase": "Generative AI"
                },
                {
                    "category": "TECH3: LLM / Generative Models",
                    "phrase": "LLMs"
                },
                {
                    "category": "TECH4: LLM Frameworks & Libraries",
                    "phrase": "LangChain"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "Keras"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "Machine Learning"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "ML models"
                }
            ]
        }
    }
}