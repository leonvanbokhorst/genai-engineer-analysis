{
    "job_id": 754,
    "job_details": {
        "job_id": 754,
        "Organisatienaam": "Garanti BBVA International",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "Finance Data Engineer / Data Analyst Role",
        "Standplaats": "Amsterdam",
        "Vacaturelink (origineel)": "nationalevacaturebank.nl",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Data analyst (m/v/x)",
        "Opleidingsniveau": "Onbekend",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "Are you a skilled Finance Data Engineer or Data Analyst looking to modernize financial data management processes in the banking domain? We're hiring a dynamic professional to join our team and lead the transformation of legacy systems like MS Access databases and Excel reports into a robust, scalable, and version-controlled environment using modern tools and best practices like like SQL Server, Git, Python.\n       The ideal candidate will have deep understanding of banking domain, especially financial products and calculations, core banking system data, and experience in working with tools like SQL Server, Git, Python, as well as being able to understand and reverse-engineer complex legacy setups that use MS Access databases, text files and Excel reports.\n       Your role:\n       In this role, you'll collaborate with key departments- Financial Control , Management Reporting , and Risk Management -to design efficient data models, implement centralized solutions, and build automation pipelines . Your efforts will break down data silos, improve data integrity, and enhance accessibility, ensuring seamless integration across systems., Legacy System Transition\n       * Migrate MS Access databases and spreadsheets to a centralized and maintainable SQL Server setup.\n       * Replace ad hoc workflows with structured, automated, and version-controlled pipelines.\n       * Work with core banking system data, including structured and non-structured text files\n       * Ability to work with limited documentation and follow complex legacy pipelines\n       Data Integration and Collaboration\n       * Collaborate with various departments to understand data needs and eliminate silos.\n       * Design and implement efficient data-sharing solutions that comply with industry standards and security policies.\n       Data Modelling and Management\n       * Develop and maintain robust, scalable data models tailored to business needs.\n       * Optimize database structures to improve performance and accessibility.\n       * Work with the BI & reporting teams to make sure the data models are suitable for existing reports and future reporting needs\n       Tooling and Automation\n       * Implement and manage ETL pipelines using Python, SQL, Airflow, or similar tools.\n       * Introduce automated solutions to streamline data collection, transformation, and analysis.\n       * Make sure all solutions are future proof and extensible as we keep working on transition to cloud-based systems\n       Version Control and Best Practices\n       * Establish Git-based workflows for version control and collaborative development.\n       * Enforce best practices in code development, testing, and deployment.\n       * Ensure all solutions have tests in place, covering various scenarios and regressions\n       Knowledge Sharing and Training\n       * Train staff on new systems, tools, and workflows to ensure smooth transitions.\n       * Serve as a resource for resolving technical challenges related to data systems.\n       Compliance and Security\n       * Ensure all data solutions align with regulatory requirements and internal policies, including GDPR and DORA\n       * Implement measures to safeguard sensitive data from unauthorized access.\n       Who are we looking for?\n       A colleague open-minded, very curious by nature and passionate about your job. You are not afraid to handle various tasks at the same time and meet tight deadlines. You are thinking proactively and always a step ahead, finding solutions with both internal and external stakeholders. You are a cooperating person who listens and invests in the work & persons to achieve common goals. You must naturally think out of the box and navigate in a fast changing and complex environment by questioning the how & the why., If you are ready to join our team and contribute to the success of company, we encourage you to apply by submitting your resume and a cover letter via Online Application: Click on the link below to access our online application portal and submit your application.\n       We appreciate your interest in our organization and look forward to reviewing your application. Should you have any questions or require further information, please don't hesitate to reach out.\n       Please note that we do not appreciate any acquisition efforts for this vacancy by recruitment agencies.\n       Fidelity Investments logo\n       Generative AI Keras LangChain LLMs Machine Learning ML models Python +4\n       Flex hours Flex vacation Health care Salary bonus Team events\n       EUR 58K EUR 58K",
        "Datum gevonden": "2024-11-06",
        "Beroepsgroep": "Systeemontwikkelaars en -analisten",
        "Beroepsklasse": "Informatie- en communicatietechnologie",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Overig / Onbekend",
        "Organisatiegrootte": "Onbekend",
        "Jaar (van datum gevonden)": 2024,
        "Maand (van datum gevonden)": 11,
        "full_text": "Finance Data Engineer / Data Analyst Role\n\nAre you a skilled Finance Data Engineer or Data Analyst looking to modernize financial data management processes in the banking domain? We're hiring a dynamic professional to join our team and lead the transformation of legacy systems like MS Access databases and Excel reports into a robust, scalable, and version-controlled environment using modern tools and best practices like like SQL Server, Git, Python.\n       The ideal candidate will have deep understanding of banking domain, especially financial products and calculations, core banking system data, and experience in working with tools like SQL Server, Git, Python, as well as being able to understand and reverse-engineer complex legacy setups that use MS Access databases, text files and Excel reports.\n       Your role:\n       In this role, you'll collaborate with key departments- Financial Control , Management Reporting , and Risk Management -to design efficient data models, implement centralized solutions, and build automation pipelines . Your efforts will break down data silos, improve data integrity, and enhance accessibility, ensuring seamless integration across systems., Legacy System Transition\n       * Migrate MS Access databases and spreadsheets to a centralized and maintainable SQL Server setup.\n       * Replace ad hoc workflows with structured, automated, and version-controlled pipelines.\n       * Work with core banking system data, including structured and non-structured text files\n       * Ability to work with limited documentation and follow complex legacy pipelines\n       Data Integration and Collaboration\n       * Collaborate with various departments to understand data needs and eliminate silos.\n       * Design and implement efficient data-sharing solutions that comply with industry standards and security policies.\n       Data Modelling and Management\n       * Develop and maintain robust, scalable data models tailored to business needs.\n       * Optimize database structures to improve performance and accessibility.\n       * Work with the BI & reporting teams to make sure the data models are suitable for existing reports and future reporting needs\n       Tooling and Automation\n       * Implement and manage ETL pipelines using Python, SQL, Airflow, or similar tools.\n       * Introduce automated solutions to streamline data collection, transformation, and analysis.\n       * Make sure all solutions are future proof and extensible as we keep working on transition to cloud-based systems\n       Version Control and Best Practices\n       * Establish Git-based workflows for version control and collaborative development.\n       * Enforce best practices in code development, testing, and deployment.\n       * Ensure all solutions have tests in place, covering various scenarios and regressions\n       Knowledge Sharing and Training\n       * Train staff on new systems, tools, and workflows to ensure smooth transitions.\n       * Serve as a resource for resolving technical challenges related to data systems.\n       Compliance and Security\n       * Ensure all data solutions align with regulatory requirements and internal policies, including GDPR and DORA\n       * Implement measures to safeguard sensitive data from unauthorized access.\n       Who are we looking for?\n       A colleague open-minded, very curious by nature and passionate about your job. You are not afraid to handle various tasks at the same time and meet tight deadlines. You are thinking proactively and always a step ahead, finding solutions with both internal and external stakeholders. You are a cooperating person who listens and invests in the work & persons to achieve common goals. You must naturally think out of the box and navigate in a fast changing and complex environment by questioning the how & the why., If you are ready to join our team and contribute to the success of company, we encourage you to apply by submitting your resume and a cover letter via Online Application: Click on the link below to access our online application portal and submit your application.\n       We appreciate your interest in our organization and look forward to reviewing your application. Should you have any questions or require further information, please don't hesitate to reach out.\n       Please note that we do not appreciate any acquisition efforts for this vacancy by recruitment agencies.\n       Fidelity Investments logo\n       Generative AI Keras LangChain LLMs Machine Learning ML models Python +4\n       Flex hours Flex vacation Health care Salary bonus Team events\n       EUR 58K EUR 58K"
    },
    "analysis": {
        "profile_classification": {
            "profile": "Ambiguous / Not Relevant",
            "confidence_score": 2,
            "rationale": "The job description focuses heavily on traditional data engineering, data analysis, and migration of legacy systems. While it mentions modern tools and best practices, there is no explicit mention or strong implication of using generative AI models, LLMs, or related technologies, which are central to the GenAI Engineer profile."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "task": "TASK2: Data Engineering",
                    "phrases": [
                        "modernize financial data management processes",
                        "transformation of legacy systems like MS Access databases and Excel reports into a robust, scalable, and version-controlled environment",
                        "design efficient data models",
                        "implement centralized solutions",
                        "build automation pipelines",
                        "break down data silos, improve data integrity, and enhance accessibility",
                        "Migrate MS Access databases and spreadsheets to a centralized and maintainable SQL Server setup",
                        "Replace ad hoc workflows with structured, automated, and version-controlled pipelines",
                        "Work with core banking system data, including structured and non-structured text files",
                        "Ability to work with limited documentation and follow complex legacy pipelines",
                        "Collaborate with various departments to understand data needs and eliminate silos",
                        "Design and implement efficient data-sharing solutions that comply with industry standards and security policies",
                        "Develop and maintain robust, scalable data models tailored to business needs",
                        "Optimize database structures to improve performance and accessibility",
                        "Work with the BI & reporting teams to make sure the data models are suitable for existing reports and future reporting needs",
                        "Implement and manage ETL pipelines using Python, SQL, Airflow, or similar tools",
                        "Introduce automated solutions to streamline data collection, transformation, and analysis",
                        "Make sure all solutions are future proof and extensible as we keep working on transition to cloud-based systems",
                        "Establish Git-based workflows for version control and collaborative development",
                        "Enforce best practices in code development, testing, and deployment",
                        "Ensure all solutions have tests in place, covering various scenarios and regressions",
                        "Train staff on new systems, tools, and workflows to ensure smooth transitions",
                        "Serve as a resource for resolving technical challenges related to data systems",
                        "Ensure all data solutions align with regulatory requirements and internal policies, including GDPR and DORA",
                        "Implement measures to safeguard sensitive data from unauthorized access"
                    ],
                    "justification": "The job description extensively details tasks related to data migration, pipeline building, ETL processes, data modeling, and managing data infrastructure, all of which fall under data engineering."
                },
                {
                    "task": "TASK1: Business Understanding",
                    "phrases": [
                        "Finance Data Engineer / Data Analyst Role",
                        "modernize financial data management processes in the banking domain",
                        "deep understanding of banking domain, especially financial products and calculations, core banking system data",
                        "collaborate with key departments- Financial Control , Management Reporting , and Risk Management",
                        "understand data needs and eliminate silos",
                        "tailored to business needs",
                        "make sure the data models are suitable for existing reports and future reporting needs",
                        "align with regulatory requirements and internal policies, including GDPR and DORA"
                    ],
                    "justification": "The role requires a strong understanding of the finance and banking domain, including financial products, calculations, and regulatory compliance, indicating a need to align technical work with business objectives."
                },
                {
                    "task": "TASK4: Software Development",
                    "phrases": [
                        "version-controlled environment using modern tools and best practices like like SQL Server, Git, Python",
                        "version-controlled pipelines",
                        "version control and collaborative development",
                        "code development, testing, and deployment",
                        "transition to cloud-based systems"
                    ],
                    "justification": "The role involves using software development tools like Git for version control, writing Python scripts for automation, and deploying solutions, which are aspects of software development applied to data engineering."
                },
                {
                    "task": "TASK5: Operations Engineering (MLOps)",
                    "phrases": [
                        "version-controlled environment",
                        "build automation pipelines",
                        "structured, automated, and version-controlled pipelines",
                        "Implement and manage ETL pipelines",
                        "Introduce automated solutions",
                        "Make sure all solutions are future proof and extensible",
                        "Establish Git-based workflows for version control and collaborative development",
                        "Enforce best practices in code development, testing, and deployment",
                        "Ensure all solutions have tests in place, covering various scenarios and regressions"
                    ],
                    "justification": "The emphasis on automation, version control (Git), testing, and building maintainable pipelines points to operational aspects of managing data systems, akin to MLOps principles but applied to data engineering."
                },
                {
                    "task": "TASK3: Modeling",
                    "phrases": [
                        "design efficient data models",
                        "Develop and maintain robust, scalable data models tailored to business needs",
                        "Optimize database structures"
                    ],
                    "justification": "The job involves designing and maintaining data models and optimizing database structures, which is a form of modeling, though not specifically machine learning or generative AI modeling."
                }
            ],
            "technologies": [
                {
                    "technology": "SQL Server",
                    "type": "TECH9: Data Storage"
                },
                {
                    "technology": "Git",
                    "type": "TECH6: MLOps & Data Pipelines"
                },
                {
                    "technology": "Python",
                    "type": "TECH1: Programming Languages"
                },
                {
                    "technology": "MS Access databases",
                    "type": "TECH9: Data Storage"
                },
                {
                    "technology": "Excel",
                    "type": "TECH11: Data Analysis"
                },
                {
                    "technology": "SQL",
                    "type": "TECH11: Data Analysis"
                },
                {
                    "technology": "Airflow",
                    "type": "TECH6: MLOps & Data Pipelines"
                },
                {
                    "technology": "GDPR",
                    "type": "SKILL4: Ethical & Legal Responsibility"
                },
                {
                    "technology": "DORA",
                    "type": "SKILL4: Ethical & Legal Responsibility"
                }
            ],
            "soft_skills": [
                {
                    "skill": "collaborate with key departments",
                    "type": "SKILL1: Communication & Collaboration"
                },
                {
                    "skill": "understand data needs",
                    "type": "SKILL1: Communication & Collaboration"
                },
                {
                    "skill": "eliminate silos",
                    "type": "SKILL1: Communication & Collaboration"
                },
                {
                    "skill": "Design and implement efficient data-sharing solutions that comply with industry standards and security policies",
                    "type": "SKILL1: Communication & Collaboration"
                },
                {
                    "skill": "Work with the BI & reporting teams",
                    "type": "SKILL1: Communication & Collaboration"
                },
                {
                    "skill": "open-minded",
                    "type": "SKILL2: Learning & Adaptability"
                },
                {
                    "skill": "very curious by nature",
                    "type": "SKILL2: Learning & Adaptability"
                },
                {
                    "skill": "passionate about your job",
                    "type": "SKILL5: Innovation & Ownership"
                },
                {
                    "skill": "not afraid to handle various tasks at the same time and meet tight deadlines",
                    "type": "SKILL3: Problem Solving & Pragmatism"
                },
                {
                    "skill": "thinking proactively and always a step ahead",
                    "type": "SKILL3: Problem Solving & Pragmatism"
                },
                {
                    "skill": "finding solutions with both internal and external stakeholders",
                    "type": "SKILL3: Problem Solving & Pragmatism"
                },
                {
                    "skill": "cooperating person who listens and invests in the work & persons to achieve common goals",
                    "type": "SKILL1: Communication & Collaboration"
                },
                {
                    "skill": "naturally think out of the box",
                    "type": "SKILL3: Problem Solving & Pragmatism"
                },
                {
                    "skill": "navigate in a fast changing and complex environment by questioning the how & the why",
                    "type": "SKILL2: Learning & Adaptability"
                },
                {
                    "skill": "Ensure all data solutions align with regulatory requirements and internal policies, including GDPR and DORA",
                    "type": "SKILL4: Ethical & Legal Responsibility"
                },
                {
                    "skill": "Implement measures to safeguard sensitive data from unauthorized access",
                    "type": "SKILL4: Ethical & Legal Responsibility"
                }
            ]
        }
    }
}