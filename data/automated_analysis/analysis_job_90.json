{
    "job_id": 90,
    "job_details": {
        "job_id": 90,
        "Organisatienaam": "ServiceNow",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "Staff Research Engineer",
        "Standplaats": "Amsterdam",
        "Vacaturelink (origineel)": "servicenow.com",
        "Contactpersoon": "Talent Acquisition",
        "Telefoonnummer": null,
        "E-mail": "talent.acquisition@servicenow.com",
        "Beroep": "Engineer (overig) (m/v/x)",
        "Opleidingsniveau": "WO",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "Team ServiceNow Research does both fundamental and applied research to futureproof AI-powered experiences. We are a group of researchers, applied scientists, and developers who lay the foundations, research, experiment, and de-risk AI technologies that unlock new work experiences in the future. Our Large Language Model (LLM) lab aims to advance the responsible development of general-purpose AI models, particularly Large Language Models. The lab takes the lead in open-science and open-governance initiatives, such as BigCode, in which it develops large language models from scratch, conducts cutting-edge research on them, and establishes responsible data governance practices. Équipe ServiceNow Research fait de la recherche fondamentale et appliquée pour créer des expériences propulsées par l'IA pour tous les usagers de la plateforme Now. Nous sommes un groupe de chercheurs, de scientifiques appliqués et de développeurs qui posent les bases, effectuent des recherches, expérimentent et\n   évaluent les technologies de l'IA afin d'ouvrir la voie vers les expériences de travail de l'avenir. L'objectif principal du laboratoire LLM est de promouvoir le développement responsable de modèles d'intelligence artificielle polyvalents, en particulier des modèles de langage de grande taille. Le laboratoire mène des initiatives de science ouverte, telles que BigCode, dans lesquelles il développe des modèles de langage de grande taille à partir de zéro, mène des recherches de pointe sur ceux-ci, et établit des pratiques responsables de gouvernance des données. Role In collaboration with research scientists in the world-class BigCode core team, you will pursue research projects on foundation models for language and code. You will be expected to: Build and manage end-to-end data pipelines and large datasets. Train large models on multi-node GPU clusters. Present your work in research papers of which you will become a coauthor. En collaboration avec des\n   chercheurs scientifiques dans l'équipe de classe mondiale BigCode , vous contribuerez à des projets de recherche sur les modèles de fondation pour le langage et le code. Vous serez appelé(e) à : Construire et gérer des chaînes de traitement de données de bout en bout et des jeux de données de grande taille. Entraîner des modèles de grande taille sur des grappes de calcul à GPU multi-nœuds. Présenter votre travail dans des articles de recherche dont vous deviendrez coauteur.",
        "Datum gevonden": "2023-06-21",
        "Beroepsgroep": "Engineering (overig)",
        "Beroepsklasse": "Engineering",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Handel",
        "Organisatiegrootte": "1-9",
        "Jaar (van datum gevonden)": 2023,
        "Maand (van datum gevonden)": 6,
        "full_text": "Staff Research Engineer\n\nTeam ServiceNow Research does both fundamental and applied research to futureproof AI-powered experiences. We are a group of researchers, applied scientists, and developers who lay the foundations, research, experiment, and de-risk AI technologies that unlock new work experiences in the future. Our Large Language Model (LLM) lab aims to advance the responsible development of general-purpose AI models, particularly Large Language Models. The lab takes the lead in open-science and open-governance initiatives, such as BigCode, in which it develops large language models from scratch, conducts cutting-edge research on them, and establishes responsible data governance practices. Équipe ServiceNow Research fait de la recherche fondamentale et appliquée pour créer des expériences propulsées par l'IA pour tous les usagers de la plateforme Now. Nous sommes un groupe de chercheurs, de scientifiques appliqués et de développeurs qui posent les bases, effectuent des recherches, expérimentent et\n   évaluent les technologies de l'IA afin d'ouvrir la voie vers les expériences de travail de l'avenir. L'objectif principal du laboratoire LLM est de promouvoir le développement responsable de modèles d'intelligence artificielle polyvalents, en particulier des modèles de langage de grande taille. Le laboratoire mène des initiatives de science ouverte, telles que BigCode, dans lesquelles il développe des modèles de langage de grande taille à partir de zéro, mène des recherches de pointe sur ceux-ci, et établit des pratiques responsables de gouvernance des données. Role In collaboration with research scientists in the world-class BigCode core team, you will pursue research projects on foundation models for language and code. You will be expected to: Build and manage end-to-end data pipelines and large datasets. Train large models on multi-node GPU clusters. Present your work in research papers of which you will become a coauthor. En collaboration avec des\n   chercheurs scientifiques dans l'équipe de classe mondiale BigCode , vous contribuerez à des projets de recherche sur les modèles de fondation pour le langage et le code. Vous serez appelé(e) à : Construire et gérer des chaînes de traitement de données de bout en bout et des jeux de données de grande taille. Entraîner des modèles de grande taille sur des grappes de calcul à GPU multi-nœuds. Présenter votre travail dans des articles de recherche dont vous deviendrez coauteur."
    },
    "analysis": {
        "profile_classification": {
            "profile": "ML Engineer",
            "rationale": "The job description emphasizes building and managing end-to-end data pipelines, training large models on GPU clusters, and conducting research on foundation models for language and code. While it mentions LLMs, the core focus aligns more with the foundational aspects of model development, training, and data pipeline management, which are central to an ML Engineer role, particularly in a research context. The mention of 'foundation models' and training them from scratch points towards deep model work rather than solely application-layer generative AI."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The phrase 'Build and manage end-to-end data pipelines and large datasets' directly relates to the creation and maintenance of data infrastructure and flows.",
                    "phrase": "Build and manage end-to-end data pipelines and large datasets"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "The phrase 'Train large models on multi-node GPU clusters' and 'research projects on foundation models for language and code' clearly indicates the core activity of creating, training, and researching machine learning models.",
                    "phrase": "Train large models on multi-node GPU clusters"
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "The phrase 'research projects on foundation models for language and code' indicates the focus on developing and understanding core AI models.",
                    "phrase": "research projects on foundation models for language and code"
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "While not the primary focus, the role involves working with researchers on projects, implying some level of software development to support research and model implementation.",
                    "phrase": "research projects on foundation models for language and code"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "The phrase 'Train large models on multi-node GPU clusters' implies managing and operating complex computing infrastructure for model training, which falls under MLOps.",
                    "phrase": "Train large models on multi-node GPU clusters"
                }
            ],
            "soft_skills": [
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "phrase": "ServiceNow Research does both fundamental and applied research to futureproof AI-powered experiences."
                },
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "In collaboration with research scientists in the world-class BigCode core team"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "You will pursue research projects"
                },
                {
                    "category": "SKILL4: Ethical & Legal Responsibility",
                    "phrase": "responsible development of general-purpose AI models"
                },
                {
                    "category": "SKILL4: Ethical & Legal Responsibility",
                    "phrase": "responsible data governance practices"
                }
            ],
            "technologies": [
                {
                    "category": "TECH3: LLM / Generative Models",
                    "phrase": "Large Language Model (LLM)"
                },
                {
                    "category": "TECH3: LLM / Generative Models",
                    "phrase": "general-purpose AI models"
                },
                {
                    "category": "TECH3: LLM / Generative Models",
                    "phrase": "foundation models"
                },
                {
                    "category": "TECH2: Cloud Platforms & Services",
                    "phrase": "multi-node GPU clusters"
                },
                {
                    "category": "TECH1: Programming Languages",
                    "phrase": "language"
                },
                {
                    "category": "TECH1: Programming Languages",
                    "phrase": "code"
                }
            ]
        }
    }
}