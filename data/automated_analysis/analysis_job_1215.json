{
    "job_id": 1215,
    "job_details": {
        "job_id": 1215,
        "Organisatienaam": "Koninklijke KPN N.V.",
        "Type adverteerder": "Intermediair",
        "Vacaturetitel": "Data engineer",
        "Standplaats": "Amsterdam",
        "Vacaturelink (origineel)": "yacht.nl",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Data engineer (m/v/x)",
        "Opleidingsniveau": "HBO",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "The Customer Contact Analytics (CCA) Team is responsible for generating continuous insights of KPN's business operations. We achieve this by collecting customer contact events across multiple channels, and processing/analysing them using various techniques (incl. but not limited to AI, GenAI, ML, and NLP). Our application is used by several hundreds of internal users, generating business value in the millions per year. The team is currently composed of a Product Owner and 3 Data Scientists, supported by external ML Engineers. In order to accelerate CCA's performance to near-real time, we are looking for talented Software/Data Engineers.\n\n    Responsibilities:\n\n   * Redesign and optimize our Kafka streaming components to reduce latency, increase throughput, and increase event consumption rate.\n\n   * Upgrading/Developing new components of a multilayered application to enable near real-time data processing.\n\n   * Monitor, maintain and debug all components daily to ensure stability and consistency.",
        "Datum gevonden": "2024-06-26",
        "Beroepsgroep": "Systeemontwikkelaars en -analisten",
        "Beroepsklasse": "Informatie- en communicatietechnologie",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "ICT",
        "Organisatiegrootte": "1-9",
        "Jaar (van datum gevonden)": 2024,
        "Maand (van datum gevonden)": 6,
        "full_text": "Data engineer\n\nThe Customer Contact Analytics (CCA) Team is responsible for generating continuous insights of KPN's business operations. We achieve this by collecting customer contact events across multiple channels, and processing/analysing them using various techniques (incl. but not limited to AI, GenAI, ML, and NLP). Our application is used by several hundreds of internal users, generating business value in the millions per year. The team is currently composed of a Product Owner and 3 Data Scientists, supported by external ML Engineers. In order to accelerate CCA's performance to near-real time, we are looking for talented Software/Data Engineers.\n\n    Responsibilities:\n\n   * Redesign and optimize our Kafka streaming components to reduce latency, increase throughput, and increase event consumption rate.\n\n   * Upgrading/Developing new components of a multilayered application to enable near real-time data processing.\n\n   * Monitor, maintain and debug all components daily to ensure stability and consistency."
    },
    "analysis": {
        "profile_classification": {
            "profile": "Ambiguous",
            "rationale": "The job description focuses heavily on data engineering tasks related to streaming and real-time processing, with mentions of AI, GenAI, ML, and NLP as techniques used by the team. However, it does not specify any direct involvement in building, fine-tuning, or deploying generative models or traditional ML models. The core responsibilities are centered around data infrastructure and processing, not model development or application building using AI/GenAI. Therefore, it does not fit the core definitions of ML Engineer or GenAI Engineer and is classified as Ambiguous."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The responsibilities include 'Redesign and optimize our Kafka streaming components' and 'Upgrading/Developing new components of a multilayered application to enable near real-time data processing', which are core data engineering activities focused on data pipelines and processing infrastructure.",
                    "phrase": "Redesign and optimize our Kafka streaming components"
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The responsibility 'Upgrading/Developing new components of a multilayered application to enable near real-time data processing' directly relates to building and maintaining data processing infrastructure.",
                    "phrase": "Upgrading/Developing new components of a multilayered application to enable near real-time data processing"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "The responsibility 'Monitor, maintain and debug all components daily to ensure stability and consistency' falls under the operational aspects of ensuring system reliability and uptime, which is a key part of MLOps.",
                    "phrase": "Monitor, maintain and debug all components daily to ensure stability and consistency"
                },
                {
                    "category": "TASK1: Business Understanding",
                    "justification": "The description mentions 'generating continuous insights of KPN's business operations' and 'generating business value in the millions per year', indicating a need to understand the business context and impact of the work.",
                    "phrase": "generating continuous insights of KPN's business operations"
                }
            ],
            "soft_skills": [
                {
                    "category": "SKILL2: Learning & Adaptability",
                    "phrase": "talented Software/Data Engineers"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "optimize our Kafka streaming components"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "reduce latency, increase throughput, and increase event consumption rate"
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "Redesign and optimize"
                }
            ],
            "technologies": [
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "Kafka"
                },
                {
                    "category": "TECH3: LLM / Generative Models",
                    "phrase": "GenAI"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "ML"
                },
                {
                    "category": "TECH4: LLM Frameworks & Libraries",
                    "phrase": "NLP"
                }
            ]
        }
    }
}