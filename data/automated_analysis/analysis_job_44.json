{
    "job_id": 44,
    "job_details": {
        "job_id": 44,
        "Organisatienaam": "Databricks",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "Sr. Spark Technical Solutions Engineer",
        "Standplaats": "Amsterdam",
        "Vacaturelink (origineel)": "engineering.jobs",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Solutions architect (m/v/x)",
        "Opleidingsniveau": "Onbekend",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "* Report\n       Strategies to transition to the new stage of data and AI\n     * eBook\n       Discover how to build and manage all your data, analytics and AI use cases.\n     * Report\n       Scaling AI: Key Data Priorities\n       Findings from 600 CIOs across 14 industries\n     * August-November 2023\n       Generation AI is coming to you! Join us to explore all things data, analytics and AI on Lakehouse.\n     * Generative AI Fundamentals\n       Build foundational knowledge, including how to use LLMs in your organization, with 4 videos\n     * Ready to get started?\n       Sr. Spark Technical Solutions Engineer\n       Amsterdam, Netherlands\n       CSQ125R3\n       As a Senior Spark Technical Solutions Engineer, you will provide technical and consulting related solutions for the challenging Spark/ML/AI/Delta/Streaming/Lakehouse reported issues by our customers and resolve any challenges involving the Databricks unified analytics platform with your comprehensive technical and client-facing skills. You will assist our customers in their Databricks journey and provide them with the guidance and expertise that they need to accomplish value and achieve their strategic goals using our products. You will join the EMEA Technical Solutions team based in Amsterdam, Netherlands reporting to the Manager of Spark Technical Solutions.\n       The impact you will have:\n     * Provide best practices guidance for custom-built solutions developed by Databricks customers.\n     * Troubleshoot, resolve and suggest deep code-level analysis of Spark to address customer issues related to Spark core internals, Spark SQL, Structured Streaming, Delta, Lakehouse and other Databricks runtime features.\n     * Assist the customers in setting up reproducible Spark problems with solutions in the areas of Spark SQL, Delta, Memory Management, Performance tuning, Streaming, Data Science and Data Integration areas in Spark.\n     * Work with Account Executives, Solutions Architects and Professional Services for coordinating customer issues and best practices guidelines.\n     * Coordinate with Engineering and Backline Support teams to help report Product defects.\n     * Help create company documentation and knowledge articles.\n     * Participate in weekend (infrequent) and weekday (normal business hrs) on-call rotation.",
        "Datum gevonden": "2023-10-14",
        "Beroepsgroep": "Systeemontwikkelaars en -analisten",
        "Beroepsklasse": "Informatie- en communicatietechnologie",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Overig / Onbekend",
        "Organisatiegrootte": "1-9",
        "Jaar (van datum gevonden)": 2023,
        "Maand (van datum gevonden)": 10,
        "full_text": "Sr. Spark Technical Solutions Engineer\n\n* Report\n       Strategies to transition to the new stage of data and AI\n     * eBook\n       Discover how to build and manage all your data, analytics and AI use cases.\n     * Report\n       Scaling AI: Key Data Priorities\n       Findings from 600 CIOs across 14 industries\n     * August-November 2023\n       Generation AI is coming to you! Join us to explore all things data, analytics and AI on Lakehouse.\n     * Generative AI Fundamentals\n       Build foundational knowledge, including how to use LLMs in your organization, with 4 videos\n     * Ready to get started?\n       Sr. Spark Technical Solutions Engineer\n       Amsterdam, Netherlands\n       CSQ125R3\n       As a Senior Spark Technical Solutions Engineer, you will provide technical and consulting related solutions for the challenging Spark/ML/AI/Delta/Streaming/Lakehouse reported issues by our customers and resolve any challenges involving the Databricks unified analytics platform with your comprehensive technical and client-facing skills. You will assist our customers in their Databricks journey and provide them with the guidance and expertise that they need to accomplish value and achieve their strategic goals using our products. You will join the EMEA Technical Solutions team based in Amsterdam, Netherlands reporting to the Manager of Spark Technical Solutions.\n       The impact you will have:\n     * Provide best practices guidance for custom-built solutions developed by Databricks customers.\n     * Troubleshoot, resolve and suggest deep code-level analysis of Spark to address customer issues related to Spark core internals, Spark SQL, Structured Streaming, Delta, Lakehouse and other Databricks runtime features.\n     * Assist the customers in setting up reproducible Spark problems with solutions in the areas of Spark SQL, Delta, Memory Management, Performance tuning, Streaming, Data Science and Data Integration areas in Spark.\n     * Work with Account Executives, Solutions Architects and Professional Services for coordinating customer issues and best practices guidelines.\n     * Coordinate with Engineering and Backline Support teams to help report Product defects.\n     * Help create company documentation and knowledge articles.\n     * Participate in weekend (infrequent) and weekday (normal business hrs) on-call rotation."
    },
    "analysis": {
        "profile_classification": {
            "profile": "Ambiguous / Not Relevant",
            "confidence_score": 2,
            "rationale": "The job description focuses heavily on providing technical solutions and consulting for existing Spark/ML/AI issues on the Databricks platform, rather than developing new models or applications. While it mentions AI and ML, the core tasks revolve around troubleshooting and supporting customers with existing technologies, fitting more into a technical support or solutions engineering role than a dedicated ML or GenAI Engineer."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "phrase": "Provide technical and consulting related solutions for the challenging Spark/ML/AI/Delta/Streaming/Lakehouse reported issues by our customers",
                    "category": "TASK1",
                    "justification": "This phrase indicates understanding customer challenges and providing solutions, which aligns with understanding business needs and translating them into technical guidance."
                },
                {
                    "phrase": "resolve any challenges involving the Databricks unified analytics platform with your comprehensive technical and client-facing skills",
                    "category": "TASK1",
                    "justification": "This involves understanding client needs and platform capabilities to resolve issues, linking technical expertise to client success and business goals."
                },
                {
                    "phrase": "assist our customers in their Databricks journey and provide them with the guidance and expertise that they need to accomplish value and achieve their strategic goals using our products",
                    "category": "TASK1",
                    "justification": "This directly relates to understanding customer strategic goals and guiding them to achieve value using the product, a key aspect of business understanding."
                },
                {
                    "phrase": "Provide best practices guidance for custom-built solutions developed by Databricks customers.",
                    "category": "TASK1",
                    "justification": "Offering guidance on best practices for customer solutions implies understanding how technical implementations align with business objectives and product usage."
                },
                {
                    "phrase": "Troubleshoot, resolve and suggest deep code-level analysis of Spark to address customer issues related to Spark core internals, Spark SQL, Structured Streaming, Delta, Lakehouse and other Databricks runtime features.",
                    "category": "TASK2",
                    "justification": "This involves deep analysis and resolution of issues related to data processing and streaming technologies, which are core components of data engineering infrastructure and pipelines."
                },
                {
                    "phrase": "Assist the customers in setting up reproducible Spark problems with solutions in the areas of Spark SQL, Delta, Memory Management, Performance tuning, Streaming, Data Science and Data Integration areas in Spark.",
                    "category": "TASK2",
                    "justification": "This task involves helping customers set up and resolve issues within data processing, performance tuning, and data integration, all of which fall under data engineering and pipeline management."
                },
                {
                    "phrase": "Work with Account Executives, Solutions Architects and Professional Services for coordinating customer issues and best practices guidelines.",
                    "category": "TASK1",
                    "justification": "This involves collaboration with various teams to address customer issues and provide guidance, requiring an understanding of both technical and business aspects of customer engagements."
                },
                {
                    "phrase": "Coordinate with Engineering and Backline Support teams to help report Product defects.",
                    "category": "TASK5",
                    "justification": "This involves coordinating with engineering teams to report defects, which is a part of the feedback loop for product improvement and maintenance in a production environment."
                },
                {
                    "phrase": "Help create company documentation and knowledge articles.",
                    "category": "TASK1",
                    "justification": "Creating documentation and knowledge articles requires understanding technical concepts and translating them into accessible information for users, aligning with business needs for support and knowledge sharing."
                },
                {
                    "phrase": "Participate in weekend (infrequent) and weekday (normal business hrs) on-call rotation.",
                    "category": "TASK5",
                    "justification": "Being on-call for customer issues relates to the operational support and maintenance of the platform in production."
                }
            ],
            "technologies": [
                {
                    "phrase": "Spark",
                    "category": "TECH10",
                    "justification": "Spark is a data processing engine often used for data modeling and large-scale data processing."
                },
                {
                    "phrase": "ML",
                    "category": "TECH10",
                    "justification": "ML (Machine Learning) is a broad category that falls under data modeling and algorithm development."
                },
                {
                    "phrase": "AI",
                    "category": "TECH10",
                    "justification": "AI (Artificial Intelligence) is a broad category that encompasses machine learning and other intelligent systems, often involving data modeling."
                },
                {
                    "phrase": "Delta",
                    "category": "TECH10",
                    "justification": "Delta Lake is a storage layer that brings ACID transactions to Apache Spark and big data workloads, often used in conjunction with data modeling and processing."
                },
                {
                    "phrase": "Streaming",
                    "category": "TECH10",
                    "justification": "Streaming refers to real-time data processing, a component of data engineering and modeling."
                },
                {
                    "phrase": "Lakehouse",
                    "category": "TECH10",
                    "justification": "Lakehouse is an architectural paradigm that combines data lakes and data warehouses, often involving data modeling and processing."
                },
                {
                    "phrase": "Databricks",
                    "category": "TECH2",
                    "justification": "Databricks is a cloud-based platform for data engineering, data science, and machine learning."
                },
                {
                    "phrase": "Spark SQL",
                    "category": "TECH11",
                    "justification": "Spark SQL is a module for structured data processing, often used for data analysis."
                },
                {
                    "phrase": "Structured Streaming",
                    "category": "TECH10",
                    "justification": "Structured Streaming is a Spark SQL module for scalable, fault-tolerant stream processing of live data streams, fitting under data modeling and processing."
                },
                {
                    "phrase": "Memory Management",
                    "category": "TECH10",
                    "justification": "Memory management is a crucial aspect of performance tuning for data processing and modeling tasks."
                },
                {
                    "phrase": "Performance tuning",
                    "category": "TECH10",
                    "justification": "Performance tuning is essential for optimizing data processing and modeling tasks."
                },
                {
                    "phrase": "Data Science",
                    "category": "TECH10",
                    "justification": "Data Science is a broad field that encompasses data modeling, analysis, and interpretation."
                },
                {
                    "phrase": "Data Integration",
                    "category": "TECH2",
                    "justification": "Data Integration involves combining data from different sources, a key aspect of data engineering."
                }
            ],
            "soft_skills": [
                {
                    "phrase": "technical and consulting related solutions",
                    "category": "SKILL3",
                    "justification": "Providing solutions and consulting requires problem-solving and a pragmatic approach to address customer challenges."
                },
                {
                    "phrase": "comprehensive technical and client-facing skills",
                    "category": "SKILL1",
                    "justification": "Client-facing skills are essential for communication and collaboration with customers."
                },
                {
                    "phrase": "provide them with the guidance and expertise",
                    "category": "SKILL1",
                    "justification": "Offering guidance and expertise requires strong communication and the ability to explain technical concepts."
                },
                {
                    "phrase": "Work with Account Executives, Solutions Architects and Professional Services",
                    "category": "SKILL1",
                    "justification": "This explicitly mentions working with different teams, highlighting collaboration."
                },
                {
                    "phrase": "Help create company documentation and knowledge articles",
                    "category": "SKILL1",
                    "justification": "Creating documentation requires clear communication and the ability to convey technical information effectively."
                },
                {
                    "phrase": "Troubleshoot, resolve and suggest deep code-level analysis",
                    "category": "SKILL3",
                    "justification": "Troubleshooting and deep code analysis are core problem-solving activities."
                },
                {
                    "phrase": "setting up reproducible Spark problems with solutions",
                    "category": "SKILL3",
                    "justification": "This involves problem-solving to create reproducible scenarios and find solutions."
                }
            ]
        }
    }
}