{
    "job_id": 115,
    "job_details": {
        "job_id": 115,
        "Organisatienaam": "Accel",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "ML Platform Engineer - Large scale compute",
        "Standplaats": "Amsterdam",
        "Vacaturelink (origineel)": "accel.com",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Cloud specialist (m/v/x)",
        "Opleidingsniveau": "Onbekend",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "We are looking for an ML Platform Engineer - Large scale compute to help streamline our ML development process and accelerate our research teams. You will be working as part of the newly created ML Platform Team, supporting 7+ teams that work \"full stack\". Our Research Engineers run Ops, Engineering and Science. We have built our own workflow engine. Now we want to streamline the process, adopt the right tools and super-charge the work we are doing., In this position, you will set up and own our compute cluster on AWS. You will be supporting multiple deep tech ML teams on large model training across 100s GPUs We want you to:\n     * Setup high performance compute clusters that are easy to access by researchers, come pre-bundled with all necessary tools & packages and can be monitored easily.\n     * Help our research teams set up their distributed ML infrastructure.\n     * Establish best practices on running ML Models on distributed hardware.\n     * Optimise the solution for ease-of-use, efficiency and maximum utilisation.\n     * Configure & create infrastructure for researchers to run their large models on.\n     * Implement new tooling in the areas of orchestration, experiment tracking, service deployment, Infrastructure as Code.",
        "Datum gevonden": "2023-05-19",
        "Beroepsgroep": "Consultants en specialisten",
        "Beroepsklasse": "Informatie- en communicatietechnologie",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "ICT",
        "Organisatiegrootte": "1-9",
        "Jaar (van datum gevonden)": 2023,
        "Maand (van datum gevonden)": 5,
        "full_text": "ML Platform Engineer - Large scale compute\n\nWe are looking for an ML Platform Engineer - Large scale compute to help streamline our ML development process and accelerate our research teams. You will be working as part of the newly created ML Platform Team, supporting 7+ teams that work \"full stack\". Our Research Engineers run Ops, Engineering and Science. We have built our own workflow engine. Now we want to streamline the process, adopt the right tools and super-charge the work we are doing., In this position, you will set up and own our compute cluster on AWS. You will be supporting multiple deep tech ML teams on large model training across 100s GPUs We want you to:\n     * Setup high performance compute clusters that are easy to access by researchers, come pre-bundled with all necessary tools & packages and can be monitored easily.\n     * Help our research teams set up their distributed ML infrastructure.\n     * Establish best practices on running ML Models on distributed hardware.\n     * Optimise the solution for ease-of-use, efficiency and maximum utilisation.\n     * Configure & create infrastructure for researchers to run their large models on.\n     * Implement new tooling in the areas of orchestration, experiment tracking, service deployment, Infrastructure as Code."
    },
    "analysis": {
        "profile_classification": {
            "profile": "ML Engineer",
            "confidence_score": 4,
            "rationale": "The role heavily emphasizes building and managing large-scale compute infrastructure for ML teams, focusing on optimizing distributed hardware and establishing best practices for running ML models. While it involves software development and MLOps, the core is enabling and streamlining the ML development process for research teams, aligning with the ML Engineer profile's focus on productionizing and supporting model development."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "task": "TASK2: Data Engineering",
                    "phrases": [
                        {
                            "phrase": "Help our research teams set up their distributed ML infrastructure.",
                            "justification": "This phrase directly relates to setting up the underlying infrastructure required for ML workflows, which is a component of data engineering in terms of pipeline and environment setup."
                        },
                        {
                            "phrase": "Configure & create infrastructure for researchers to run their large models on.",
                            "justification": "Creating and configuring infrastructure for model execution falls under the umbrella of preparing the environment and resources for ML tasks, which is related to data engineering."
                        }
                    ]
                },
                {
                    "task": "TASK3: Modeling",
                    "phrases": [
                        {
                            "phrase": "supporting multiple deep tech ML teams on large model training",
                            "justification": "This indicates direct involvement in the training phase of large ML models, which is a core aspect of the modeling task."
                        },
                        {
                            "phrase": "Establish best practices on running ML Models on distributed hardware.",
                            "justification": "This involves understanding and guiding the process of training and running ML models, a key part of the modeling lifecycle."
                        },
                        {
                            "phrase": "run their large models on",
                            "justification": "This phrase directly refers to the execution and management of ML models, a central part of the modeling task."
                        }
                    ]
                },
                {
                    "task": "TASK4: Software Development",
                    "phrases": [
                        {
                            "phrase": "streamline our ML development process",
                            "justification": "This implies developing or improving processes and tools that facilitate the overall ML development lifecycle, which involves software development principles."
                        },
                        {
                            "phrase": "adopt the right tools and super-charge the work we are doing",
                            "justification": "This suggests the implementation and integration of tools, which often involves software development to make them work effectively within the existing ecosystem."
                        },
                        {
                            "phrase": "Implement new tooling in the areas of orchestration, experiment tracking, service deployment, Infrastructure as Code.",
                            "justification": "Implementing new tooling, especially in areas like orchestration, experiment tracking, and IaC, requires software development skills to integrate and manage these components."
                        }
                    ]
                },
                {
                    "task": "TASK5: Operations Engineering (MLOps)",
                    "phrases": [
                        {
                            "phrase": "ML Platform Engineer",
                            "justification": "The job title itself indicates a focus on the platform that supports ML operations, which is a core MLOps function."
                        },
                        {
                            "phrase": "streamline our ML development process",
                            "justification": "Streamlining development processes often involves implementing MLOps practices for efficiency and automation."
                        },
                        {
                            "phrase": "set up and own our compute cluster on AWS",
                            "justification": "Managing and owning compute infrastructure, especially on cloud platforms like AWS, is a fundamental aspect of MLOps."
                        },
                        {
                            "phrase": "Setup high performance compute clusters that are easy to access by researchers, come pre-bundled with all necessary tools & packages and can be monitored easily.",
                            "justification": "This describes the setup and maintenance of production-grade infrastructure for ML, including monitoring, which is a key MLOps responsibility."
                        },
                        {
                            "phrase": "Optimise the solution for ease-of-use, efficiency and maximum utilisation.",
                            "justification": "Optimization of ML infrastructure for efficiency and utilization is a critical MLOps concern."
                        },
                        {
                            "phrase": "Implement new tooling in the areas of orchestration, experiment tracking, service deployment, Infrastructure as Code.",
                            "justification": "These are all core components of MLOps, focusing on automating and managing the ML lifecycle."
                        }
                    ]
                }
            ],
            "technologies": [
                {
                    "technology": "AWS",
                    "category": "TECH2: Cloud Platforms & Services"
                },
                {
                    "technology": "GPUs",
                    "category": "TECH1: Programming Languages"
                },
                {
                    "technology": "Infrastructure as Code",
                    "category": "TECH6: MLOps & Data Pipelines"
                }
            ],
            "soft_skills": [
                {
                    "skill": "supporting 7+ teams that work \"full stack\"",
                    "category": "SKILL1: Communication & Collaboration"
                },
                {
                    "skill": "Our Research Engineers run Ops, Engineering and Science.",
                    "category": "SKILL1: Communication & Collaboration"
                },
                {
                    "skill": "easy to access by researchers",
                    "category": "SKILL1: Communication & Collaboration"
                },
                {
                    "skill": "ease-of-use",
                    "category": "SKILL3: Problem Solving & Pragmatism"
                },
                {
                    "skill": "efficiency",
                    "category": "SKILL3: Problem Solving & Pragmatism"
                },
                {
                    "skill": "maximum utilisation",
                    "category": "SKILL3: Problem Solving & Pragmatism"
                }
            ]
        }
    }
}