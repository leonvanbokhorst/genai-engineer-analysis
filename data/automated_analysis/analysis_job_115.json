{
    "job_id": 115,
    "job_details": {
        "job_id": 115,
        "Organisatienaam": "Accel",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "ML Platform Engineer - Large scale compute",
        "Standplaats": "Amsterdam",
        "Vacaturelink (origineel)": "accel.com",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Cloud specialist (m/v/x)",
        "Opleidingsniveau": "Onbekend",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "We are looking for an ML Platform Engineer - Large scale compute to help streamline our ML development process and accelerate our research teams. You will be working as part of the newly created ML Platform Team, supporting 7+ teams that work \"full stack\". Our Research Engineers run Ops, Engineering and Science. We have built our own workflow engine. Now we want to streamline the process, adopt the right tools and super-charge the work we are doing., In this position, you will set up and own our compute cluster on AWS. You will be supporting multiple deep tech ML teams on large model training across 100s GPUs We want you to:\n     * Setup high performance compute clusters that are easy to access by researchers, come pre-bundled with all necessary tools & packages and can be monitored easily.\n     * Help our research teams set up their distributed ML infrastructure.\n     * Establish best practices on running ML Models on distributed hardware.\n     * Optimise the solution for ease-of-use, efficiency and maximum utilisation.\n     * Configure & create infrastructure for researchers to run their large models on.\n     * Implement new tooling in the areas of orchestration, experiment tracking, service deployment, Infrastructure as Code.",
        "Datum gevonden": "2023-05-19",
        "Beroepsgroep": "Consultants en specialisten",
        "Beroepsklasse": "Informatie- en communicatietechnologie",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "ICT",
        "Organisatiegrootte": "1-9",
        "Jaar (van datum gevonden)": 2023,
        "Maand (van datum gevonden)": 5,
        "full_text": "ML Platform Engineer - Large scale compute\n\nWe are looking for an ML Platform Engineer - Large scale compute to help streamline our ML development process and accelerate our research teams. You will be working as part of the newly created ML Platform Team, supporting 7+ teams that work \"full stack\". Our Research Engineers run Ops, Engineering and Science. We have built our own workflow engine. Now we want to streamline the process, adopt the right tools and super-charge the work we are doing., In this position, you will set up and own our compute cluster on AWS. You will be supporting multiple deep tech ML teams on large model training across 100s GPUs We want you to:\n     * Setup high performance compute clusters that are easy to access by researchers, come pre-bundled with all necessary tools & packages and can be monitored easily.\n     * Help our research teams set up their distributed ML infrastructure.\n     * Establish best practices on running ML Models on distributed hardware.\n     * Optimise the solution for ease-of-use, efficiency and maximum utilisation.\n     * Configure & create infrastructure for researchers to run their large models on.\n     * Implement new tooling in the areas of orchestration, experiment tracking, service deployment, Infrastructure as Code."
    },
    "analysis": {
        "profile_classification": {
            "profile": "ML Engineer",
            "rationale": "The job description emphasizes building and maintaining large-scale compute infrastructure for ML teams, including setting up GPU clusters, establishing best practices for distributed ML, and implementing MLOps tooling. While it involves supporting ML teams, the core focus is on the platform and infrastructure rather than the direct development or fine-tuning of generative models or user-facing applications, which aligns more closely with the 'ML Engineer' profile's focus on productionizing models and MLOps."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "The role involves setting up and managing compute clusters and infrastructure for ML teams, which includes aspects of data pipeline and infrastructure management for large-scale model training.",
                    "phrase": "Setup high performance compute clusters that are easy to access by researchers, come pre-bundled with all necessary tools & packages and can be monitored easily."
                },
                {
                    "category": "TASK2: Data Engineering",
                    "justification": "Supporting research teams in setting up their distributed ML infrastructure involves data pipeline and infrastructure configuration.",
                    "phrase": "Help our research teams set up their distributed ML infrastructure."
                },
                {
                    "category": "TASK3: Modeling",
                    "justification": "The role directly supports teams running large model training and establishes best practices for running ML models on distributed hardware, implying involvement in the operational aspects of model execution.",
                    "phrase": "Establish best practices on running ML Models on distributed hardware."
                },
                {
                    "category": "TASK4: Software Development",
                    "justification": "While not building user-facing applications, the role involves configuring and creating infrastructure for researchers to run their large models, which requires software development skills for infrastructure setup.",
                    "phrase": "Configure & create infrastructure for researchers to run their large models on."
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "The description explicitly mentions implementing new tooling in orchestration, experiment tracking, and service deployment, which are core MLOps activities.",
                    "phrase": "Implement new tooling in the areas of orchestration, experiment tracking, service deployment, Infrastructure as Code."
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Owning the compute cluster on AWS and optimizing it for efficiency and utilization falls under the operational management of ML infrastructure.",
                    "phrase": "set up and own our compute cluster on AWS"
                },
                {
                    "category": "TASK5: Operations Engineering (MLOps)",
                    "justification": "Optimizing the solution for ease-of-use, efficiency and maximum utilization is a key aspect of operational excellence in ML platforms.",
                    "phrase": "Optimise the solution for ease-of-use, efficiency and maximum utilisation."
                }
            ],
            "soft_skills": [
                {
                    "category": "SKILL1: Communication & Collaboration",
                    "phrase": "supporting 7+ teams that work \"full stack\""
                },
                {
                    "category": "SKILL5: Innovation & Ownership",
                    "phrase": "set up and own our compute cluster on AWS"
                },
                {
                    "category": "SKILL3: Problem Solving & Pragmatism",
                    "phrase": "streamline our ML development process and accelerate our research teams"
                }
            ],
            "technologies": [
                {
                    "category": "TECH2: Cloud Platforms & Services",
                    "phrase": "AWS"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "deep tech ML teams"
                },
                {
                    "category": "TECH10: Data Modeling",
                    "phrase": "large model training"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "orchestration"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "experiment tracking"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "service deployment"
                },
                {
                    "category": "TECH6: MLOps & Data Pipelines",
                    "phrase": "Infrastructure as Code"
                }
            ]
        }
    }
}