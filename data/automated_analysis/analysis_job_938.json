{
    "job_id": 938,
    "job_details": {
        "job_id": 938,
        "Organisatienaam": "Microsoft B.V.",
        "Type adverteerder": "Directe werkgever",
        "Vacaturetitel": "Senior Telemetry Data Engineer",
        "Standplaats": null,
        "Vacaturelink (origineel)": "dejobs.org",
        "Contactpersoon": null,
        "Telefoonnummer": null,
        "E-mail": null,
        "Beroep": "Data engineer (m/v/x)",
        "Opleidingsniveau": "HBO",
        "Jobfeed feedbacklink": "Meld fout",
        "Functieomschrijving": "Are you passionate about cloud computing? Do you get excited about taking a hands-on approach to transforming Microsoft's most critical business through investigation, data analysis, and automation? If so, come and help us build the most reliable & efficient datacenter infrastructure on the planet. The CO+I Critical Environment Systems Intelligence (CESI) team is responsible for designing and delivering solutions to support global datacenter operations and to improve availability. CESI is helping to drive CO+I's transition to a customer centric, data driven, observability based, live service culture. As a Data Engineer, you will be a key player in this transition.   \n\n   As a Senior Data Engineer on the CO+I Critical Environment Service Intelligence (CESI) team, you partner and collaborate on the design and delivery of automated solutions to monitor, detect, and alert on data center critical environment mechanical and electrical resources. You will collaborate with other CO+I teams to contribute and benefit from their work to ensure that we are constantly improving across the fleet. You will work with massive amounts of data with low latency requirements across cutting edge technologies, with the potential for significant impact to both internal partners and external customers.\n\n   In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day., As a Senior Technical Program Manager in DC Critical Environments, you will:\n     * Drive a program that covers end-to-endmonitoring, and processing of critical environment (CE) infrastructure telemetry for all leased sites, to bring those sites on par with owneddatacenter sites.\n     * Design and implement telemetry data ingestion and data processing systems for leased sites.\n     * Prototype, pilot, and deploy multi-signal anomaly detection and prevention systemsleveraging machine learning and statistical analysis for DC leased sites\n     * Define and drive an operationalization plan for the telemetry pipeline for leased sites.\n     * Ensure interoperability of detection methods, systems, and workflows by defining conceptual, logical, and physical data models.\n     * Understand the signals coming from the EPMS and BAS systems for leased sites.\n     * Ensure high percent coverage and mapping of leased site signals including thermal, power, and other environmental conditions and data.\n     * Define a set of reusable primitives for mapping logical and physical topology of data centers leased sites.\n     * Ensure there is a high-frequency, high-volume, low-latency streaming and micro-batching capable pipeline to process DC CE telemetry from leased sites.\n     * Architect a staging model to ensure the onboarding of leased sites CE telemetry (thermal, power, and other environmental subjects)., About Us: We are committed to maintaining the highest standards of operational excellence in our data centers. Join us in our mission to enhance our telemetry capabilities and ensure the reliability and efficiency of our critical environments.",
        "Datum gevonden": "2024-12-19",
        "Beroepsgroep": "Systeemontwikkelaars en -analisten",
        "Beroepsklasse": "Informatie- en communicatietechnologie",
        "Contracttype": "Vast contract",
        "Parttime / fulltime": "Fulltime (> 32 uur)",
        "Branche": "Handel",
        "Organisatiegrootte": "10-49",
        "Jaar (van datum gevonden)": 2024,
        "Maand (van datum gevonden)": 12,
        "full_text": "Senior Telemetry Data Engineer\n\nAre you passionate about cloud computing? Do you get excited about taking a hands-on approach to transforming Microsoft's most critical business through investigation, data analysis, and automation? If so, come and help us build the most reliable & efficient datacenter infrastructure on the planet. The CO+I Critical Environment Systems Intelligence (CESI) team is responsible for designing and delivering solutions to support global datacenter operations and to improve availability. CESI is helping to drive CO+I's transition to a customer centric, data driven, observability based, live service culture. As a Data Engineer, you will be a key player in this transition.   \n\n   As a Senior Data Engineer on the CO+I Critical Environment Service Intelligence (CESI) team, you partner and collaborate on the design and delivery of automated solutions to monitor, detect, and alert on data center critical environment mechanical and electrical resources. You will collaborate with other CO+I teams to contribute and benefit from their work to ensure that we are constantly improving across the fleet. You will work with massive amounts of data with low latency requirements across cutting edge technologies, with the potential for significant impact to both internal partners and external customers.\n\n   In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day., As a Senior Technical Program Manager in DC Critical Environments, you will:\n     * Drive a program that covers end-to-endmonitoring, and processing of critical environment (CE) infrastructure telemetry for all leased sites, to bring those sites on par with owneddatacenter sites.\n     * Design and implement telemetry data ingestion and data processing systems for leased sites.\n     * Prototype, pilot, and deploy multi-signal anomaly detection and prevention systemsleveraging machine learning and statistical analysis for DC leased sites\n     * Define and drive an operationalization plan for the telemetry pipeline for leased sites.\n     * Ensure interoperability of detection methods, systems, and workflows by defining conceptual, logical, and physical data models.\n     * Understand the signals coming from the EPMS and BAS systems for leased sites.\n     * Ensure high percent coverage and mapping of leased site signals including thermal, power, and other environmental conditions and data.\n     * Define a set of reusable primitives for mapping logical and physical topology of data centers leased sites.\n     * Ensure there is a high-frequency, high-volume, low-latency streaming and micro-batching capable pipeline to process DC CE telemetry from leased sites.\n     * Architect a staging model to ensure the onboarding of leased sites CE telemetry (thermal, power, and other environmental subjects)., About Us: We are committed to maintaining the highest standards of operational excellence in our data centers. Join us in our mission to enhance our telemetry capabilities and ensure the reliability and efficiency of our critical environments."
    },
    "analysis": {
        "job_profile_classification": {
            "profile": "ML Engineer",
            "confidence_score": 4,
            "rationale": "The role heavily emphasizes data engineering, building and maintaining data pipelines, and implementing anomaly detection systems using machine learning and statistical analysis. While it involves software development for integration, the core focus is on data processing, model application for prediction/detection, and operationalizing these systems, aligning with the ML Engineer profile."
        },
        "thematic_analysis": {
            "job_tasks": [
                {
                    "task_category": "TASK1: Business Understanding",
                    "phrases": [
                        {
                            "phrase": "transforming Microsoft's most critical business through investigation, data analysis, and automation",
                            "justification": "This phrase indicates an understanding of how data engineering contributes to the broader business objectives and critical operations of Microsoft."
                        },
                        {
                            "phrase": "help us build the most reliable & efficient datacenter infrastructure on the planet",
                            "justification": "This highlights the business goal of improving datacenter infrastructure reliability and efficiency, which the role aims to support."
                        },
                        {
                            "phrase": "driving CO+I's transition to a customer centric, data driven, observability based, live service culture",
                            "justification": "This shows an understanding of the strategic business direction and cultural shift the team is part of."
                        },
                        {
                            "phrase": "partner and collaborate on the design and delivery of automated solutions to monitor, detect, and alert on data center critical environment mechanical and electrical resources",
                            "justification": "This describes collaborating to deliver solutions that meet business needs for monitoring and alerting on critical infrastructure."
                        },
                        {
                            "phrase": "contribute and benefit from their work to ensure that we are constantly improving across the fleet",
                            "justification": "This emphasizes collaboration towards a common business goal of fleet-wide improvement."
                        },
                        {
                            "phrase": "potential for significant impact to both internal partners and external customers",
                            "justification": "This points to the business impact and value the role is expected to deliver."
                        },
                        {
                            "phrase": "Drive a program that covers end-to-end monitoring, and processing of critical environment (CE) infrastructure telemetry for all leased sites, to bring those sites on par with owned datacenter sites.",
                            "justification": "This describes driving a program with a clear business objective: standardizing telemetry across different types of sites."
                        },
                        {
                            "phrase": "Define and drive an operationalization plan for the telemetry pipeline for leased sites.",
                            "justification": "This involves strategic planning for the operational deployment of data pipelines to meet business needs."
                        },
                        {
                            "phrase": "Ensure interoperability of detection methods, systems, and workflows by defining conceptual, logical, and physical data models.",
                            "justification": "This relates to ensuring systems work together effectively to meet business requirements for detection and monitoring."
                        },
                        {
                            "phrase": "Ensure high percent coverage and mapping of leased site signals including thermal, power, and other environmental conditions and data.",
                            "justification": "This focuses on achieving business objectives related to comprehensive data coverage for monitoring."
                        },
                        {
                            "phrase": "Define a set of reusable primitives for mapping logical and physical topology of data centers leased sites.",
                            "justification": "This involves creating standardized approaches to represent infrastructure, supporting business needs for understanding and management."
                        },
                        {
                            "phrase": "About Us: We are committed to maintaining the highest standards of operational excellence in our data centers. Join us in our mission to enhance our telemetry capabilities and ensure the reliability and efficiency of our critical environments.",
                            "justification": "This explicitly states the business mission and commitment to operational excellence and reliability."
                        }
                    ]
                },
                {
                    "task_category": "TASK2: Data Engineering",
                    "phrases": [
                        {
                            "phrase": "Senior Telemetry Data Engineer",
                            "justification": "The job title itself indicates a primary focus on data engineering, specifically for telemetry data."
                        },
                        {
                            "phrase": "investigation, data analysis, and automation",
                            "justification": "These are core activities within data engineering, involving understanding data, deriving insights, and automating processes."
                        },
                        {
                            "phrase": "design and delivery of automated solutions to monitor, detect, and alert on data center critical environment mechanical and electrical resources",
                            "justification": "This describes the design and implementation of data-driven solutions for monitoring and alerting, a key data engineering function."
                        },
                        {
                            "phrase": "work with massive amounts of data with low latency requirements",
                            "justification": "This highlights the challenges and requirements typical in data engineering for handling large volumes of data with performance constraints."
                        },
                        {
                            "phrase": "Design and implement telemetry data ingestion and data processing systems for leased sites.",
                            "justification": "This is a direct description of core data engineering responsibilities: building ingestion and processing pipelines."
                        },
                        {
                            "phrase": "Define and drive an operationalization plan for the telemetry pipeline for leased sites.",
                            "justification": "This involves planning the deployment and management of data pipelines, a crucial aspect of data engineering."
                        },
                        {
                            "phrase": "Ensure there is a high-frequency, high-volume, low-latency streaming and micro-batching capable pipeline to process DC CE telemetry from leased sites.",
                            "justification": "This specifies the technical requirements for data pipelines, including streaming and batch processing capabilities."
                        },
                        {
                            "phrase": "Architect a staging model to ensure the onboarding of leased sites CE telemetry (thermal, power, and other environmental subjects).",
                            "justification": "This involves designing the architecture for data staging and onboarding, a key data engineering task."
                        }
                    ]
                },
                {
                    "task_category": "TASK3: Modeling",
                    "phrases": [
                        {
                            "phrase": "Prototype, pilot, and deploy multi-signal anomaly detection and prevention systems leveraging machine learning and statistical analysis for DC leased sites",
                            "justification": "This directly mentions the use of machine learning and statistical analysis to build anomaly detection systems, which falls under modeling."
                        },
                        {
                            "phrase": "interoperability of detection methods, systems, and workflows by defining conceptual, logical, and physical data models.",
                            "justification": "While 'data models' can refer to database schemas, in the context of 'detection methods' and 'systems', it also implies modeling of data relationships and structures for analytical purposes."
                        }
                    ]
                },
                {
                    "task_category": "TASK4: Software Development",
                    "phrases": [
                        {
                            "phrase": "design and delivery of automated solutions",
                            "justification": "Designing and delivering solutions often involves software development to automate processes and build systems."
                        },
                        {
                            "phrase": "Prototype, pilot, and deploy multi-signal anomaly detection and prevention systems",
                            "justification": "The process of prototyping, piloting, and deploying systems implies software development to build and integrate these components."
                        },
                        {
                            "phrase": "Ensure interoperability of detection methods, systems, and workflows",
                            "justification": "Ensuring systems work together requires software development for integration and API design."
                        }
                    ]
                },
                {
                    "task_category": "TASK5: Operations Engineering (MLOps)",
                    "phrases": [
                        {
                            "phrase": "automated solutions to monitor, detect, and alert",
                            "justification": "Building automated monitoring and alerting systems requires operational considerations for deployment and maintenance."
                        },
                        {
                            "phrase": "Define and drive an operationalization plan for the telemetry pipeline for leased sites.",
                            "justification": "This directly refers to operationalizing data pipelines, a core MLOps activity."
                        },
                        {
                            "phrase": "high-frequency, high-volume, low-latency streaming and micro-batching capable pipeline to process DC CE telemetry",
                            "justification": "Designing pipelines with specific performance characteristics (latency, volume) is crucial for production operations."
                        },
                        {
                            "phrase": "ensure the onboarding of leased sites CE telemetry",
                            "justification": "Onboarding data sources and ensuring continuous data flow is an operational concern."
                        }
                    ]
                }
            ],
            "technologies": [
                {
                    "tech_category": "TECH1: Programming Languages",
                    "technologies": []
                },
                {
                    "tech_category": "TECH2: Cloud Platforms & Services",
                    "technologies": [
                        "Microsoft"
                    ]
                },
                {
                    "tech_category": "TECH3: LLM / Generative Models",
                    "technologies": []
                },
                {
                    "tech_category": "TECH4: LLM Frameworks & Libraries",
                    "technologies": []
                },
                {
                    "tech_category": "TECH5: Vector Stores & Search",
                    "technologies": []
                },
                {
                    "tech_category": "TECH6: MLOps & Data Pipelines",
                    "technologies": [
                        "streaming",
                        "micro-batching"
                    ]
                },
                {
                    "tech_category": "TECH7: Data Visualization",
                    "technologies": []
                },
                {
                    "tech_category": "TECH8: Data Processing",
                    "technologies": []
                },
                {
                    "tech_category": "TECH9: Data Storage",
                    "technologies": []
                },
                {
                    "tech_category": "TECH10: Data Modeling",
                    "technologies": [
                        "conceptual data models",
                        "logical data models",
                        "physical data models"
                    ]
                },
                {
                    "tech_category": "TECH11: Data Analysis",
                    "technologies": [
                        "data analysis"
                    ]
                }
            ],
            "soft_skills": [
                {
                    "skill_category": "SKILL1: Communication & Collaboration",
                    "skills": [
                        "partner and collaborate",
                        "collaborate with other CO+I teams"
                    ]
                },
                {
                    "skill_category": "SKILL2: Learning & Adaptability",
                    "skills": [
                        "transforming Microsoft's most critical business through investigation, data analysis, and automation",
                        "transition to a customer centric, data driven, observability based, live service culture"
                    ]
                },
                {
                    "skill_category": "SKILL3: Problem Solving & Pragmatism",
                    "skills": [
                        "investigation, data analysis, and automation",
                        "automated solutions to monitor, detect, and alert",
                        "Prototype, pilot, and deploy multi-signal anomaly detection and prevention systems",
                        "Define and drive an operationalization plan",
                        "Ensure interoperability",
                        "Ensure high percent coverage and mapping",
                        "Define a set of reusable primitives"
                    ]
                },
                {
                    "skill_category": "SKILL4: Ethical & Legal Responsibility",
                    "skills": []
                },
                {
                    "skill_category": "SKILL5: Innovation & Ownership",
                    "skills": [
                        "Drive a program",
                        "Architect a staging model"
                    ]
                }
            ]
        }
    }
}