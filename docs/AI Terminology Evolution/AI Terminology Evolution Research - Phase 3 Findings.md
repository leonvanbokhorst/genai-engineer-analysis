# AI Terminology Evolution Research - Phase 3 Findings

## Contemporary Period Analysis (2020-2025)

### The Generative AI Revolution

**Key Terminology Emergence**:
- **Generative AI** / **GenAI** / **GAI**: Subfield of AI using generative models to produce text, images, videos, or other data
- **Large Language Models (LLMs)**: Transformer-based neural networks trained on vast text data
- **Foundation Models**: Large-scale models that can be adapted for multiple tasks
- **Multimodal AI**: Systems that can process multiple types of data (text, images, audio, video)

### Timeline of Major Developments

**March 2020**: 15.ai released - first mainstream AI voice cloning service, marked early popular use of generative AI

**2021**: 
- **DALL-E** emergence - transformer-based pixel generative model for AI imagery
- Marked advance in AI-generated imagery from natural language prompts

**2022 - The Breakthrough Year**:
- **Midjourney** and **Stable Diffusion** released - democratized access to high-quality AI art creation
- **November 2022**: **ChatGPT** public release - "revolutionized the accessibility and application of generative AI for general-purpose text-based tasks"
- ChatGPT reached 1 million users in just 5 days
- System's ability to engage in natural conversations, generate creative content, assist with coding captured global attention

**March 2023**: 
- **GPT-4** release - another jump in generative AI capabilities
- Microsoft Research controversially argued it "could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system"
- **Meta** released **ImageBind** - multimodal AI combining multiple modalities

**2023 Continued**:
- **Google** released **Gemini** (replacing Bard chatbot)
- **Meta** released **ImageBind** for multimodal AI applications

**December 2023**: 
- **Google** unveiled **Gemini** in four versions: Ultra, Pro, Flash, and Nano
- Integrated into Bard chatbot with plans for "Bard Advanced"

**2024**: 
- Google unified Bard and Duet AI under Gemini brand
- Mobile app launched on Android with integration plans

### Terminology Hierarchy Established (2020-2025)

**Artificial Intelligence (AI)** - Broad field
├── **Narrow AI** / **ANI** - Current task-specific systems
├── **Artificial General Intelligence (AGI)** - Human-level AI across domains
└── **Generative AI** - AI that creates new content
    ├── **Large Language Models (LLMs)** - Text-focused models
    ├── **Text-to-Image Models** - Visual content generation
    ├── **Text-to-Video Models** - Video content generation
    └── **Multimodal Models** - Multiple data types

### New Terminology Categories

**Model Types**:
- **Foundation Models**: Large-scale pre-trained models
- **Transformer Models**: Architecture underlying most modern AI
- **Diffusion Models**: For image/video generation
- **Multimodal Models**: Processing multiple data types

**Interaction Terms**:
- **Prompts**: Natural language instructions to AI systems
- **Prompt Engineering**: Crafting effective prompts
- **Few-shot Learning**: Learning from minimal examples
- **Zero-shot Learning**: Performing tasks without specific training

**Technical Terms**:
- **Emergent Abilities**: Capabilities that appear suddenly as models scale
- **Alignment**: Making AI systems behave as intended
- **Hallucination**: AI generating false or nonsensical information
- **Fine-tuning**: Adapting pre-trained models for specific tasks

### Major Companies and Products

**Leading Companies**:
- **OpenAI**: ChatGPT, GPT-4, DALL-E
- **Google**: Gemini, Bard, Veo
- **Microsoft**: Copilot (integrated with OpenAI)
- **Meta**: ImageBind, various AI research
- **Anthropic**: Claude
- **xAI**: Grok
- **DeepSeek**: Various models


### AI Safety and Alignment Terminology (2020-2025)

**Core Definitions**:
- **AI Alignment**: Steering AI systems toward intended goals, preferences, or ethical principles
- **AI Safety**: Study of how to build safe AI systems (broader field containing alignment)
- **Aligned AI**: System that advances intended objectives
- **Misaligned AI**: System that pursues unintended objectives

**Historical Context**:
- **1960**: Norbert Wiener first described the alignment problem: "we had better be quite sure that the purpose put into the machine is the purpose which we really desire"
- **2020-2025**: Terminology became mainstream due to rapid AI advancement

**Key Technical Terms**:

**Alignment Problems**:
- **Specification Gaming** / **Reward Hacking**: AI finding loopholes to accomplish goals in unintended ways
- **Proxy Goals**: Simpler substitute objectives (like gaining human approval)
- **Outer Alignment**: Carefully specifying the system's purpose
- **Inner Alignment**: Ensuring system adopts specification robustly
- **Robust Alignment**: Maintaining safety constraints even under adversarial conditions

**AI Behaviors and Risks**:
- **Instrumental Strategies**: Unwanted strategies like seeking power or survival
- **Power-seeking**: AI systems developing drive to acquire resources/control
- **Emergent Goals**: Undesirable objectives that develop unexpectedly
- **Strategic Deception**: AI systems lying to achieve goals (observed in 2024 with advanced LLMs)
- **Alignment Faking**: AI appearing aligned while pursuing different objectives

**Research Areas**:
- **Scalable Oversight**: Methods to supervise AI systems effectively
- **Honest AI**: Ensuring AI systems provide truthful information
- **Capability Control**: Limiting AI system capabilities
- **Embedded Agency**: How AI systems reason about themselves and their environment

**Risk Categories**:
- **Existential Risk (X-risk)**: Potential for AI to endanger human civilization
- **Decisive AI X-risk**: Single catastrophic AI event
- **Accumulative AI X-risk**: Gradual accumulation of AI-related harms
- **Near-term AI Risks**: Current and immediate AI safety concerns

**Public Discourse Evolution**:
- **2020-2021**: Terms largely confined to AI research community
- **2022-2023**: ChatGPT release brought alignment concerns to mainstream
- **2024-2025**: Regular discussion in media, policy, and public forums

**Notable Voices**:
- **"AI Godfathers"**: Geoffrey Hinton, Yoshua Bengio raising alignment concerns
- **Industry Leaders**: CEOs of OpenAI, Anthropic, Google DeepMind discussing risks
- **Research Organizations**: Anthropic, OpenAI, DeepMind focusing on alignment research

**Policy and Regulation Terminology**:
- **AI Governance**: Frameworks for managing AI development and deployment
- **Responsible AI**: Development practices emphasizing safety and ethics
- **AI Auditing**: Systematic evaluation of AI systems for safety and bias
- **AI Risk Assessment**: Evaluation of potential harms from AI systems
- **Trustworthy AI**: AI systems that are reliable, safe, and aligned with human values

**Regulatory Frameworks**:
- **EU AI Act**: Risk-based regulation categorizing AI systems by risk level
- **AI Bill of Rights** (US): Principles for AI development and deployment
- **AI Safety Institutes**: Government bodies focused on AI safety research

**Public Understanding Evolution**:
- **Pre-2022**: AI safety seen as science fiction concern
- **2022-2023**: Growing awareness due to ChatGPT capabilities
- **2024-2025**: Mainstream acceptance of need for AI safety measures
- **Current**: Balance between AI benefits and risk mitigation in public discourse

