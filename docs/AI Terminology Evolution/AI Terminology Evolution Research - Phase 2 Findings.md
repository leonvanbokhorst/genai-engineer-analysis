# AI Terminology Evolution Research - Phase 2 Findings

## Early 21st Century Evolution (2000-2019)

### The Data-Driven Revolution (2000s)

**Key Paradigm Shift**: From knowledge-driven to data-driven approaches
- Scientists began creating programs for computers to analyze large amounts of data and draw conclusions or "learn" from results
- Support-Vector Machines (SVMs) and Recurrent Neural Networks (RNNs) became popular
- Support-Vector Clustering and other kernel methods became widespread
- Unsupervised machine learning methods gained prominence

**Major Milestones 2000-2009**:
- **2002**: Torch machine learning library released
- **2006**: Netflix Prize launched - using machine learning to beat Netflix's recommendation accuracy
- **2009**: ImageNet created by Fei-Fei Li - large visual database that became catalyst for AI boom of 21st century

### The Deep Learning Revolution (2010s)

**2010**: Kaggle platform launched for machine learning competitions

**2011**: IBM Watson beats human champions in Jeopardy using combination of machine learning, natural language processing, and information retrieval techniques

**2012 - The Breakthrough Year**:
- **Google Brain** project (Andrew Ng, Jeff Dean) creates neural network that learns to recognize cats by watching YouTube videos
- **AlexNet** paper achieves breakthrough results in image recognition in ImageNet benchmark - "This popularizes deep neural networks"
- **Deep Learning becomes feasible** - leads to machine learning becoming integral to many widely used software services and applications

**2013**: **Word2vec** revolutionizes text processing in machine learning - shows how words can be converted into sequences of numbers (word embeddings)

**2014**: Facebook researchers publish work on **DeepFace** - neural network system for face recognition with 97.35% accuracy, rivaling human performance

### Key Terminology Changes 2000-2019:

**New Terms Emerged**:
- **Big Data** (early 2000s) - datasets too large for traditional processing
- **Deep Learning** (2010s) - multi-layer neural networks
- **Neural Networks** (resurged strongly after 2012)
- **Machine Learning** (became mainstream term)
- **Word Embeddings** (2013)
- **Convolutional Neural Networks (CNNs)**
- **Recurrent Neural Networks (RNNs)**
- **Long Short-Term Memory (LSTM)** (1997, but gained prominence in 2010s)

**Terminology Hierarchy Established**:
- **Artificial Intelligence** (broad field)
  - **Machine Learning** (subset of AI)
    - **Deep Learning** (subset of ML using neural networks)

**Industry vs Academic Usage**:
- Industry began using "AI" and "Machine Learning" more interchangeably
- Academic community maintained more precise distinctions
- "Deep Learning" became associated with breakthrough performance
- "Neural Networks" regained respectability after AI winter stigma


### The Emergence of AGI (Artificial General Intelligence) Terminology

**2007 - Term "AGI" Coined**:
- Term officially coined in 2007 with publication of book "Artificial General Intelligence" co-edited by Ben Goertzel and Cassio Pennachin
- **Shane Legg** (co-founder of DeepMind) suggested the term to Goertzel

**AGI Definition (2007)**:
"AGI is, loosely speaking, AI systems that possess a reasonable degree of self-understanding and autonomous self-control, and have the ability to solve a variety of complex problems in a variety of contexts, and to learn to solve new problems that they didn't know about at the time of their creation."

**Rationale for AGI Terminology**:
- Distinguish from "run-of-the-mill 'artificial intelligence' research"
- AGI explicitly focused on "engineering general intelligence in the short term"
- 2007 AI research focused on narrow challenges - programs could only "generalize within their limited context"

**Social Context (2007)**:
- Shane Legg described attitude: "If you talked to anybody about general AI, you would be considered at best eccentric, at worst some kind of delusional, nonscientific character"
- AGI research had "gotten a bit of a bad reputation"
- Considered "merely an engineering problem" though "certainly a very difficult one"

**Narrow AI vs AGI Distinction**:
- **Narrow AI (ANI - Artificial Narrow Intelligence)**: Systems confined to well-defined, specific tasks
- **AGI**: Systems that can generalize knowledge, transfer skills between domains, solve variety of complex problems

**Ironic Historical Note**:
- 2007 AGI researchers completely ignored the "fringe approach" of deep learning (neural networks)
- Geoffrey Hinton, Yann LeCun, and Joshua Bengio coined "deep learning" in 2007 but were considered fringe
- By 2012, this "fringe approach" became mainstream AI, while AGI remained theoretical

**Terminology Hierarchy Established by 2010s**:
- **Artificial Narrow Intelligence (ANI)** / **Narrow AI** / **Weak AI**: Current AI systems
- **Artificial General Intelligence (AGI)** / **Strong AI**: Human-level AI across all domains  
- **Artificial Superintelligence (ASI)**: AI exceeding human intelligence

**Public Perception Impact**:
- AGI terminology helped distinguish between current AI capabilities and future possibilities
- Created framework for discussing AI safety and existential risks
- Influenced media coverage and public understanding of AI limitations vs potential

